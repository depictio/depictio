name: "Depictio ‚Äì Full CI: Quality, Build, Integration, E2E Tests"

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  # Smart caching for quality checks - skip tests if code hasn't changed
  # Hashes all Python files, config files, and test files to detect changes
  # If hash matches a previous successful run, quality job is skipped
  check-quality-cache:
    runs-on: ubuntu-22.04
    outputs:
      cache-hit: ${{ steps.cache-quality.outputs.cache-hit }}
      code-hash: ${{ steps.hash.outputs.hash }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history to compare with previous commit

      - name: Generate code hash
        id: hash
        run: |
          # Hash all relevant files that affect quality checks:
          # - All Python source files (*.py)
          # - Dependency configuration (pyproject.toml)
          # - Pre-commit hooks (.pre-commit-config.yaml)
          # - Test configuration (pytest.ini)
          # - This workflow file itself
          # Only hash files that actually exist (filter out deleted/missing files)
          HASH=$(git ls-files '*.py' 'pyproject.toml' '.pre-commit-config.yaml' 'pytest.ini' '.github/workflows/depictio-ci.yaml' | \
            while read -r file; do
              if [ -f "$file" ]; then
                cat "$file"
              fi
            done | sha256sum | cut -d' ' -f1)
          echo "hash=$HASH" >> $GITHUB_OUTPUT
          echo "üìù Code hash: $HASH"

      - name: Check quality cache
        id: cache-quality
        uses: actions/cache@v4
        with:
          path: .quality-passed
          key: quality-${{ steps.hash.outputs.hash }}

      - name: Report cache status
        run: |
          if [ "${{ steps.cache-quality.outputs.cache-hit }}" == "true" ]; then
            echo "‚úÖ Quality checks passed for this code state previously - skipping"
          else
            echo "üîç No cache found - quality checks will run"
          fi

  quality:
    runs-on: ubuntu-22.04
    needs: check-quality-cache
    if: needs.check-quality-cache.outputs.cache-hit != 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"
          cache-dependency-path: "pyproject.toml"

      - name: Install Dependencies
        run: |
          uv venv --python 3.12.9 venv
          source venv/bin/activate
          uv pip install --upgrade pip

          # Install dependencies from pyproject.toml
          uv pip install -e ".[dev]"

          # Clean up any conflicting polars packages that may have been pulled in
          echo "üßπ Removing conflicting polars packages..."
          uv pip uninstall -y polars polars-runtime-32 2>/dev/null || true

          # Ensure correct polars-lts-cpu version is installed (required for MultiQC)
          echo "üì¶ Installing polars-lts-cpu 1.19.0..."
          uv pip install --force-reinstall "polars-lts-cpu[numpy,pandas,pyarrow,excel,deltalake]==1.19.0"

          # Verify only polars-lts-cpu is installed
          echo "‚úÖ Verifying polars installation..."
          uv pip list | grep -i polars
          python -c "import polars; assert '1.19' in polars.__version__, f'Wrong version: {polars.__version__}'; print(f'‚úÖ Polars {polars.__version__} verified')"

      # - name: Run Ruff for formatting
      #   run: |
      #     source venv/bin/activate
      #     ruff format depictio

      # - uses: astral-sh/ruff-action@v3
      #   with:
      #     src: depictio
      #     args: check --fix --exit-non-zero-on-fix --line-length=100
      #     version-file: pyproject.toml

      # - name: Debug environment before Ruff check
      #   run: |
      #     source venv/bin/activate
      #     echo "=== RUFF DEBUGGING INFO ==="
      #     echo "Ruff version: $(ruff --version)"
      #     echo "Working directory: $(pwd)"
      #     echo "Python path: $(which python)"
      #     echo "Python version: $(python --version)"

      #     echo "=== RUFF CONFIGURATION ==="
      #     ruff check --show-settings depictio | head -20

      #     echo "=== FILE COUNTS ==="
      #     echo "Total Python files in depictio: $(find depictio -name '*.py' | wc -l)"
      #     echo "Sample files being checked:"
      #     find depictio -name '*.py' | head -10

      #     echo "=== IMPORT VIOLATIONS CHECK ==="
      #     echo "Running import-only check to see specific violations:"
      #     ruff check depictio --select I --output-format=json | jq '.[0:5]' || echo "No import violations found or jq not available"

      #     echo "=== PRE-COMMIT RUFF VERSION ==="
      #     cat .pre-commit-config.yaml | grep -A 2 "charliermarsh/ruff-pre-commit" || echo "Pre-commit config not found"

      # - name: Run Ruff for linting
      #   run: |
      #     source venv/bin/activate
      #     ruff check depictio

      # - uses: astral-sh/ruff-action@v3
      #   with:
      #     src: depictio
      #     args: format
      #     version-file: pyproject.toml

      # - name: Run ty type checker (must pass)
      #   run: |
      #     source venv/bin/activate
      #     ty version
      #     ty check depictio/models/ depictio/api/ depictio/dash/ depictio/cli/ depictio/tests/

      # - name: Run pre-commit hooks
      #   run: |
      #     source venv/bin/activate
      #     pre-commit run --all-files

      - name: Run tests
        run: |
          source venv/bin/activate
          python -m pytest -xvs -n auto

      - name: Save quality cache marker
        if: success()
        run: |
          echo "Quality checks passed at $(date)" > .quality-passed
          echo "‚úÖ Quality cache marker created"

      - name: Update quality cache
        if: success()
        uses: actions/cache/save@v4
        with:
          path: .quality-passed
          key: quality-${{ needs.check-quality-cache.outputs.code-hash }}

  # Test pixi installation and basic functionality (no Docker required)
  pixi-install-test:
    runs-on: ubuntu-22.04
    needs: check-quality-cache
    steps:
      - uses: actions/checkout@v4

      - name: Install pixi
        uses: prefix-dev/setup-pixi@v0.9.3
        with:
          pixi-version: v0.39.5
          # Disable cache until pixi.lock is committed to the repo
          # Enable cache: true after running `pixi install` locally and committing pixi.lock
          cache: false
          # Allow pixi to generate lockfile
          locked: false
          # Use temp location for pixi binary to avoid cleanup issues
          pixi-bin-path: ${{ runner.temp }}/bin/pixi

      - name: Install dependencies with pixi
        run: |
          echo "üì¶ Installing dependencies with pixi..."
          pixi install
          echo "‚úÖ Pixi installation successful"

      - name: Verify pixi environment
        run: |
          echo "üîç Verifying pixi environment..."
          pixi run python --version
          pixi run python -c "import depictio; print(f'depictio package loaded successfully')"

      - name: Run quick tests (no infrastructure)
        run: |
          echo "üß™ Running quick tests without infrastructure..."
          pixi run test-fast || echo "‚ö†Ô∏è Some tests may require infrastructure - this is expected"

      - name: Verify infrastructure commands exist
        run: |
          echo "üîç Verifying infrastructure commands are available..."
          pixi run mongod --version || echo "MongoDB binary available"
          pixi run redis-server --version || echo "Redis binary available"
          pixi run minio --version || echo "MinIO binary available"
          echo "‚úÖ All infrastructure binaries available via pixi"

  docker-build:
    needs: [check-quality-cache, quality]
    # Run if quality passed OR if it was skipped due to cache hit
    if: |
      always() &&
      (needs.quality.result == 'success' ||
       (needs.quality.result == 'skipped' && needs.check-quality-cache.outputs.cache-hit == 'true'))
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: write
      id-token: write
    outputs:
      image-tag: ${{ steps.image-info.outputs.tag }}
      image-digest: ${{ steps.build.outputs.digest }}
      rebuild-needed: ${{ steps.check-rebuild.outputs.rebuild }}
      full-image: ${{ steps.image-info.outputs.full-image }}
    steps:
      - uses: actions/checkout@v4

      - name: Configure Docker Permissions
        run: |
          sudo usermod -aG docker $USER || true
          sudo chmod 666 /var/run/docker.sock

      - name: Export UID and GID
        run: |
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV

      - name: Setup directories
        run: |
          cp .env.example .env
          mkdir -p depictioDB minio_data
          chmod 777 depictioDB minio_data

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        if: env.ACT != 'true' # Skip login when using act
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Generate image info
        id: image-info
        run: |
          REPO_LOWER=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            TAG="pr-${{ github.event.number }}-${{ github.sha }}"
          else
            TAG="main-${{ github.sha }}"
          fi
          echo "tag=${TAG}" >> $GITHUB_OUTPUT
          echo "repo=${REPO_LOWER}" >> $GITHUB_OUTPUT
          echo "full-image=ghcr.io/${REPO_LOWER}:${TAG}" >> $GITHUB_OUTPUT

      - name: Check if rebuild needed
        id: check-rebuild
        run: |
          FULL_IMAGE="${{ steps.image-info.outputs.full-image }}"
          if docker manifest inspect "${FULL_IMAGE}" > /dev/null 2>&1; then
            echo "rebuild=false" >> $GITHUB_OUTPUT
            echo "‚úÖ Image ${FULL_IMAGE} already exists, skipping build"
          else
            echo "rebuild=true" >> $GITHUB_OUTPUT
            echo "üî® Image doesn't exist, will build ${FULL_IMAGE}"
          fi

      # Detect if running with act and set cache type accordingly
      - name: Set cache strategy
        id: cache-strategy
        run: |
          if [ "${ACT:-false}" = "true" ]; then
            echo "Running with act - using local cache"
            echo "cache_from=type=local,src=/tmp/buildx-cache" >> $GITHUB_OUTPUT
            echo "cache_to=type=local,dest=/tmp/buildx-cache-new,mode=max" >> $GITHUB_OUTPUT
            echo "cache_enabled=local" >> $GITHUB_OUTPUT
          else
            echo "Running on GitHub Actions - using GHA cache"
            echo "cache_from=type=gha,scope=${{ github.ref_name }}" >> $GITHUB_OUTPUT
            echo "cache_to=type=gha,mode=max,scope=${{ github.ref_name }}" >> $GITHUB_OUTPUT
            echo "cache_enabled=gha" >> $GITHUB_OUTPUT
          fi

      # Create cache directory for act
      - name: Prepare local cache directory (act only)
        if: env.ACT == 'true' || runner.os == 'act'
        run: |
          mkdir -p /tmp/buildx-cache
          echo "Created local cache directory for act"

      - name: Build and push Docker image
        id: build
        if: steps.check-rebuild.outputs.rebuild == 'true'
        uses: docker/build-push-action@v6
        with:
          context: .
          # Use uv-based Dockerfile for faster builds (pure Python, no conda)
          file: docker-images/Dockerfile_depictio_uv.dockerfile
          platforms: linux/amd64
          push: ${{ env.ACT != 'true' }} # Push to registry unless using act
          load: ${{ env.ACT == 'true' }} # Load locally only when using act
          tags: ${{ steps.image-info.outputs.full-image }}
          cache-from: |
            ${{ steps.cache-strategy.outputs.cache_from }}
            ${{ env.ACT != 'true' && 'type=gha,scope=refs/heads/main' || '' }}
          cache-to: ${{ steps.cache-strategy.outputs.cache_to }}

      # Move cache for next run (act only)
      - name: Move cache (act only)
        if: (env.ACT == 'true' || runner.os == 'act') && steps.check-rebuild.outputs.rebuild == 'true'
        run: |
          rm -rf /tmp/buildx-cache
          mv /tmp/buildx-cache-new /tmp/buildx-cache || true

      - name: Pull image if it exists in registry (GitHub Actions only)
        if: env.ACT != 'true' && steps.check-rebuild.outputs.rebuild == 'false'
        run: |
          echo "üì• Image already exists in registry, pulling..."
          docker pull "${{ steps.image-info.outputs.full-image }}"

      - name: Pull newly built image (GitHub Actions only)
        if: env.ACT != 'true' && steps.check-rebuild.outputs.rebuild == 'true'
        run: docker pull "${{ steps.image-info.outputs.full-image }}"

      - name: Tag image for local use (act only)
        if: env.ACT == 'true' || runner.os == 'act'
        run: |
          # When using act, tag the built image with the expected name
          docker tag "${{ steps.image-info.outputs.full-image }}" depictio:local || true
          echo "Tagged image for local use"

  docker-system-init:
    needs: docker-build
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    outputs:
      services-ready: ${{ steps.health.outputs.ready }}
    steps:
      - uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Configure Docker and directories
        run: |
          sudo usermod -aG docker $USER || true
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          mkdir -p depictioDB minio_data prof_files cache
          chmod 777 depictioDB minio_data prof_files cache

      - name: Start services
        run: |
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d

      - name: Logs
        run: sleep 3 && docker compose logs

      - name: Logs depictio-frontend (early check)
        run: |
          echo "üìã Frontend container logs (early check):"
          docker compose logs depictio-frontend || echo "Failed to get frontend logs"

      - name: Check frontend container status
        run: |
          echo "üîç Checking if depictio-frontend is running..."
          docker compose ps depictio-frontend

          echo ""
          echo "üîç Container detailed status:"
          docker inspect depictio-frontend --format='Status: {{.State.Status}}, Running: {{.State.Running}}, ExitCode: {{.State.ExitCode}}, Restarting: {{.State.Restarting}}'

          echo ""
          echo "üîç Container restart count:"
          docker inspect depictio-frontend --format='RestartCount: {{.RestartCount}}'

          if ! docker compose ps depictio-frontend | grep -q "Up"; then
            echo "‚ùå Frontend container is not running!"
            echo "üìã Frontend logs:"
            docker compose logs depictio-frontend
            exit 1
          fi
          echo "‚úÖ Frontend container is running"

      - name: Debug Docker networking and frontend startup
        run: |
          echo "üîç Docker Network Debugging"
          echo "üìä List all networks:"
          docker network ls

          echo ""
          echo "üìä Frontend container network:"
          docker inspect depictio-frontend --format='{{range $net, $conf := .NetworkSettings.Networks}}{{$net}} {{end}}'

          echo ""
          echo "üìä Backend container network:"
          docker inspect depictio-backend --format='{{range $net, $conf := .NetworkSettings.Networks}}{{$net}} {{end}}'

          echo ""
          echo "üîç Test DNS resolution from backend to frontend:"
          docker compose exec -T depictio-backend sh -c "getent hosts depictio-frontend || echo 'DNS resolution failed'"

          echo ""
          echo "üîç Test connectivity from backend to frontend:"
          docker compose exec -T depictio-backend sh -c "curl -v --max-time 5 http://depictio-frontend:5080/ || echo 'Connection failed'"

          echo ""
          echo "üîç Frontend container details:"
          echo "Container is running: $(docker inspect depictio-frontend --format='{{.State.Running}}')"
          echo "Container exit code: $(docker inspect depictio-frontend --format='{{.State.ExitCode}}')"

          echo ""
          echo "üîç Check if Dash is listening on port 5080:"
          docker compose exec -T depictio-frontend sh -c "netstat -tlnp 2>/dev/null | grep 5080 || echo 'Port 5080 not listening'"

          echo ""
          echo "üìã Full frontend logs (ALL):"
          docker compose logs depictio-frontend

          echo ""
          echo "üîç Check running processes in frontend:"
          docker compose exec -T depictio-frontend sh -c "ps aux | grep -E 'dash|python|gunicorn' || echo 'No Python processes found'"

          echo ""
          echo "üîç Check startup script and environment:"
          docker compose exec -T depictio-frontend sh -c "echo 'Working directory:' && pwd"
          docker compose exec -T depictio-frontend sh -c "echo 'DEPICTIO_DEV_MODE=' && echo \$DEPICTIO_DEV_MODE"
          docker compose exec -T depictio-frontend sh -c "echo 'Script executable:' && ls -la /app/run_dash.sh"
          docker compose exec -T depictio-frontend sh -c "echo 'Python available:' && which python || echo 'Python not found'"
          docker compose exec -T depictio-frontend sh -c "echo 'Files in /app:' && ls -la /app/ | head -20"

          echo ""
          echo "üîç Manually run startup script to see errors:"
          docker compose exec -T depictio-frontend bash -c "cd /app && bash -x /app/run_dash.sh" || echo "Script failed with exit code: $?"

      - name: Logs depictio-backend
        run: sleep 3 && docker compose logs depictio-backend

      - name: Final frontend logs check
        if: always()
        run: |
          echo "üìã Final frontend container logs (complete):"
          docker compose logs depictio-frontend

      - name: Wait and verify services
        id: health
        run: |
          echo "‚è≥ Waiting for services..."
          sleep 15
          docker compose ps

          # Extract token and health check
          for i in {1..5}; do
            if token=$(docker compose exec depictio-backend bash -c "cat /app/depictio/.depictio/admin_config.yaml" 2>/dev/null | grep 'access_token' | awk '{print $2}'); then
              token=$(echo $token | tr -d "'\"")
              health_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/utils/status)
              if [ "$health_check" = "200" ]; then
                echo "‚úÖ Services ready"
                echo "ready=true" >> $GITHUB_OUTPUT
                exit 0
              fi
            fi
            echo "‚ö†Ô∏è Services not ready, attempt $i/5"
            sleep 10
          done
          echo "‚ùå Services failed to start"
          docker compose logs
          exit 1

      - name: Verify users and initial data
        run: |
          # Verify admin user
          ADMIN_USER=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.users.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.email == "admin@example.com" and .is_admin == true) | .email')
          [ -z "$ADMIN_USER" ] && echo "‚ùå Admin user not found" && exit 1

          # Verify test user
          TEST_USER=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.users.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.email == "test_user@example.com" and .is_admin == false) | .email')
          [ -z "$TEST_USER" ] && echo "‚ùå Test user not found" && exit 1

          echo "‚úÖ Users verified: $ADMIN_USER, $TEST_USER"

      - name: Verify Iris integration from system initialization
        run: |
          # Verify project
          IRIS_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | .name')
          [ -z "$IRIS_PROJECT" ] && echo "‚ùå Iris project not found" && exit 1

          # Verify deltatable
          IRIS_DC_ID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | .workflows[0].data_collections[0]._id')
          IRIS_DT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$IRIS_DC_ID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$IRIS_DT" ] && echo "‚ùå Iris deltatable not found" && exit 1

          # Verify dashboard
          IRIS_PID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | ._id')
          IRIS_DASH=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.dashboards.find({\"project_id\": ObjectId(\"$IRIS_PID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$IRIS_DASH" ] && echo "‚ùå Iris dashboard not found" && exit 1

          echo "‚úÖ Iris integration verified: Project=$IRIS_PROJECT, DT=$IRIS_DT, Dashboard=$IRIS_DASH"

      - name: Test Screenshot Generation - screenshot-dash-fixed
        run: |
          echo "üì∏ Testing screenshot generation functionality..."

          # Wait for services to be ready
          echo "‚è≥ Waiting for services to be ready..."
          for i in {1..30}; do
            if curl -s http://localhost:8058/depictio/api/v1/utils/status >/dev/null 2>&1; then
              echo "‚úÖ Backend API is ready"
              break
            fi
            echo "‚ö†Ô∏è Backend not ready, attempt $i/30"
            sleep 10
          done

          # Test screenshot endpoint with actual Iris dashboard ID
          echo "üß™ Testing screenshot generation endpoint..."

          # Get the actual Iris dashboard ID from the database
          IRIS_PID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | ._id')
          DASHBOARD_ID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.dashboards.find({\"project_id\": ObjectId(\"$IRIS_PID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')

          if [ -z "$DASHBOARD_ID" ]; then
            echo "‚ùå No dashboard found for testing - skipping screenshot test"
            echo "‚úÖ Screenshot endpoint test skipped (no dashboard available)"
            exit 0
          fi

          echo "üìã Using dashboard ID: $DASHBOARD_ID"

          # Debug: Check container status and logs before screenshot
          echo "üîç Pre-screenshot debugging:"
          echo "üìä Container status:"
          docker compose ps

          echo "üìã Recent frontend logs (last 50 lines):"
          docker compose logs --tail=50 depictio-frontend || echo "Failed to get frontend logs"

          echo "üìã Recent backend logs (last 20 lines):"
          docker compose logs --tail=20 depictio-backend || echo "Failed to get backend logs"

          echo "üåê Testing basic API connectivity:"
          curl -s -o /dev/null -w "Status: %{http_code}, Time: %{time_total}s\n" http://localhost:8058/depictio/api/v1/utils/status || echo "API connectivity test failed"

          echo "üåê Testing frontend accessibility:"
          curl -s -o /dev/null -w "Frontend Status: %{http_code}, Time: %{time_total}s\n" http://localhost:5080/ || echo "Frontend connectivity test failed"

          # Make the API call and capture response with timeout
          SCREENSHOT_RESPONSE=$(timeout 60s curl -s -w "\n%{http_code}" http://localhost:8058/depictio/api/v1/utils/screenshot-dash-fixed/$DASHBOARD_ID || echo -e "\nTIMEOUT")
          # SCREENSHOT_RESPONSE=$(curl -s -w "\n%{http_code}" http://localhost:8058/depictio/api/v1/dashboards/screenshot/$DASHBOARD_ID)

          # Extract HTTP status code (last line)
          HTTP_CODE=$(echo "$SCREENSHOT_RESPONSE" | tail -n1)

          # Extract JSON response (all lines except last)
          JSON_RESPONSE=$(echo "$SCREENSHOT_RESPONSE" | head -n -1)

          echo "üìä HTTP Status: $HTTP_CODE"

          # Debug: Check logs after screenshot attempt
          echo "üîç Post-screenshot debugging:"
          echo "üìã Recent backend logs (last 30 lines after screenshot):"
          docker compose logs --tail=30 depictio-backend || echo "Failed to get backend logs"

          echo "üìä All container status after screenshot:"
          docker compose ps

          # Handle timeout case
          if [ "$HTTP_CODE" = "TIMEOUT" ]; then
            echo "‚ö†Ô∏è Screenshot generation timed out after 60 seconds"
            echo "üìã Backend logs during timeout (last 50 lines):"
            docker compose logs --tail=50 depictio-backend || echo "Failed to get timeout logs"
            echo "‚úÖ Screenshot endpoint is accessible but slow - this may be expected in CI environment"
            exit 0
          elif [ "$HTTP_CODE" = "200" ]; then
            echo "‚úÖ Screenshot endpoint responded successfully"

            # Parse and check response without logging sensitive data
            SUCCESS=$(echo "$JSON_RESPONSE" | jq -r '.success // false' 2>/dev/null)
            MESSAGE=$(echo "$JSON_RESPONSE" | jq -r '.message // "unknown"' 2>/dev/null)
            SCREENSHOT_PATH=$(echo "$JSON_RESPONSE" | jq -r '.screenshot_path // "unknown"' 2>/dev/null)
            URL=$(echo "$JSON_RESPONSE" | jq -r '.url // "unknown"' 2>/dev/null)

            echo "üìã Response details:"
            echo "  Success: $SUCCESS"
            echo "  Message: $MESSAGE"
            echo "  Screenshot path: $SCREENSHOT_PATH"
            echo "  URL: $URL"


            if [ "$SUCCESS" = "true" ]; then
              echo "‚úÖ Screenshot generation successful"

              # Additional verification - check if screenshot path is valid
              if [[ "$SCREENSHOT_PATH" == *".png" ]]; then
                echo "‚úÖ Screenshot path format is valid"
              else
                echo "‚ö†Ô∏è  Screenshot path format may be invalid"
              fi

              # Optional: Verify screenshot file exists in container
              echo "üß™ Checking if screenshot file exists in backend container..."
              if docker compose exec -T depictio-backend test -f "$SCREENSHOT_PATH" 2>/dev/null; then
                echo "‚úÖ Screenshot file exists in backend container"
              else
                echo "‚ö†Ô∏è  Screenshot file not found in backend container (may be normal depending on setup)"
              fi

            else
              echo "‚ùå Screenshot generation failed"
              exit 1
            fi

          elif [ "$HTTP_CODE" = "404" ]; then
            echo "‚ö†Ô∏è  Dashboard not found (expected for dummy ID) - testing endpoint availability only"
            echo "‚úÖ Screenshot endpoint is accessible"
          else
            echo "‚ùå Screenshot endpoint failed with status: $HTTP_CODE"
            echo "Response: $JSON_RESPONSE"
            echo "üìã Backend logs on failure (last 50 lines):"
            docker compose logs --tail=50 depictio-backend || echo "Failed to get failure logs"
            echo "üîç Full container logs on failure:"
            docker compose logs depictio-backend || echo "Failed to get full logs"
            exit 1
          fi

          # Final debug: Show summary logs
          echo "üîç Final debugging summary:"
          echo "üìä Final container status:"
          docker compose ps

  cli-iris-single-file-test:
    needs: [docker-build]
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"
          cache-dependency-path: "pyproject.toml"

      - name: Setup environment
        run: |
          # Reuse setup from docker-system-init
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          mkdir -p depictioDB minio_data prof_files cache
          chmod 777 depictioDB minio_data prof_files cache

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d
          sleep 15

      - name: Setup CLI
        run: |
          cd depictio/cli
          uv venv --python 3.12.9 venv
          source venv/bin/activate
          uv pip install -e .
          docker cp depictio-backend:/app/depictio/.depictio/admin_config.yaml .

      - name: Run Iris CLI operations
        run: |
          cd depictio/cli
          source venv/bin/activate

          # Validate project config
          depictio-cli --verbose config validate-project-config \
            --project-config-path ../api/v1/configs/iris_dataset/initial_project_cli.yaml \
            --CLI-config-path admin_config.yaml

          # Sync project to server
          depictio-cli --verbose config sync-project-config-to-server \
            --update \
            --project-config-path ../api/v1/configs/iris_dataset/initial_project_cli.yaml \
            --CLI-config-path admin_config.yaml

          # Scan and process data
          depictio-cli --verbose data scan \
            --sync-files --rescan-folders \
            --project-config-path ../api/v1/configs/iris_dataset/initial_project_cli.yaml \
            --CLI-config-path admin_config.yaml

          depictio-cli --verbose data process \
            --overwrite \
            --project-config-path ../api/v1/configs/iris_dataset/initial_project_cli.yaml \
            --CLI-config-path admin_config.yaml

      - name: Verify Iris integration from CLI
        run: |
          # Verify project
          IRIS_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis CLI") | .name')
          [ -z "$IRIS_PROJECT" ] && echo "‚ùå Iris project not found" && exit 1

          # Verify deltatable
          IRIS_DC_ID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis CLI") | .workflows[0].data_collections[0]._id')
          IRIS_DT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$IRIS_DC_ID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$IRIS_DT" ] && echo "‚ùå Iris deltatable not found" && exit 1


          echo "‚úÖ Iris integration verified: Project=$IRIS_PROJECT, DT=$IRIS_DT"

      - name: Upload logs on failure
        if: failure()
        run: |
          docker compose logs > iris-logs.txt
        continue-on-error: true

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: iris-integration-logs
          path: iris-logs.txt
          retention-days: 7

  cli-penguin-multi-file-test:
    needs: [docker-build]
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"
          cache-dependency-path: "pyproject.toml"

      - name: Setup environment
        run: |
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          mkdir -p depictioDB minio_data prof_files cache
          chmod 777 depictioDB minio_data prof_files cache

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d
          sleep 15

      - name: Setup CLI
        run: |
          cd depictio/cli
          uv venv --python 3.12.9 venv
          source venv/bin/activate
          uv pip install -e .
          docker cp depictio-backend:/app/depictio/.depictio/admin_config.yaml .

      - name: Run Penguin CLI operations
        run: |
          cd depictio/cli
          source venv/bin/activate

          # Validate project config
          depictio-cli --verbose config validate-project-config \
            --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml \
            --CLI-config-path admin_config.yaml

          # Sync project to server
          depictio-cli --verbose config sync-project-config-to-server \
            --update \
            --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml \
            --CLI-config-path admin_config.yaml

          # Scan and process data
          depictio-cli --verbose data scan \
            --sync-files --rescan-folders \
            --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml \
            --CLI-config-path admin_config.yaml

          depictio-cli --verbose data process \
            --overwrite \
            --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml \
            --CLI-config-path admin_config.yaml

          # Test full pipeline run
          sed -i 's/name: "Palmer Penguins Species Comparison"/name: "Palmer Penguins Species Comparison - RUN"/g' ../api/v1/configs/penguins_dataset/penguins_project.yaml
          depictio-cli run \
            --CLI-config-path admin_config.yaml \
            --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml

      - name: Verify Penguin integration
        run: |
          # Verify original project
          PENGUIN_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Palmer Penguins Species Comparison") | .name')
          [ -z "$PENGUIN_PROJECT" ] && echo "‚ùå Penguin project not found" && exit 1

          # Verify run project
          PENGUIN_RUN_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Palmer Penguins Species Comparison - RUN") | .name')
          [ -z "$PENGUIN_RUN_PROJECT" ] && echo "‚ùå Penguin run project not found" && exit 1

          # Verify deltatables for run project
          PENGUIN_DC1=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Palmer Penguins Species Comparison - RUN") | .workflows[0].data_collections[0]._id')
          PENGUIN_DT1=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$PENGUIN_DC1\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$PENGUIN_DT1" ] && echo "‚ùå Penguin deltatable 1 not found" && exit 1

          echo "‚úÖ Penguin integration verified: Project=$PENGUIN_PROJECT, Run=$PENGUIN_RUN_PROJECT, DT1=$PENGUIN_DT1"

      - name: Upload logs on failure
        if: failure()
        run: |
          docker compose logs > penguin-logs.txt
        continue-on-error: true

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: penguin-integration-logs
          path: penguin-logs.txt
          retention-days: 7

  backup-s3-strategies-comprehensive-tests:
    needs: [docker-build]
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    strategy:
      fail-fast: false
      matrix:
        backup_strategy: [local, s3_to_s3, both]
        include:
          - backup_strategy: local
            strategy_name: "S3 to Local"
            s3_enabled: false
            expected_local_files: true
            expected_s3_files: false
          - backup_strategy: s3_to_s3
            strategy_name: "S3 to S3"
            s3_enabled: true
            expected_local_files: false
            expected_s3_files: true
          - backup_strategy: both
            strategy_name: "S3 to Both"
            s3_enabled: true
            expected_local_files: true
            expected_s3_files: true
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"
          cache-dependency-path: "pyproject.toml"

      - name: Setup environment for ${{ matrix.strategy_name }}
        run: |
          echo "üîß Setting up environment for ${{ matrix.strategy_name }} backup strategy..."
          echo "üê≥ Docker permissions and user setup..."
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          echo "UID: $(id -u), GID: $(id -g)"

          echo "üìÅ Creating environment files..."
          # Create root .env for Docker Compose variables
          cp .env.example .env
          echo "‚úÖ Root .env file created"

          # Copy to docker-compose/.env for application variables
          cp .env.example docker-compose/.env
          echo "‚úÖ docker-compose/.env file created"

          echo "‚öôÔ∏è Configuring backup strategy in docker-compose/.env file..."
          # Remove any existing backup configuration first
          sed -i '/^DEPICTIO_BACKUP_/d' docker-compose/.env || echo "No existing backup config to remove"

          echo "" >> docker-compose/.env
          echo "# === BACKUP STRATEGY CONFIGURATION FOR CI ===" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_S3_BACKUP_STRATEGY=${{ matrix.backup_strategy }}" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_ENABLED=${{ matrix.s3_enabled }}" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_BUCKET=depictio-backup-bucket" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_ENDPOINT_URL=http://minio-backup:9000" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_REGION=us-east-1" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_ACCESS_KEY=backup_minio" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_SECRET_KEY=backup_minio123" >> docker-compose/.env

          echo "üìã Complete backup configuration for ${{ matrix.strategy_name }}:"
          grep "DEPICTIO_BACKUP" docker-compose/.env || echo "‚ùå No DEPICTIO_BACKUP vars found!"

          echo "üìÇ Creating required directories..."
          mkdir -p depictioDB minio_data minio_backup_data
          chmod 777 depictioDB minio_data minio_backup_data
          # Ensure MongoDB can create additional directories
          chmod -R 777 depictioDB 2>/dev/null || echo "Directory permissions already set"
          ls -la depictioDB minio_data minio_backup_data
          echo "‚úÖ Directories created and permissions set"

      - name: Log in and start services for ${{ matrix.strategy_name }}
        run: |
          echo "üöÄ Starting services for ${{ matrix.strategy_name }} backup strategy..."

          echo "üîê Logging into container registry..."
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin

          echo "üê≥ Setting up Docker image..."
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          echo "Using image: $FULL_IMAGE"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          echo "DEPICTIO_VERSION set to: $DEPICTIO_VERSION"

          echo "üìã Final environment file content before starting services:"
          echo "=== ALL DEPICTIO_BACKUP VARIABLES ==="
          grep "DEPICTIO_BACKUP" docker-compose/.env || echo "‚ùå No DEPICTIO_BACKUP vars found!"
          echo "=== SAMPLE OF OTHER ENVIRONMENT VARIABLES ==="
          head -10 docker-compose/.env
          echo "=================================="

          echo "üê≥ Starting Docker Compose services..."
          echo "Compose files: docker-compose.dev.yaml + docker-compose.minio.yaml + docker-compose.backup-minio.yaml"
          echo "Environment file: docker-compose/.env"

          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml -f docker-compose/docker-compose.backup-minio.yaml up -d --force-recreate

          echo "‚è≥ Waiting 30 seconds for services to start..."
          sleep 30

          echo "üìä Verifying services are running..."
          docker compose ps

          echo "üîç Checking individual container status..."
          echo "--- Depictio Backend ---"
          docker compose logs --tail=10 depictio-backend || echo "‚ùå Backend logs not available"
          echo "--- Main MinIO ---"
          docker compose logs --tail=5 minio || echo "‚ùå MinIO logs not available"
          echo "--- Backup MinIO ---"
          docker compose logs --tail=5 minio-backup || echo "‚ùå Backup MinIO logs not available"
          echo "--- MongoDB ---"
          docker compose logs --tail=10 mongo || echo "‚ùå MongoDB logs not available"

          # Wait for backup MinIO to be ready and create bucket
          echo "‚è≥ Waiting for backup MinIO to be ready..."
          sleep 10

          echo "üîß Testing backup MinIO connectivity and creating bucket..."
          docker compose exec -T depictio-backend python3 -c "
          import boto3
          import time
          from botocore.exceptions import ClientError

          print('üîç Attempting to connect to backup MinIO...')
          print('Endpoint: http://minio-backup:9000')
          print('Access Key: backup_minio')
          print('Secret Key: backup_minio123')

          # Wait for backup MinIO to be ready
          for i in range(30):
              try:
                  client = boto3.client('s3',
                      endpoint_url='http://minio-backup:9000',
                      aws_access_key_id='backup_minio',
                      aws_secret_access_key='backup_minio123',
                      region_name='us-east-1')
                  response = client.list_buckets()
                  print(f'‚úÖ Backup MinIO ready after {i+1} attempts')
                  print(f'üìã Current buckets: {[b[\"Name\"] for b in response.get(\"Buckets\", [])]}')
                  break
              except Exception as e:
                  print(f'‚ö†Ô∏è Backup MinIO not ready (attempt {i+1}/30): {e}')
                  if i < 5:  # Show detailed error for first few attempts
                      import traceback
                      traceback.print_exc()
                  time.sleep(2)
          else:
              print('‚ùå Backup MinIO failed to start after 30 attempts')
              print('üîç Final connection attempt with full error details:')
              try:
                  client = boto3.client('s3',
                      endpoint_url='http://minio-backup:9000',
                      aws_access_key_id='backup_minio',
                      aws_secret_access_key='backup_minio123',
                      region_name='us-east-1')
                  client.list_buckets()
              except Exception as final_e:
                  import traceback
                  traceback.print_exc()
              exit(1)

          # Create backup bucket
          print('ü™£ Creating backup bucket...')
          try:
              client.create_bucket(Bucket='depictio-backup-bucket')
              print('‚úÖ Backup bucket created successfully')
          except ClientError as e:
              if e.response['Error']['Code'] == 'BucketAlreadyOwnedByYou':
                  print('‚úÖ Backup bucket already exists')
              else:
                  print(f'‚ùå Failed to create backup bucket: {e}')
                  exit(1)

          # Final verification
          final_buckets = client.list_buckets()
          print(f'üìã Final bucket list: {[b[\"Name\"] for b in final_buckets.get(\"Buckets\", [])]}')
          "

          echo "‚úÖ Services started for ${{ matrix.strategy_name }} strategy"

      - name: Setup CLI for ${{ matrix.strategy_name }}
        run: |
          echo "üîß Setting up CLI for ${{ matrix.strategy_name }} testing..."

          echo "üìÅ Navigating to CLI directory..."
          cd depictio/cli

          echo "üêç Creating Python virtual environment..."
          uv venv --python 3.11 venv
          source venv/bin/activate
          echo "Python version: $(python --version)"
          echo "Pip version: $(pip --version)"

          echo "üì¶ Installing CLI dependencies..."
          uv pip install --upgrade pip
          uv pip install -e .
          echo "‚úÖ CLI dependencies installed"

          echo "üîë Copying admin configuration from backend container..."
          docker cp depictio-backend:/app/depictio/.depictio/admin_config.yaml .
          echo "üìã Admin config file copied, checking contents..."
          ls -la admin_config.yaml
          head -5 admin_config.yaml | grep -v "token" || echo "Config file structure check"

          echo "‚úÖ CLI setup completed for ${{ matrix.strategy_name }}"

      - name: Wait for system initialization - ${{ matrix.strategy_name }}
        run: |
          echo "‚è≥ Waiting for system initialization for ${{ matrix.strategy_name }}..."

          echo "üîë Extracting authentication token for health checks..."
          # Verify system is ready
          for i in {1..10}; do
            echo "üîç Health check attempt $i/10..."

            if token=$(docker compose exec depictio-backend bash -c "cat /app/depictio/.depictio/admin_config.yaml" 2>/dev/null | grep 'access_token' | awk '{print $2}'); then
              token=$(echo $token | tr -d "'\"")
              echo "‚úÖ Token extracted successfully (length: ${#token})"

              echo "üåê Testing API health endpoint..."
              health_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/utils/status)
              echo "üìä Health check response: HTTP $health_check"

              if [ "$health_check" = "200" ]; then
                echo "‚úÖ System ready for ${{ matrix.strategy_name }}"

                echo "üîç Testing additional API endpoints..."
                # Test projects endpoint
                projects_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/projects/get/all)
                echo "üìä Projects endpoint: HTTP $projects_check"

                # Test backup endpoint
                backup_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/backup/list)
                echo "üìä Backup endpoint: HTTP $backup_check"

                break
              else
                echo "‚ö†Ô∏è Health check failed with HTTP $health_check"
              fi
            else
              echo "‚ùå Failed to extract token from admin config"
            fi

            echo "‚ö†Ô∏è System not ready for ${{ matrix.strategy_name }}, attempt $i/10"
            echo "üîç Backend container logs (last 5 lines):"
            docker compose logs --tail=5 depictio-backend || echo "Failed to get logs"
            sleep 15
          done

          echo "‚è≥ Additional stabilization period..."
          sleep 30

          echo "üìä Final container status before backup testing:"
          docker compose ps

      - name: Create backup with ${{ matrix.strategy_name }} strategy
        run: |
          echo "üíæ Creating backup with ${{ matrix.strategy_name }} strategy..."
          cd depictio/cli
          source venv/bin/activate

          # Show current backup configuration from backend
          echo "üìã Checking backend configuration and database state..."

          echo "üîç Checking environment variables in backend container..."
          docker compose exec -T depictio-backend bash -c "env | grep DEPICTIO_BACKUP || echo 'No DEPICTIO_BACKUP env vars found'"

          echo "üìã Backend backup configuration:"
          docker compose exec -T depictio-backend python3 -c "
          import os;
          print('=== ENVIRONMENT VARIABLES ===');
          for key, value in os.environ.items():
              if 'DEPICTIO_BACKUP' in key:
                  print(f'{key}={value}');
          print('=== LOADED SETTINGS ===');
          from depictio.api.v1.configs.config import settings;
          print(f'Backup Strategy: {settings.backup.s3_backup_strategy}');
          print(f'Backup S3 Enabled: {settings.backup.backup_s3_enabled}');
          print(f'Backup S3 Bucket: {settings.backup.backup_s3_bucket}');
          print(f'Backup S3 Endpoint: {settings.backup.backup_s3_endpoint_url}');
          print(f'S3 Local Backup Path: {settings.backup.s3_local_backup_path}');
          print(f'Compress Local Backups: {settings.backup.compress_local_backups}');

          print('\n=== SOURCE S3 CONFIGURATION ===');
          print(f'Source MinIO Bucket: {settings.minio.bucket}');
          print(f'Source MinIO Endpoint: {settings.minio.endpoint_url}');

          # Test connectivity to both MinIO instances
          import boto3;
          print('\n=== CONNECTIVITY TESTS ===');

          # Test source MinIO
          try:
              source_client = boto3.client('s3',
                  endpoint_url=settings.minio.endpoint_url,
                  aws_access_key_id=settings.minio.aws_access_key_id,
                  aws_secret_access_key=settings.minio.aws_secret_access_key,
                  region_name='us-east-1');
              source_buckets = source_client.list_buckets();
              print(f'‚úÖ Source MinIO accessible, buckets: {[b[\"Name\"] for b in source_buckets.get(\"Buckets\", [])]}');

              # Check if source bucket has any deltatable data
              if settings.minio.bucket in [b[\"Name\"] for b in source_buckets.get(\"Buckets\", [])]:
                  objects = source_client.list_objects_v2(Bucket=settings.minio.bucket);
                  object_count = len(objects.get('Contents', []));
                  print(f'üìä Source bucket objects count: {object_count}');
                  if object_count > 0:
                      print('üìã Sample objects:');
                      for obj in objects.get('Contents', [])[:5]:
                          print(f'  - {obj[\"Key\"]} ({obj[\"Size\"]} bytes)');
              else:
                  print(f'‚ùå Source bucket {settings.minio.bucket} not found');
          except Exception as e:
              print(f'‚ùå Source MinIO not accessible: {e}');
              import traceback;
              traceback.print_exc();

          # Test backup MinIO
          try:
              backup_client = boto3.client('s3',
                  endpoint_url='http://minio-backup:9000',
                  aws_access_key_id='backup_minio',
                  aws_secret_access_key='backup_minio123',
                  region_name='us-east-1');
              backup_buckets = backup_client.list_buckets();
              print(f'‚úÖ Backup MinIO accessible, buckets: {[b[\"Name\"] for b in backup_buckets.get(\"Buckets\", [])]}');
          except Exception as e:
              print(f'‚ùå Backup MinIO not accessible: {e}');
              import traceback;
              traceback.print_exc();
          "

          echo ""
          echo "üìä Database state analysis..."

          echo "üîç Testing MongoDB connectivity..."
          docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "print('MongoDB connection test: ' + new Date())" --quiet || echo "‚ùå MongoDB query failed"

          # Show deltatable count before backup with error handling
          echo "üìä Querying deltatables collection..."
          DELTATABLE_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
          try {
            var count = db.deltatables.countDocuments({});
            print('Deltatable count: ' + count);
            print(count);
          } catch(e) {
            print('Error counting deltatables: ' + e);
            print('0');
          }" --quiet 2>&1 | tail -1)
          echo "üìä Total deltatables in database: $DELTATABLE_COUNT"

          # Show project count
          PROJECT_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
          try {
            var count = db.projects.countDocuments({});
            print('Project count: ' + count);
            print(count);
          } catch(e) {
            print('Error counting projects: ' + e);
            print('0');
          }" --quiet 2>&1 | tail -1)
          echo "üìä Total projects in database: $PROJECT_COUNT"

          # Debug database collections
          echo "üîç Available collections:"
          docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "db.listCollectionNames()" --quiet || echo "‚ùå Failed to list collections"

          if [ "$DELTATABLE_COUNT" -gt 0 ]; then
            echo "üìã Deltatable details (first 3):"
            docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
            db.deltatables.find({}).limit(3).forEach(function(doc) {
              var location = doc.delta_table_location || doc.location || 'no location';
              print('ID: ' + doc._id + ', Location: ' + location + ', Collection: ' + (doc.data_collection_id || 'no collection'));
            })" --quiet
          else
            echo "‚ö†Ô∏è  No deltatables found in database - backup will have no S3 data to process"
            echo "üîç Checking if system initialization completed..."
            docker compose logs --tail=20 depictio-backend | grep -i "iris\|init\|startup" || echo "No initialization logs found"
          fi

          # Create backup with strategy-specific prefix
          echo ""
          echo "üöÄ Starting backup creation with detailed logging..."
          echo "Command: depictio-cli -v -vl DEBUG backup create --CLI-config-path admin_config.yaml --include-s3-data --s3-backup-prefix ci_${{ matrix.backup_strategy }}_backup"
          echo "Strategy: ${{ matrix.backup_strategy }}"
          echo "Expected S3 files: ${{ matrix.expected_s3_files }}"
          echo "Expected local files: ${{ matrix.expected_local_files }}"
          echo ""

          # Set up timing
          START_TIME=$(date +%s)

          # Run backup command with full debugging
          if depictio-cli -v -vl DEBUG backup create \
            --CLI-config-path admin_config.yaml \
            --include-s3-data \
            --s3-backup-prefix "ci_${{ matrix.backup_strategy }}_backup"; then
            END_TIME=$(date +%s)
            DURATION=$((END_TIME - START_TIME))
            echo "‚úÖ Backup creation completed successfully for ${{ matrix.strategy_name }} in ${DURATION}s"
          else
            EXIT_CODE=$?
            END_TIME=$(date +%s)
            DURATION=$((END_TIME - START_TIME))
            echo "‚ùå Backup creation failed for ${{ matrix.strategy_name }} after ${DURATION}s with exit code $EXIT_CODE"

            echo "üîç Backend logs after failed backup:"
            docker compose logs --tail=30 depictio-backend

            echo "üîç CLI debug information:"
            ls -la admin_config.yaml
            echo "Environment variables:"
            env | grep DEPICTIO | head -10

            exit $EXIT_CODE
          fi

          echo ""
          echo "üìä Post-backup analysis..."

          # Check what was created after backup
          echo "üìÅ Checking backup directory structure after backup..."
          docker compose exec -T depictio-backend find /app/depictio/backups -type f -name "*" 2>/dev/null | head -10 || echo "No backup files found"

          if [ "${{ matrix.expected_local_files }}" = "true" ]; then
            echo "üìÇ Checking for local S3 backup files..."
            docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -type f -name "*" 2>/dev/null | head -5 || echo "No S3 local backup files found"
          fi

      - name: Verify S3 local backup files - ${{ matrix.strategy_name }}
        if: matrix.expected_local_files == true
        run: |
          echo "üìÅ Verifying local backup files for ${{ matrix.strategy_name }} strategy..."

          # Check if local backup files exist in the backend container
          echo "üîç Checking for local backup files in backend container..."
          echo "üìÇ Listing backup directory structure:"
          docker compose exec -T depictio-backend find /app/depictio/backups -type d -name "*" 2>/dev/null || echo "Backup directory not found, checking if it exists..."
          docker compose exec -T depictio-backend ls -la /app/depictio/backups 2>/dev/null || echo "Main backup directory doesn't exist"
          docker compose exec -T depictio-backend ls -la /app/depictio/backups/s3_data_backups 2>/dev/null || echo "S3 backup directory doesn't exist"

          # Look for backup files by checking prefix directory
          DATE=$(date +%Y%m%d)
          echo "üîç Searching for backup files with date prefix $DATE..."

          # Check for any backup files in the s3_data_backups directory with current date
          BACKUP_COUNT=$(docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "ci_${{ matrix.backup_strategy }}_backup" -type d 2>/dev/null | wc -l)
          echo "Found $BACKUP_COUNT backup prefix directories"

          if [ "$BACKUP_COUNT" -gt 0 ]; then
            echo "‚úÖ Local backup directory found for ${{ matrix.strategy_name }}"
            docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "ci_${{ matrix.backup_strategy }}_backup" -type d -exec ls -la {} \;

            # Check for actual data files inside backup directories
            FILE_COUNT=$(docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "*.parquet" -o -name "*.json" -o -name "*${DATE}*" 2>/dev/null | wc -l)
            echo "Found $FILE_COUNT actual backup files"

            if [ "$FILE_COUNT" -gt 0 ]; then
              echo "‚úÖ Local backup files verified for ${{ matrix.strategy_name }}"
              docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "*.parquet" -o -name "*.json" -o -name "*${DATE}*" 2>/dev/null | head -10
            else
              echo "‚ö†Ô∏è  Backup directory exists but no files found"
            fi
          else
            echo "‚ùå No local backup directories found for ${{ matrix.strategy_name }}"
            exit 1
          fi

      - name: Verify S3 backup files - ${{ matrix.strategy_name }}
        if: matrix.expected_s3_files == true
        run: |
          echo "‚òÅÔ∏è Verifying S3 backup files for ${{ matrix.strategy_name }} strategy..."

          # Check if backup files exist on local backup MinIO
          echo "üìã Checking S3 backup files in local backup MinIO for ${{ matrix.strategy_name }}..."
          docker compose exec -T depictio-backend python3 -c "
          import boto3;
          try:
              print('üîç Connecting to backup MinIO...');
              client = boto3.client('s3',
                  endpoint_url='http://minio-backup:9000',
                  aws_access_key_id='backup_minio',
                  aws_secret_access_key='backup_minio123',
                  region_name='us-east-1');

              # Test connection first
              print('üìã Testing backup MinIO connection...');
              buckets = client.list_buckets();
              print(f'Available buckets: {[b[\"Name\"] for b in buckets.get(\"Buckets\", [])]}');

              # List all objects in the bucket for debugging
              print('üìã Listing all objects in backup bucket...');
              all_response = client.list_objects_v2(Bucket='depictio-backup-bucket');
              all_files = all_response.get('Contents', []);
              if all_files:
                  print(f'üìä Total objects in backup bucket: {len(all_files)}');
                  for f in all_files:
                      print(f'  - {f[\"Key\"]} ({f[\"Size\"]} bytes)');
              else:
                  print('üìä No objects found in backup bucket');

              # Now check for specific prefix
              print(f'üîç Searching for files with prefix: ci_${{ matrix.backup_strategy }}_backup/');
              response = client.list_objects_v2(Bucket='depictio-backup-bucket', Prefix='ci_${{ matrix.backup_strategy }}_backup/');
              files = response.get('Contents', []);
              parquet_files = [f for f in files if f['Key'].endswith('.parquet')];
              print(f'‚úÖ ${{ matrix.strategy_name }}: Found {len(files)} total files, {len(parquet_files)} parquet files');

              # List backup files with prefix for debugging
              if files:
                  print('üìã Prefix-specific backup files found:');
                  for f in files:
                      print(f'  - {f[\"Key\"]} ({f[\"Size\"]} bytes)');

              if len(files) == 0:
                  print('‚ùå No S3 backup files found for ${{ matrix.strategy_name }}');
                  exit(1);
              else:
                  print('‚úÖ S3 backup verification successful for ${{ matrix.strategy_name }}');
          except Exception as e:
              print(f'‚ùå S3 verification failed for ${{ matrix.strategy_name }}: {e}');
              import traceback;
              traceback.print_exc();
              exit(1);
          "

      - name: Verify backup strategy behavior - ${{ matrix.strategy_name }}
        run: |
          echo "üîç Verifying ${{ matrix.strategy_name }} backup strategy behavior..."
          cd depictio/cli
          source venv/bin/activate

          # List backups and get the latest one
          BACKUP_LIST=$(depictio-cli backup list --CLI-config-path admin_config.yaml)
          echo "Available backups for ${{ matrix.strategy_name }}: $BACKUP_LIST"

          # Validate backup integrity
          BACKUP_ID=$(echo "$BACKUP_LIST" | grep -o '"backup_id": "[^"]*"' | head -1 | cut -d'"' -f4)
          echo "Using backup ID for ${{ matrix.strategy_name }}: $BACKUP_ID"

          if [ -n "$BACKUP_ID" ]; then
            depictio-cli -v -vl DEBUG backup validate "$BACKUP_ID" --CLI-config-path admin_config.yaml
            echo "‚úÖ Backup validation successful for ${{ matrix.strategy_name }}"
          else
            echo "‚ùå No backup ID found for ${{ matrix.strategy_name }}"
            exit 1
          fi

      - name: Test backup restoration - ${{ matrix.strategy_name }}
        run: |
          echo "‚ôªÔ∏è Testing backup restoration for ${{ matrix.strategy_name }}..."
          cd depictio/cli
          source venv/bin/activate

          # Drop some test data for restoration test
          docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
            var dashboardCount = db.dashboards.countDocuments({});
            print('Dashboards before deletion for ${{ matrix.strategy_name }}: ' + dashboardCount);
            if (dashboardCount > 0) {
              db.dashboards.deleteMany({});
              print('Dashboards after deletion for ${{ matrix.strategy_name }}: ' + db.dashboards.countDocuments({}));
            }
          "

          # Get backup ID and restore
          BACKUP_LIST=$(depictio-cli backup list --CLI-config-path admin_config.yaml)
          BACKUP_ID=$(echo "$BACKUP_LIST" | grep -o '"backup_id": "[^"]*"' | head -1 | cut -d'"' -f4)

          if [ -n "$BACKUP_ID" ]; then
            echo "üîÑ Performing restore test for ${{ matrix.strategy_name }}..."
            depictio-cli -v -vl DEBUG backup restore "$BACKUP_ID" \
              --CLI-config-path admin_config.yaml \
              --force

            # Verify restoration
            DASHBOARD_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "db.dashboards.countDocuments({})" --quiet)
            echo "Dashboards after restore for ${{ matrix.strategy_name }}: $DASHBOARD_COUNT"

            echo "‚úÖ Backup restoration test completed for ${{ matrix.strategy_name }}"
          else
            echo "‚ùå No backup ID found for restoration test"
            exit 1
          fi

      - name: Cleanup and summary - ${{ matrix.strategy_name }}
        run: |
          echo "üßπ Cleanup and summary for ${{ matrix.strategy_name }}..."

          # Show final status
          echo "üìä Final status for ${{ matrix.strategy_name }} backup strategy:"
          echo "- Strategy: ${{ matrix.backup_strategy }}"
          echo "- S3 Enabled: ${{ matrix.s3_enabled }}"
          echo "- Expected Local Files: ${{ matrix.expected_local_files }}"
          echo "- Expected S3 Files: ${{ matrix.expected_s3_files }}"

          # Stop services for this iteration
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml -f docker-compose/docker-compose.backup-minio.yaml down
          echo "‚úÖ ${{ matrix.strategy_name }} backup strategy test completed successfully"

      - name: Upload logs on failure
        if: failure()
        run: |
          docker compose logs > backup-${{ matrix.backup_strategy }}-logs.txt
          cd depictio/cli && ls -la >> ../backup-${{ matrix.backup_strategy }}-logs.txt
        continue-on-error: true

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: backup-${{ matrix.backup_strategy }}-logs
          path: backup-${{ matrix.backup_strategy }}-logs.txt
          retention-days: 7

  e2e-tests:
    needs: [docker-build]
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Setup environment
        run: |
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          # Enable dev mode
          sed -i 's/# DEPICTIO_DEV_MODE=false/DEPICTIO_DEV_MODE=true/' docker-compose/.env
          mkdir -p depictioDB minio_data prof_files cache
          chmod 777 depictioDB minio_data prof_files cache

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d
          sleep 15

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "16"

      - name: Install Chrome
        run: |
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Install Cypress dependencies
        run: |
          cd depictio/tests/e2e-tests
          if [ ! -f "package.json" ]; then
            npm init -y
            npm install cypress --save-dev
          else
            npm ci
          fi

      - name: Run Cypress tests
        run: |
          cd depictio/tests/e2e-tests
          export CYPRESS_UNAUTHENTICATED_MODE=false
          # Set Chrome flags for better CI rendering and stability
          export CYPRESS_BROWSER_ARGS="--disable-gpu --no-sandbox --disable-dev-shm-usage --disable-extensions --disable-background-timer-throttling --disable-renderer-backgrounding --disable-backgrounding-occluded-windows"
          # Run Chrome in headless mode for CI with improved stability
          npx cypress run \
            --browser chrome \
            --headless \
            --config screenshotsFolder=cypress/screenshots,videosFolder=cypress/videos,trashAssetsBeforeRuns=false,video=true,screenshotOnRunFailure=true,viewportWidth=1920,viewportHeight=1080,chromeWebSecurity=false \
            --spec "cypress/e2e/!(unauthenticated)/**/*.cy.js"

      - name: Upload screenshots
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cypress-screenshots
          path: depictio/tests/e2e-tests/cypress/screenshots
          retention-days: 30

      - name: Upload videos on failure
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: cypress-videos
          path: depictio/tests/e2e-tests/cypress/videos
          retention-days: 7

  e2e-tests-unauthenticated:
    needs: [docker-build]
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Setup environment
        run: |
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          # Enable unauthenticated mode
          sed -i 's/# DEPICTIO_AUTH_UNAUTHENTICATED_MODE=false/DEPICTIO_AUTH_UNAUTHENTICATED_MODE=true/' docker-compose/.env
          sed -i 's/# DEPICTIO_DEV_MODE=false/DEPICTIO_DEV_MODE=true/' docker-compose/.env
          mkdir -p depictioDB minio_data prof_files cache
          chmod 777 depictioDB minio_data prof_files cache

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml --env-file docker-compose/.env up -d
          sleep 15

      - name: Show .env files
        run: |
          echo "üìã Environment variables in docker-compose/.env:"
          cat docker-compose/.env || echo "‚ùå .env file not found"
          echo "üìã Environment variables in .env.example:"
          cat .env.example || echo "‚ùå .env.example file not found"
          echo "üìã Environment variables in .env:"
          cat .env || echo "‚ùå .env file not found"

      - name: Log backend container status
        run: |
          echo "üìä Backend container status:"
          docker compose ps depictio-backend || echo "‚ùå Backend container not running"
          docker compose logs depictio-backend || echo "‚ùå Failed to get backend logs"

      - name: Verify unauthenticated mode is enabled
        run: |
          echo "üîç Verifying unauthenticated mode configuration..."

          # Check if anonymous user was created
          for i in {1..10}; do
            ANON_USER=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.users.find({email: 'anonymous@depict.io'}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.email == "anonymous@depict.io") | .email')
            if [ -n "$ANON_USER" ]; then
              echo "‚úÖ Anonymous user found: $ANON_USER"
              break
            fi
            echo "‚ö†Ô∏è Anonymous user not found, attempt $i/10"
            sleep 5
          done
          [ -z "$ANON_USER" ] && echo "‚ùå Anonymous user not found" && exit 1

          # Verify frontend bypasses auth
          echo "üåê Testing unauthenticated access to frontend..."
          curl -s -o /dev/null -w "%{http_code}" http://localhost:5080/ | grep -q "200" && echo "‚úÖ Frontend accessible without authentication" || (echo "‚ùå Frontend not accessible" && exit 1)

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "16"

      - name: Install Cypress dependencies
        run: |
          cd depictio/tests/e2e-tests
          if [ ! -f "package.json" ]; then
            npm init -y
            npm install cypress --save-dev
          else
            npm ci
          fi

      - name: Install Chrome for unauthenticated tests
        run: |
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Run Cypress unauthenticated tests
        run: |
          cd depictio/tests/e2e-tests
          # Set environment variable for cypress to know it's unauthenticated mode
          export CYPRESS_UNAUTHENTICATED_MODE=true
          # Set Chrome flags for better CI rendering and stability
          export CYPRESS_BROWSER_ARGS="--disable-gpu --no-sandbox --disable-dev-shm-usage --disable-extensions --disable-background-timer-throttling --disable-renderer-backgrounding --disable-backgrounding-occluded-windows"
          npx cypress run \
            --browser chrome \
            --headless \
            --config screenshotsFolder=cypress/screenshots-unauthenticated,videosFolder=cypress/videos-unauthenticated,trashAssetsBeforeRuns=false,video=true,screenshotOnRunFailure=true,viewportWidth=1920,viewportHeight=1080,chromeWebSecurity=false \
            --spec "cypress/e2e/unauthenticated/**/*.cy.js"

      - name: Upload screenshots
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cypress-screenshots-unauthenticated
          path: depictio/tests/e2e-tests/cypress/screenshots-unauthenticated
          retention-days: 30

      - name: Upload videos on failure
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: cypress-videos-unauthenticated
          path: depictio/tests/e2e-tests/cypress/videos-unauthenticated
          retention-days: 7
