name: "Depictio ‚Äì Full CI: Quality, Build, Integration, E2E Tests"

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  # Smart caching for quality checks - skip tests if code hasn't changed
  # Hashes all Python files, config files, and test files to detect changes
  # If hash matches a previous successful run, quality job is skipped
  check-quality-cache:
    runs-on: ubuntu-22.04
    outputs:
      cache-hit: ${{ steps.cache-quality.outputs.cache-hit }}
      code-hash: ${{ steps.hash.outputs.hash }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history to compare with previous commit

      - name: Generate code hash
        id: hash
        run: |
          # Hash all relevant files that affect quality checks:
          # - All Python source files (*.py)
          # - Dependency configuration (pyproject.toml, uv.lock)
          # - Pre-commit hooks (.pre-commit-config.yaml)
          # - Test configuration (pytest.ini)
          # NOTE: CI workflow file is NOT included - CI changes shouldn't invalidate quality cache
          # Only hash files that actually exist (filter out deleted/missing files)
          HASH=$(git ls-files '*.py' 'pyproject.toml' 'uv.lock' '.pre-commit-config.yaml' 'pytest.ini' | \
            while read -r file; do
              if [ -f "$file" ]; then
                cat "$file"
              fi
            done | sha256sum | cut -d' ' -f1)
          echo "hash=$HASH" >> $GITHUB_OUTPUT
          echo "üìù Code hash: $HASH"

      - name: Check quality cache
        id: cache-quality
        uses: actions/cache@v4
        with:
          path: .quality-passed
          key: quality-${{ steps.hash.outputs.hash }}

      - name: Report cache status
        run: |
          if [ "${{ steps.cache-quality.outputs.cache-hit }}" == "true" ]; then
            echo "‚úÖ Quality checks passed for this code state previously - skipping"
          else
            echo "üîç No cache found - quality checks will run"
          fi

  quality:
    runs-on: ubuntu-22.04
    needs: check-quality-cache
    if: needs.check-quality-cache.outputs.cache-hit != 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"
          cache-dependency-path: "pyproject.toml"

      - name: Install Dependencies
        run: |
          uv venv --python 3.12.9 venv
          source venv/bin/activate
          uv pip install --upgrade pip

          # Install dependencies from pyproject.toml
          uv pip install -e ".[dev]"

          # Clean up any conflicting polars packages that may have been pulled in
          echo "üßπ Removing conflicting polars packages..."
          uv pip uninstall -y polars polars-runtime-32 2>/dev/null || true

          # Ensure correct polars-lts-cpu version is installed (required for MultiQC)
          echo "üì¶ Installing polars-lts-cpu 1.19.0..."
          uv pip install --force-reinstall "polars-lts-cpu[numpy,pandas,pyarrow,excel,deltalake]==1.19.0"

          # Verify only polars-lts-cpu is installed
          echo "‚úÖ Verifying polars installation..."
          uv pip list | grep -i polars
          python -c "import polars; assert '1.19' in polars.__version__, f'Wrong version: {polars.__version__}'; print(f'‚úÖ Polars {polars.__version__} verified')"

      # - name: Run Ruff for formatting
      #   run: |
      #     source venv/bin/activate
      #     ruff format depictio

      # - uses: astral-sh/ruff-action@v3
      #   with:
      #     src: depictio
      #     args: check --fix --exit-non-zero-on-fix --line-length=100
      #     version-file: pyproject.toml

      # - name: Debug environment before Ruff check
      #   run: |
      #     source venv/bin/activate
      #     echo "=== RUFF DEBUGGING INFO ==="
      #     echo "Ruff version: $(ruff --version)"
      #     echo "Working directory: $(pwd)"
      #     echo "Python path: $(which python)"
      #     echo "Python version: $(python --version)"

      #     echo "=== RUFF CONFIGURATION ==="
      #     ruff check --show-settings depictio | head -20

      #     echo "=== FILE COUNTS ==="
      #     echo "Total Python files in depictio: $(find depictio -name '*.py' | wc -l)"
      #     echo "Sample files being checked:"
      #     find depictio -name '*.py' | head -10

      #     echo "=== IMPORT VIOLATIONS CHECK ==="
      #     echo "Running import-only check to see specific violations:"
      #     ruff check depictio --select I --output-format=json | jq '.[0:5]' || echo "No import violations found or jq not available"

      #     echo "=== PRE-COMMIT RUFF VERSION ==="
      #     cat .pre-commit-config.yaml | grep -A 2 "charliermarsh/ruff-pre-commit" || echo "Pre-commit config not found"

      # - name: Run Ruff for linting
      #   run: |
      #     source venv/bin/activate
      #     ruff check depictio

      # - uses: astral-sh/ruff-action@v3
      #   with:
      #     src: depictio
      #     args: format
      #     version-file: pyproject.toml

      # - name: Run ty type checker (must pass)
      #   run: |
      #     source venv/bin/activate
      #     ty version
      #     ty check depictio/models/ depictio/api/ depictio/dash/ depictio/cli/ depictio/tests/

      # - name: Run pre-commit hooks
      #   run: |
      #     source venv/bin/activate
      #     pre-commit run --all-files

      - name: Run tests
        run: |
          source venv/bin/activate
          python -m pytest -xvs -n auto

      - name: Save quality cache marker
        if: success()
        run: |
          echo "Quality checks passed at $(date)" > .quality-passed
          echo "‚úÖ Quality cache marker created"

      - name: Update quality cache
        if: success()
        uses: actions/cache/save@v4
        with:
          path: .quality-passed
          key: quality-${{ needs.check-quality-cache.outputs.code-hash }}

  # Test pixi installation and basic functionality (no Docker required)
  pixi-install-test:
    runs-on: ubuntu-22.04
    needs: check-quality-cache
    steps:
      - uses: actions/checkout@v4

      - name: Install pixi
        uses: prefix-dev/setup-pixi@v0.9.3
        with:
          pixi-version: v0.39.5
          # Disable cache until pixi.lock is committed to the repo
          cache: false
          # Allow pixi to generate lockfile
          locked: false
          # Use temp location for pixi binary to avoid cleanup issues
          pixi-bin-path: ${{ runner.temp }}/bin/pixi
          # Enable verbose logging to debug installation issues
          log-level: vv
          # Disable automatic install so we can run it manually with better error capture
          run-install: false

      - name: Install dependencies with pixi
        run: |
          echo "üì¶ Installing dependencies with pixi..."
          echo "üîç Pixi version: $(pixi --version)"
          echo "üîç Platform: $(uname -a)"
          echo ""
          echo "üìã pixi.toml contents:"
          cat pixi.toml
          echo ""
          echo "üîç Running pixi install with verbose output..."
          # Run with maximum verbosity to see solver errors
          pixi install -vvv 2>&1 | tee /tmp/pixi-install.log || {
            echo ""
            echo "‚ùå pixi install failed!"
            echo ""
            echo "üìã Full pixi install log:"
            cat /tmp/pixi-install.log
            echo ""
            echo "üìã pyproject.toml dependencies section:"
            grep -A 100 '\[project.dependencies\]' pyproject.toml | head -80 || true
            exit 1
          }
          echo "‚úÖ Pixi installation successful"

      - name: Verify pixi environment
        run: |
          echo "üîç Verifying pixi environment..."
          pixi run python --version
          pixi run python -c 'import depictio; print("depictio package loaded successfully")'

      - name: Run quick tests (no infrastructure)
        run: |
          echo "üß™ Running quick tests without infrastructure..."
          pixi run test-fast || echo "‚ö†Ô∏è Some tests may require infrastructure - this is expected"

      - name: Verify infrastructure commands exist
        run: |
          echo "üîç Verifying infrastructure commands are available..."
          pixi run mongod --version || echo "MongoDB binary available"
          pixi run redis-server --version || echo "Redis binary available"
          pixi run minio --version || echo "MinIO binary available"
          echo "‚úÖ All infrastructure binaries available via pixi"

  docker-build:
    needs: [check-quality-cache, quality]
    # Run if quality passed OR if it was skipped due to cache hit
    if: |
      always() &&
      (needs.quality.result == 'success' ||
       (needs.quality.result == 'skipped' && needs.check-quality-cache.outputs.cache-hit == 'true'))
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: write
      id-token: write
    outputs:
      image-tag: ${{ steps.image-info.outputs.tag }}
      image-digest: ${{ steps.build.outputs.digest }}
      rebuild-needed: ${{ steps.check-rebuild.outputs.rebuild }}
      full-image: ${{ steps.image-info.outputs.full-image }}
    steps:
      - uses: actions/checkout@v4

      - name: Configure Docker Permissions
        run: |
          sudo usermod -aG docker $USER || true
          sudo chmod 666 /var/run/docker.sock

      - name: Export UID and GID
        run: |
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV

      - name: Setup directories
        run: |
          cp .env.example .env
          mkdir -p depictioDB minio_data
          chmod 777 depictioDB minio_data

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        if: env.ACT != 'true' # Skip login when using act
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Generate image info
        id: image-info
        run: |
          REPO_LOWER=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')

          # Generate content-based hash from files that affect the Docker build
          # Excludes tests/ to avoid rebuilding when only tests change
          DOCKER_HASH=$(find depictio -type f \( -name "*.py" -o -name "*.js" -o -name "*.css" -o -name "*.html" \) \
            ! -path "depictio/tests/*" | sort | xargs cat 2>/dev/null | sha256sum | cut -c1-12)
          # Also include key config files
          CONFIG_HASH=$(cat pyproject.toml uv.lock docker-images/Dockerfile_depictio_uv.dockerfile .dockerignore 2>/dev/null | sha256sum | cut -c1-12)
          CONTENT_HASH="${DOCKER_HASH}-${CONFIG_HASH}"

          if [ "${{ github.event_name }}" = "pull_request" ]; then
            TAG="pr-${{ github.event.number }}-${CONTENT_HASH}"
          else
            TAG="main-${CONTENT_HASH}"
          fi
          echo "tag=${TAG}" >> $GITHUB_OUTPUT
          echo "repo=${REPO_LOWER}" >> $GITHUB_OUTPUT
          echo "full-image=ghcr.io/${REPO_LOWER}:${TAG}" >> $GITHUB_OUTPUT
          echo "üì¶ Docker content hash: ${CONTENT_HASH}"
          echo "üè∑Ô∏è Image tag: ${TAG}"

      - name: Check if rebuild needed
        id: check-rebuild
        run: |
          FULL_IMAGE="${{ steps.image-info.outputs.full-image }}"
          if docker manifest inspect "${FULL_IMAGE}" > /dev/null 2>&1; then
            echo "rebuild=false" >> $GITHUB_OUTPUT
            echo "‚úÖ Image ${FULL_IMAGE} already exists, skipping build"
          else
            echo "rebuild=true" >> $GITHUB_OUTPUT
            echo "üî® Image doesn't exist, will build ${FULL_IMAGE}"
          fi

      # Detect if running with act and set cache type accordingly
      - name: Set cache strategy
        id: cache-strategy
        run: |
          if [ "${ACT:-false}" = "true" ]; then
            echo "Running with act - using local cache"
            echo "cache_from=type=local,src=/tmp/buildx-cache" >> $GITHUB_OUTPUT
            echo "cache_to=type=local,dest=/tmp/buildx-cache-new,mode=max" >> $GITHUB_OUTPUT
            echo "cache_enabled=local" >> $GITHUB_OUTPUT
          else
            echo "Running on GitHub Actions - using GHA cache"
            echo "cache_from=type=gha,scope=${{ github.ref_name }}" >> $GITHUB_OUTPUT
            echo "cache_to=type=gha,mode=max,scope=${{ github.ref_name }}" >> $GITHUB_OUTPUT
            echo "cache_enabled=gha" >> $GITHUB_OUTPUT
          fi

      # Create cache directory for act
      - name: Prepare local cache directory (act only)
        if: env.ACT == 'true' || runner.os == 'act'
        run: |
          mkdir -p /tmp/buildx-cache
          echo "Created local cache directory for act"

      - name: Build and push Docker image
        id: build
        if: steps.check-rebuild.outputs.rebuild == 'true'
        uses: docker/build-push-action@v6
        with:
          context: .
          # Use uv-based Dockerfile for faster builds (pure Python, no conda)
          file: docker-images/Dockerfile_depictio_uv.dockerfile
          platforms: linux/amd64
          push: ${{ env.ACT != 'true' }} # Push to registry unless using act
          load: ${{ env.ACT == 'true' }} # Load locally only when using act
          tags: ${{ steps.image-info.outputs.full-image }}
          cache-from: |
            ${{ steps.cache-strategy.outputs.cache_from }}
            ${{ env.ACT != 'true' && 'type=gha,scope=refs/heads/main' || '' }}
          cache-to: ${{ steps.cache-strategy.outputs.cache_to }}

      # Move cache for next run (act only)
      - name: Move cache (act only)
        if: (env.ACT == 'true' || runner.os == 'act') && steps.check-rebuild.outputs.rebuild == 'true'
        run: |
          rm -rf /tmp/buildx-cache
          mv /tmp/buildx-cache-new /tmp/buildx-cache || true

      - name: Pull image if it exists in registry (GitHub Actions only)
        if: env.ACT != 'true' && steps.check-rebuild.outputs.rebuild == 'false'
        run: |
          echo "üì• Image already exists in registry, pulling..."
          docker pull "${{ steps.image-info.outputs.full-image }}"

      - name: Pull newly built image (GitHub Actions only)
        if: env.ACT != 'true' && steps.check-rebuild.outputs.rebuild == 'true'
        run: docker pull "${{ steps.image-info.outputs.full-image }}"

      - name: Tag image for local use (act only)
        if: env.ACT == 'true' || runner.os == 'act'
        run: |
          # When using act, tag the built image with the expected name
          docker tag "${{ steps.image-info.outputs.full-image }}" depictio:local || true
          echo "Tagged image for local use"

  docker-system-init:
    needs: docker-build
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    outputs:
      services-ready: ${{ steps.health.outputs.ready }}
    steps:
      - uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Configure Docker and directories
        run: |
          sudo usermod -aG docker $USER || true
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          mkdir -p depictioDB minio_data prof_files cache
          chmod 777 depictioDB minio_data prof_files cache

      - name: Start services
        run: |
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          export DEPICTIO_FASTAPI_WORKERS=1  # Single worker to avoid boot race conditions
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d

      - name: Logs
        run: sleep 3 && docker compose logs

      - name: Logs depictio-frontend (early check)
        run: |
          echo "üìã Frontend container logs (early check):"
          docker compose logs depictio-frontend || echo "Failed to get frontend logs"

      - name: Check frontend container status
        run: |
          echo "üîç Checking if depictio-frontend is running..."
          docker compose ps depictio-frontend

          echo ""
          echo "üîç Container detailed status:"
          docker inspect depictio-frontend --format='Status: {{.State.Status}}, Running: {{.State.Running}}, ExitCode: {{.State.ExitCode}}, Restarting: {{.State.Restarting}}'

          echo ""
          echo "üîç Container restart count:"
          docker inspect depictio-frontend --format='RestartCount: {{.RestartCount}}'

          if ! docker compose ps depictio-frontend | grep -q "Up"; then
            echo "‚ùå Frontend container is not running!"
            echo "üìã Frontend logs:"
            docker compose logs depictio-frontend
            exit 1
          fi
          echo "‚úÖ Frontend container is running"

      - name: Debug Docker networking and frontend startup
        run: |
          echo "üîç Docker Network Debugging"
          echo "üìä List all networks:"
          docker network ls

          echo ""
          echo "üìä Frontend container network:"
          docker inspect depictio-frontend --format='{{range $net, $conf := .NetworkSettings.Networks}}{{$net}} {{end}}'

          echo ""
          echo "üìä Backend container network:"
          docker inspect depictio-backend --format='{{range $net, $conf := .NetworkSettings.Networks}}{{$net}} {{end}}'

          echo ""
          echo "üîç Test DNS resolution from backend to frontend:"
          docker compose exec -T depictio-backend sh -c "getent hosts depictio-frontend || echo 'DNS resolution failed'"

          echo ""
          echo "üîç Test connectivity from backend to frontend:"
          docker compose exec -T depictio-backend sh -c "curl -v --max-time 5 http://depictio-frontend:5080/ || echo 'Connection failed'"

          echo ""
          echo "üîç Frontend container details:"
          echo "Container is running: $(docker inspect depictio-frontend --format='{{.State.Running}}')"
          echo "Container exit code: $(docker inspect depictio-frontend --format='{{.State.ExitCode}}')"

          echo ""
          echo "üîç Check if Dash is listening on port 5080:"
          docker compose exec -T depictio-frontend sh -c "netstat -tlnp 2>/dev/null | grep 5080 || echo 'Port 5080 not listening'"

          echo ""
          echo "üìã Full frontend logs (ALL):"
          docker compose logs depictio-frontend

          echo ""
          echo "üîç Check running processes in frontend:"
          docker compose exec -T depictio-frontend sh -c "ps aux | grep -E 'dash|python|gunicorn' || echo 'No Python processes found'"

          echo ""
          echo "üîç Check startup script and environment:"
          docker compose exec -T depictio-frontend sh -c "echo 'Working directory:' && pwd"
          docker compose exec -T depictio-frontend sh -c "echo 'DEPICTIO_DEV_MODE=' && echo \$DEPICTIO_DEV_MODE"
          docker compose exec -T depictio-frontend sh -c "echo 'Script executable:' && ls -la /app/run_dash.sh"
          docker compose exec -T depictio-frontend sh -c "echo 'Python available:' && which python || echo 'Python not found'"
          docker compose exec -T depictio-frontend sh -c "echo 'Files in /app:' && ls -la /app/ | head -20"

          echo ""
          echo "üîç Manually run startup script to see errors:"
          docker compose exec -T depictio-frontend bash -c "cd /app && bash -x /app/run_dash.sh" || echo "Script failed with exit code: $?"

      - name: Logs depictio-backend
        run: sleep 3 && docker compose logs depictio-backend

      - name: Final frontend logs check
        if: always()
        run: |
          echo "üìã Final frontend container logs (complete):"
          docker compose logs depictio-frontend

      - name: Wait and verify services
        id: health
        run: |
          echo "‚è≥ Waiting for services to be ready..."

          # Wait for MongoDB
          echo "Waiting for MongoDB..."
          for i in {1..30}; do
            if docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "db.runCommand({ ping: 1 })" --quiet &>/dev/null; then
              echo "‚úÖ MongoDB ready"
              break
            fi
            echo "MongoDB not ready yet, attempt $i/30..."
            sleep 2
          done

          # Wait for Redis
          echo "Waiting for Redis..."
          for i in {1..30}; do
            if docker compose exec -T redis redis-cli ping &>/dev/null; then
              echo "‚úÖ Redis ready"
              break
            fi
            echo "Redis not ready yet, attempt $i/30..."
            sleep 2
          done

          # Wait for MinIO
          echo "Waiting for MinIO..."
          for i in {1..30}; do
            if curl -f http://localhost:9000/minio/health/ready &>/dev/null; then
              echo "‚úÖ MinIO ready"
              break
            fi
            echo "MinIO not ready yet, attempt $i/30..."
            sleep 2
          done

          # Wait for Backend API health check with restart on crash
          echo "Waiting for Backend API..."
          RESTART_COUNT=0
          MAX_RESTARTS=2
          for i in {1..60}; do
            if curl -f http://localhost:8058/health &>/dev/null; then
              echo "‚úÖ Backend API ready"
              break
            fi
            # Check if container crashed and restart if needed
            if ! docker compose ps depictio-backend | grep -q "Up"; then
              if [ $RESTART_COUNT -lt $MAX_RESTARTS ]; then
                echo "‚ö†Ô∏è  Backend container crashed, restarting (attempt $((RESTART_COUNT+1))/$MAX_RESTARTS)..."
                docker compose up -d depictio-backend
                RESTART_COUNT=$((RESTART_COUNT+1))
                sleep 5
              fi
            fi
            echo "Backend API not ready yet, attempt $i/60..."
            sleep 2
          done

          # Show final status
          echo "üîç Verifying all services..."
          docker compose ps

          # Test API health endpoint
          if ! curl -f http://localhost:8058/health; then
            echo "‚ùå Backend API health check failed"
            echo "Backend logs:"
            docker compose logs depictio-backend --tail=50
            exit 1
          fi

          echo "‚úÖ All services ready and healthy"
          echo "ready=true" >> $GITHUB_OUTPUT

      - name: Verify users and initial data
        run: |
          # Verify admin user
          ADMIN_USER=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.users.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.email == "admin@example.com" and .is_admin == true) | .email')
          [ -z "$ADMIN_USER" ] && echo "‚ùå Admin user not found" && exit 1

          # Verify test user
          TEST_USER=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.users.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.email == "test_user@example.com" and .is_admin == false) | .email')
          [ -z "$TEST_USER" ] && echo "‚ùå Test user not found" && exit 1

          echo "‚úÖ Users verified: $ADMIN_USER, $TEST_USER"

      - name: Verify Iris integration from system initialization
        run: |
          # Verify project
          IRIS_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | .name')
          [ -z "$IRIS_PROJECT" ] && echo "‚ùå Iris project not found" && exit 1

          # Verify deltatable
          IRIS_DC_ID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | .workflows[0].data_collections[0]._id')
          IRIS_DT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$IRIS_DC_ID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$IRIS_DT" ] && echo "‚ùå Iris deltatable not found" && exit 1

          # Verify dashboard
          IRIS_PID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | ._id')
          IRIS_DASH=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.dashboards.find({\"project_id\": ObjectId(\"$IRIS_PID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$IRIS_DASH" ] && echo "‚ùå Iris dashboard not found" && exit 1

          echo "‚úÖ Iris integration verified: Project=$IRIS_PROJECT, DT=$IRIS_DT, Dashboard=$IRIS_DASH"

      - name: Verify Penguins integration from system initialization
        run: |
          # Verify project
          PENGUIN_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Palmer Penguins Species Comparison") | .name')
          [ -z "$PENGUIN_PROJECT" ] && echo "‚ùå Penguins project not found" && exit 1

          # Verify deltatables (should have 2 data collections with joins)
          PENGUIN_PID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Palmer Penguins Species Comparison") | ._id')
          PENGUIN_DC_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find({\"_id\": ObjectId(\"$PENGUIN_PID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[].workflows[0].data_collections | length')
          [ "$PENGUIN_DC_COUNT" -lt 2 ] && echo "‚ùå Penguins data collections not found (expected >=2, got $PENGUIN_DC_COUNT)" && exit 1

          # Verify dashboard
          PENGUIN_DASH=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.dashboards.find({\"project_id\": ObjectId(\"$PENGUIN_PID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$PENGUIN_DASH" ] && echo "‚ùå Penguins dashboard not found" && exit 1

          echo "‚úÖ Penguins integration verified: Project=$PENGUIN_PROJECT, DCs=$PENGUIN_DC_COUNT, Dashboard=$PENGUIN_DASH"

      - name: Verify Ampliseq integration from system initialization
        run: |
          # Verify project
          AMPLISEQ_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Ampliseq Microbial Community Analysis") | .name')
          [ -z "$AMPLISEQ_PROJECT" ] && echo "‚ùå Ampliseq project not found" && exit 1

          # Verify deltatables (should have 5 data collections: metadata, multiqc_data, alpha_rarefaction, taxonomy_composition, ancom_volcano)
          AMPLISEQ_PID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Ampliseq Microbial Community Analysis") | ._id')
          AMPLISEQ_DC_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find({\"_id\": ObjectId(\"$AMPLISEQ_PID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[].workflows[0].data_collections | length')
          [ "$AMPLISEQ_DC_COUNT" -lt 5 ] && echo "‚ùå Ampliseq data collections not found (expected >=5, got $AMPLISEQ_DC_COUNT)" && exit 1

          # Verify dashboards (should have 2: MultiQC main tab + Analysis child tab)
          AMPLISEQ_DASH_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.dashboards.find({\"project_id\": ObjectId(\"$AMPLISEQ_PID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r 'length')
          [ "$AMPLISEQ_DASH_COUNT" -lt 2 ] && echo "‚ùå Ampliseq dashboards not found (expected >=2, got $AMPLISEQ_DASH_COUNT)" && exit 1

          # Verify main tab dashboard
          AMPLISEQ_MAIN_DASH=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.dashboards.find({\"project_id\": ObjectId(\"$AMPLISEQ_PID\"), \"is_main_tab\": true}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$AMPLISEQ_MAIN_DASH" ] && echo "‚ùå Ampliseq main dashboard not found" && exit 1

          # Verify child tab dashboard
          AMPLISEQ_CHILD_DASH=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.dashboards.find({\"project_id\": ObjectId(\"$AMPLISEQ_PID\"), \"is_main_tab\": false}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$AMPLISEQ_CHILD_DASH" ] && echo "‚ùå Ampliseq child dashboard not found" && exit 1

          echo "‚úÖ Ampliseq integration verified: Project=$AMPLISEQ_PROJECT, DCs=$AMPLISEQ_DC_COUNT, Dashboards=$AMPLISEQ_DASH_COUNT (Main=$AMPLISEQ_MAIN_DASH, Child=$AMPLISEQ_CHILD_DASH)"

      - name: Test Screenshot Generation - screenshot-dash-fixed
        run: |
          echo "üì∏ Testing screenshot generation functionality..."

          # Wait for services to be ready
          echo "‚è≥ Waiting for services to be ready..."
          for i in {1..30}; do
            if curl -s http://localhost:8058/depictio/api/v1/utils/status >/dev/null 2>&1; then
              echo "‚úÖ Backend API is ready"
              break
            fi
            echo "‚ö†Ô∏è Backend not ready, attempt $i/30"
            sleep 10
          done

          # Test screenshot endpoint with actual Iris dashboard ID
          echo "üß™ Testing screenshot generation endpoint..."

          # Get the actual Iris dashboard ID from the database
          IRIS_PID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | ._id')
          DASHBOARD_ID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.dashboards.find({\"project_id\": ObjectId(\"$IRIS_PID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')

          if [ -z "$DASHBOARD_ID" ]; then
            echo "‚ùå No dashboard found for testing - skipping screenshot test"
            echo "‚úÖ Screenshot endpoint test skipped (no dashboard available)"
            exit 0
          fi

          echo "üìã Using dashboard ID: $DASHBOARD_ID"

          # Debug: Check container status and logs before screenshot
          echo "üîç Pre-screenshot debugging:"
          echo "üìä Container status:"
          docker compose ps

          echo "üìã Recent frontend logs (last 50 lines):"
          docker compose logs --tail=50 depictio-frontend || echo "Failed to get frontend logs"

          echo "üìã Recent backend logs (last 20 lines):"
          docker compose logs --tail=20 depictio-backend || echo "Failed to get backend logs"

          echo "üåê Testing basic API connectivity:"
          curl -s -o /dev/null -w "Status: %{http_code}, Time: %{time_total}s\n" http://localhost:8058/depictio/api/v1/utils/status || echo "API connectivity test failed"

          echo "üåê Testing frontend accessibility:"
          curl -s -o /dev/null -w "Frontend Status: %{http_code}, Time: %{time_total}s\n" http://localhost:5080/ || echo "Frontend connectivity test failed"

          # Make the API call and capture response with timeout
          SCREENSHOT_RESPONSE=$(timeout 60s curl -s -w "\n%{http_code}" http://localhost:8058/depictio/api/v1/utils/screenshot-dash-fixed/$DASHBOARD_ID || echo -e "\nTIMEOUT")
          # SCREENSHOT_RESPONSE=$(curl -s -w "\n%{http_code}" http://localhost:8058/depictio/api/v1/dashboards/screenshot/$DASHBOARD_ID)

          # Extract HTTP status code (last line)
          HTTP_CODE=$(echo "$SCREENSHOT_RESPONSE" | tail -n1)

          # Extract JSON response (all lines except last)
          JSON_RESPONSE=$(echo "$SCREENSHOT_RESPONSE" | head -n -1)

          echo "üìä HTTP Status: $HTTP_CODE"

          # Debug: Check logs after screenshot attempt
          echo "üîç Post-screenshot debugging:"
          echo "üìã Recent backend logs (last 30 lines after screenshot):"
          docker compose logs --tail=30 depictio-backend || echo "Failed to get backend logs"

          echo "üìä All container status after screenshot:"
          docker compose ps

          # Handle timeout case
          if [ "$HTTP_CODE" = "TIMEOUT" ]; then
            echo "‚ö†Ô∏è Screenshot generation timed out after 60 seconds"
            echo "üìã Backend logs during timeout (last 50 lines):"
            docker compose logs --tail=50 depictio-backend || echo "Failed to get timeout logs"
            echo "‚úÖ Screenshot endpoint is accessible but slow - this may be expected in CI environment"
            exit 0
          elif [ "$HTTP_CODE" = "200" ]; then
            echo "‚úÖ Screenshot endpoint responded successfully"

            # Parse and check response without logging sensitive data
            SUCCESS=$(echo "$JSON_RESPONSE" | jq -r '.success // false' 2>/dev/null)
            MESSAGE=$(echo "$JSON_RESPONSE" | jq -r '.message // "unknown"' 2>/dev/null)
            SCREENSHOT_PATH=$(echo "$JSON_RESPONSE" | jq -r '.screenshot_path // "unknown"' 2>/dev/null)
            URL=$(echo "$JSON_RESPONSE" | jq -r '.url // "unknown"' 2>/dev/null)

            echo "üìã Response details:"
            echo "  Success: $SUCCESS"
            echo "  Message: $MESSAGE"
            echo "  Screenshot path: $SCREENSHOT_PATH"
            echo "  URL: $URL"


            if [ "$SUCCESS" = "true" ]; then
              echo "‚úÖ Screenshot generation successful"

              # Additional verification - check if screenshot path is valid
              if [[ "$SCREENSHOT_PATH" == *".png" ]]; then
                echo "‚úÖ Screenshot path format is valid"
              else
                echo "‚ö†Ô∏è  Screenshot path format may be invalid"
              fi

              # Optional: Verify screenshot file exists in container
              echo "üß™ Checking if screenshot file exists in backend container..."
              if docker compose exec -T depictio-backend test -f "$SCREENSHOT_PATH" 2>/dev/null; then
                echo "‚úÖ Screenshot file exists in backend container"
              else
                echo "‚ö†Ô∏è  Screenshot file not found in backend container (may be normal depending on setup)"
              fi

            else
              echo "‚ùå Screenshot generation failed"
              exit 1
            fi

          elif [ "$HTTP_CODE" = "404" ]; then
            echo "‚ö†Ô∏è  Dashboard not found (expected for dummy ID) - testing endpoint availability only"
            echo "‚úÖ Screenshot endpoint is accessible"
          else
            echo "‚ùå Screenshot endpoint failed with status: $HTTP_CODE"
            echo "Response: $JSON_RESPONSE"
            echo "üìã Backend logs on failure (last 50 lines):"
            docker compose logs --tail=50 depictio-backend || echo "Failed to get failure logs"
            echo "üîç Full container logs on failure:"
            docker compose logs depictio-backend || echo "Failed to get full logs"
            exit 1
          fi

          # Final debug: Show summary logs
          echo "üîç Final debugging summary:"
          echo "üìä Final container status:"
          docker compose ps

  cli-comprehensive-test:
    needs: [docker-build]
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"
          cache-dependency-path: "pyproject.toml"

      - name: Setup CLI environment
        run: |
          cd depictio/cli
          uv venv --python 3.12.9 venv
          source venv/bin/activate
          uv pip install -e .

      # ============================================
      # PHASE 1: Offline Tests (No Server Required)
      # ============================================

      - name: Test CLI help commands
        run: |
          cd depictio/cli
          source venv/bin/activate
          echo "üìã Testing CLI help commands..."

          depictio-cli --help
          depictio-cli backup --help
          depictio-cli config --help
          depictio-cli dashboard --help
          depictio-cli data --help

          echo "‚úÖ All help commands passed"

      - name: Test dashboard validate (offline)
        run: |
          cd depictio/cli
          source venv/bin/activate
          echo "üìã Testing dashboard validate (offline)..."

          depictio-cli dashboard validate ../projects/init/iris/dashboard_lite.yaml

          echo "‚úÖ Dashboard validate passed"

      # ============================================
      # PHASE 2: Server-Connected Tests
      # ============================================

      - name: Setup environment and start services
        run: |
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          mkdir -p depictioDB minio_data prof_files cache
          chmod 777 depictioDB minio_data prof_files cache

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          export DEPICTIO_FASTAPI_WORKERS=1  # Single worker to avoid boot race conditions
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d

          echo "‚è≥ Waiting for services to be ready..."

          # Wait for MongoDB
          echo "Waiting for MongoDB..."
          for i in {1..30}; do
            if docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "db.runCommand({ ping: 1 })" --quiet &>/dev/null; then
              echo "‚úÖ MongoDB ready"
              break
            fi
            echo "MongoDB not ready yet, attempt $i/30..."
            sleep 2
          done

          # Wait for Redis
          echo "Waiting for Redis..."
          for i in {1..30}; do
            if docker compose exec -T redis redis-cli ping &>/dev/null; then
              echo "‚úÖ Redis ready"
              break
            fi
            echo "Redis not ready yet, attempt $i/30..."
            sleep 2
          done

          # Wait for MinIO
          echo "Waiting for MinIO..."
          for i in {1..30}; do
            if curl -f http://localhost:9000/minio/health/ready &>/dev/null; then
              echo "‚úÖ MinIO ready"
              break
            fi
            echo "MinIO not ready yet, attempt $i/30..."
            sleep 2
          done

          # Wait for Backend API with health check and restart on crash
          echo "Waiting for Backend API..."
          RESTART_COUNT=0
          MAX_RESTARTS=2
          for i in {1..60}; do
            if curl -f http://localhost:8058/health &>/dev/null; then
              echo "‚úÖ Backend API ready"
              break
            fi
            # Check if container crashed and restart if needed
            if ! docker compose ps depictio-backend | grep -q "Up"; then
              if [ $RESTART_COUNT -lt $MAX_RESTARTS ]; then
                echo "‚ö†Ô∏è  Backend container crashed, restarting (attempt $((RESTART_COUNT+1))/$MAX_RESTARTS)..."
                docker compose up -d depictio-backend
                RESTART_COUNT=$((RESTART_COUNT+1))
                sleep 5
              fi
            fi
            echo "Backend API not ready yet, attempt $i/60..."
            sleep 2
          done

          # Final verification
          echo "üîç Verifying all services..."
          docker compose ps

          # Test API endpoint
          if ! curl -f http://localhost:8058/health; then
            echo "‚ùå Backend API health check failed"
            echo "Backend logs:"
            docker compose logs depictio-backend --tail=50
            exit 1
          fi

          echo "‚úÖ All services ready and healthy"

      - name: Setup CLI authentication
        run: |
          cd depictio/cli
          docker cp depictio-backend:/app/depictio/.depictio/admin_config.yaml .

      - name: Test config commands
        run: |
          cd depictio/cli
          source venv/bin/activate
          echo "üìã Testing config commands..."

          # Validate project config
          depictio-cli --verbose config validate-project-config \
            --project-config-path ../projects/init/iris/project.yaml \
            --CLI-config-path admin_config.yaml

          # Sync project config (with --update for idempotency)
          depictio-cli --verbose config sync-project-config-to-server \
            --update \
            --project-config-path ../projects/init/iris/project.yaml \
            --CLI-config-path admin_config.yaml

          echo "‚úÖ Config commands passed"

      - name: Test dashboard commands (server)
        run: |
          cd depictio/cli
          source venv/bin/activate
          echo "üìã Testing dashboard commands (server)..."

          # Import with dry-run (validates without creating)
          depictio-cli dashboard import ../projects/init/iris/dashboard_lite.yaml --dry-run

          # Actually import dashboard to server
          echo "üîÑ Importing dashboard to server..."
          IMPORT_OUTPUT=$(depictio-cli dashboard import ../projects/init/iris/dashboard_lite.yaml --config admin_config.yaml 2>&1)
          echo "$IMPORT_OUTPUT"

          # Extract dashboard ID from import output
          DASHBOARD_ID=$(echo "$IMPORT_OUTPUT" | grep "Dashboard ID:" | awk '{print $NF}')

          if [ -z "$DASHBOARD_ID" ]; then
            echo "‚ùå Failed to extract dashboard ID from import output"
            exit 1
          fi

          echo "‚úÖ Dashboard imported with ID: $DASHBOARD_ID"

          # Verify dashboard exists in MongoDB via API
          echo "üîç Verifying dashboard registration in database..."

          # Get access token from admin config (same pattern as docker-system-init)
          JWT_TOKEN=$(grep 'access_token' admin_config.yaml | awk '{print $2}' | tr -d "'\"")

          if [ -z "$JWT_TOKEN" ]; then
            echo "‚ùå Failed to extract access token from admin_config.yaml"
            exit 1
          fi

          echo "  ‚úì Using access token from config (length: ${#JWT_TOKEN})"

          # Query API to verify dashboard exists
          API_URL="http://localhost:8058/depictio/api/v1/dashboards/get/$DASHBOARD_ID"
          echo "  API URL: $API_URL"
          echo "  Dashboard ID length: ${#DASHBOARD_ID}"

          # Get full response with status code
          HTTP_RESPONSE=$(curl -s -w "\n%{http_code}" -H "Authorization: Bearer $JWT_TOKEN" "$API_URL")
          HTTP_STATUS=$(echo "$HTTP_RESPONSE" | tail -n1)
          RESPONSE=$(echo "$HTTP_RESPONSE" | head -n-1)

          echo "  HTTP Status: $HTTP_STATUS"
          echo "  Response: $RESPONSE"

          # If 404, check MongoDB directly to see if dashboard exists at all
          if [ "$HTTP_STATUS" = "404" ]; then
            echo ""
            echo "üîç Checking MongoDB directly..."
            docker exec depictio-mongo mongosh depictioDB --quiet --eval "
              db.dashboards.findOne({dashboard_id: ObjectId('$DASHBOARD_ID')}, {_id: 1, dashboard_id: 1, title: 1, project_id: 1})
            " || echo "  MongoDB query failed"
          fi

          # Check if response contains expected fields (API returns "id" not "_id" due to serialization)
          if echo "$RESPONSE" | grep -q '"dashboard_id"' && [ "$HTTP_STATUS" = "200" ]; then
            echo "‚úÖ Dashboard verified in database"

            # Extract and display dashboard details
            TITLE=$(echo "$RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin).get('title', 'N/A'))" 2>/dev/null || echo "N/A")
            PROJECT_ID=$(echo "$RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin).get('project_id', 'N/A'))" 2>/dev/null || echo "N/A")

            echo "  Dashboard Name: $TITLE"
            echo "  Project ID: $PROJECT_ID"
            echo "  Dashboard ID: $DASHBOARD_ID"
          else
            echo "‚ùå Dashboard not found in database (HTTP $HTTP_STATUS)"
            echo "API Response: $RESPONSE"
            exit 1
          fi

          echo "‚úÖ Dashboard commands passed"

      - name: Test CLI workflow with local test project
        run: |
          cd depictio/cli
          source venv/bin/activate
          echo "üìã Testing full CLI workflow with local test project..."

          # Test full CLI workflow with local paths (not Docker paths)
          # This validates that CLI scan/process operations work correctly

          # Validate project config
          depictio-cli --verbose config validate-project-config \
            --project-config-path ../projects/test/cli-test/project.yaml \
            --CLI-config-path admin_config.yaml

          # Sync project to server
          depictio-cli --verbose config sync-project-config-to-server \
            --project-config-path ../projects/test/cli-test/project.yaml \
            --CLI-config-path admin_config.yaml

          # Scan data files
          depictio-cli --verbose data scan \
            --sync-files \
            --project-config-path ../projects/test/cli-test/project.yaml \
            --CLI-config-path admin_config.yaml

          # Process data into deltatables
          depictio-cli --verbose data process \
            --overwrite \
            --project-config-path ../projects/test/cli-test/project.yaml \
            --CLI-config-path admin_config.yaml

          echo "‚úÖ CLI workflow with local test project passed"

      - name: Test Penguin CLI operations
        run: |
          cd depictio/cli
          source venv/bin/activate
          echo "üìã Testing Penguin CLI operations..."

          # NOTE: Penguins is a reference dataset that's auto-initialized by the backend
          # on startup via db_init_reference_datasets.py. The data files exist inside
          # the Docker container at /app/depictio/projects/reference/penguins/, not on the host.
          # Therefore, we skip CLI operations that require host filesystem access.

          # Validate project config (tests validation logic with Docker path detection)
          depictio-cli --verbose config validate-project-config \
            --project-config-path ../projects/reference/penguins/project.yaml \
            --CLI-config-path admin_config.yaml

          # Sync project to server (validates against API)
          depictio-cli --verbose config sync-project-config-to-server \
            --update \
            --project-config-path ../projects/reference/penguins/project.yaml \
            --CLI-config-path admin_config.yaml

          # Skip scan/process/run - penguins is already initialized as reference dataset
          # The verification step below confirms the project and data exist in the database

          echo "‚úÖ Penguin CLI operations passed"

      - name: Test Image Demo CLI operations
        run: |
          cd depictio/cli
          source venv/bin/activate
          echo "üìã Testing Image Demo CLI operations..."

          # Test Image DC workflow with delta table creation and S3 image uploads
          # Validates that Image DCs work like Table DCs but with mandatory image_column

          # Validate project config (tests Image DC model validation)
          depictio-cli --verbose config validate-project-config \
            --project-config-path ../projects/test/image_demo/project.yaml \
            --CLI-config-path admin_config.yaml

          # Sync project to server
          depictio-cli --verbose config sync-project-config-to-server \
            --project-config-path ../projects/test/image_demo/project.yaml \
            --CLI-config-path admin_config.yaml

          # Scan data files (syncs images to S3)
          depictio-cli --verbose data scan \
            --sync-files \
            --project-config-path ../projects/test/image_demo/project.yaml \
            --CLI-config-path admin_config.yaml

          # Process data into deltatables (creates delta table from CSV)
          depictio-cli --verbose data process \
            --overwrite \
            --project-config-path ../projects/test/image_demo/project.yaml \
            --CLI-config-path admin_config.yaml

          echo "‚úÖ Image Demo CLI operations passed"

      - name: Test Image Demo dashboard import
        run: |
          cd depictio/cli
          source venv/bin/activate
          echo "üìã Testing Image Demo dashboard import..."

          # Import Image Demo dashboard
          IMPORT_OUTPUT=$(depictio-cli dashboard import ../projects/test/image_demo/dashboard_lite.yaml --config admin_config.yaml 2>&1)
          echo "$IMPORT_OUTPUT"

          # Extract dashboard ID
          DASHBOARD_ID=$(echo "$IMPORT_OUTPUT" | grep "Dashboard ID:" | awk '{print $NF}')

          if [ -z "$DASHBOARD_ID" ]; then
            echo "‚ùå Failed to extract dashboard ID from import output"
            exit 1
          fi

          echo "‚úÖ Image Demo dashboard imported with ID: $DASHBOARD_ID"

          # Verify dashboard in database
          echo "üîç Verifying dashboard registration in database..."

          # Get access token from admin config (same pattern as Iris verification)
          JWT_TOKEN=$(grep 'access_token' admin_config.yaml | awk '{print $2}' | tr -d "'\"")

          if [ -z "$JWT_TOKEN" ]; then
            echo "‚ùå Failed to get access token from admin_config.yaml"
            exit 1
          fi

          echo "  ‚úì Got access token from config (length: ${#JWT_TOKEN})"

          API_URL="http://localhost:8058/depictio/api/v1/dashboards/get/$DASHBOARD_ID"
          RESPONSE=$(curl -s -H "Authorization: Bearer $JWT_TOKEN" "$API_URL")

          if echo "$RESPONSE" | grep -q '"dashboard_id"'; then
            echo "‚úÖ Image Demo dashboard verified in database"
            TITLE=$(echo "$RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin).get('title', 'N/A'))" 2>/dev/null || echo "N/A")
            echo "  Dashboard Name: $TITLE"
            echo "  Dashboard ID: $DASHBOARD_ID"
          else
            echo "‚ùå Image Demo dashboard not found in database"
            exit 1
          fi

          echo "‚úÖ Image Demo dashboard import test passed"

      - name: Test backup commands (read-only)
        run: |
          cd depictio/cli
          source venv/bin/activate
          echo "üìã Testing backup commands (read-only)..."

          # List backups (read-only, won't fail if empty)
          depictio-cli backup list --CLI-config-path admin_config.yaml || true

          echo "‚úÖ Backup commands passed"

      - name: Verify Image Demo project
        run: |
          # Verify project was created
          IMAGE_DEMO_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Image Component Demo Project") | .name')
          [ -z "$IMAGE_DEMO_PROJECT" ] && echo "‚ùå Image Demo project not found" && exit 1
          echo "‚úÖ Image Demo project found"

          # Verify Image DC deltatable was created
          IMAGE_DEMO_DC=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Image Component Demo Project") | .workflows[0].data_collections[0]._id')
          echo "üìä Image Demo DC ID: $IMAGE_DEMO_DC"

          IMAGE_DEMO_DT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$IMAGE_DEMO_DC\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$IMAGE_DEMO_DT" ] && echo "‚ùå Image Demo deltatable not found" && exit 1
          echo "‚úÖ Image Demo deltatable created successfully"

          # Verify images were uploaded to S3
          echo "üìä Checking S3 for uploaded images..."
          IMAGE_COUNT=$(docker compose exec -T minio mc ls depictio/depictio-bucket/image_demo/ 2>/dev/null | grep -c "\.png" || true)
          IMAGE_COUNT=${IMAGE_COUNT:-0}
          [ "$IMAGE_COUNT" -eq 0 ] && echo "‚ö†Ô∏è  Warning: No images found in S3, but continuing..." || echo "‚úÖ Found $IMAGE_COUNT images in S3"

      - name: Verify CLI test project
        run: |
          # Verify project was created
          CLI_TEST_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "CLI Test Project") | .name')
          [ -z "$CLI_TEST_PROJECT" ] && echo "‚ùå CLI Test Project not found" && exit 1
          echo "‚úÖ CLI Test Project found"

          # Verify deltatable was created
          CLI_TEST_DC=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "CLI Test Project") | .workflows[0].data_collections[0]._id')
          CLI_TEST_DT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$CLI_TEST_DC\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$CLI_TEST_DT" ] && echo "‚ùå CLI Test deltatable not found" && exit 1
          echo "‚úÖ CLI Test deltatable created successfully"

      - name: Verify Iris integration from CLI
        run: |
          # Verify project (auto-initialized as reference dataset)
          IRIS_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | .name')
          [ -z "$IRIS_PROJECT" ] && echo "‚ùå Iris project not found" && exit 1
          echo "‚úÖ Iris project found: $IRIS_PROJECT"

          # Verify deltatable (created during reference dataset initialization)
          IRIS_DC_ID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | .workflows[0].data_collections[0]._id')
          echo "üìä Iris DC ID: $IRIS_DC_ID"

          # Check all deltatables to see what's available
          echo "üìä All deltatables in database:"
          docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "db.deltatables.find({}).limit(5).forEach(doc => print(JSON.stringify(doc)))" --quiet 2>&1 | head -20 || echo "No deltatables found"

          IRIS_DT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$IRIS_DC_ID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')

          if [ -z "$IRIS_DT" ]; then
            echo "‚ùå Iris deltatable not found for DC ID: $IRIS_DC_ID"
            echo "This is expected - Iris is a reference dataset that gets auto-initialized"
            echo "Skipping deltatable verification for reference datasets in CLI job"
          else
            echo "‚úÖ Iris deltatable found: $IRIS_DT"
          fi

          echo "‚úÖ Iris reference dataset verified (project exists)"

      - name: Verify Penguin integration
        run: |
          # Verify project was auto-initialized
          PENGUIN_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Palmer Penguins Species Comparison") | .name')
          [ -z "$PENGUIN_PROJECT" ] && echo "‚ùå Penguin project not found" && exit 1
          echo "‚úÖ Penguin project found: $PENGUIN_PROJECT"

          # Verify deltatables were auto-created during reference dataset initialization
          PENGUIN_DC1=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Palmer Penguins Species Comparison") | .workflows[0].data_collections[0]._id')
          PENGUIN_DT1=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$PENGUIN_DC1\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')

          if [ -z "$PENGUIN_DT1" ]; then
            echo "‚ùå Penguin deltatable not found for DC ID: $PENGUIN_DC1"
            echo "This is expected - Penguins is a reference dataset that gets auto-initialized"
            echo "Skipping deltatable verification for reference datasets in CLI job"
          else
            echo "‚úÖ Penguin deltatable found: $PENGUIN_DT1"
          fi

          echo "‚úÖ Penguin reference dataset verified (project exists)"

      - name: Upload logs on failure
        if: failure()
        run: docker compose logs > cli-comprehensive-logs.txt
        continue-on-error: true

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: cli-comprehensive-logs
          path: cli-comprehensive-logs.txt
          retention-days: 7

  backup-s3-strategies-comprehensive-tests:
    needs: [docker-build]
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    strategy:
      fail-fast: false
      matrix:
        backup_strategy: [local, s3_to_s3, both]
        include:
          - backup_strategy: local
            strategy_name: "S3 to Local"
            s3_enabled: false
            expected_local_files: true
            expected_s3_files: false
          - backup_strategy: s3_to_s3
            strategy_name: "S3 to S3"
            s3_enabled: true
            expected_local_files: false
            expected_s3_files: true
          - backup_strategy: both
            strategy_name: "S3 to Both"
            s3_enabled: true
            expected_local_files: true
            expected_s3_files: true
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"
          cache-dependency-path: "pyproject.toml"

      - name: Setup environment for ${{ matrix.strategy_name }}
        run: |
          echo "üîß Setting up environment for ${{ matrix.strategy_name }} backup strategy..."
          echo "üê≥ Docker permissions and user setup..."
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          echo "UID: $(id -u), GID: $(id -g)"

          echo "üìÅ Creating environment files..."
          # Create root .env for Docker Compose variables
          cp .env.example .env
          echo "‚úÖ Root .env file created"

          # Copy to docker-compose/.env for application variables
          cp .env.example docker-compose/.env
          echo "‚úÖ docker-compose/.env file created"

          echo "‚öôÔ∏è Configuring backup strategy in docker-compose/.env file..."
          # Remove any existing backup configuration first
          sed -i '/^DEPICTIO_BACKUP_/d' docker-compose/.env || echo "No existing backup config to remove"

          echo "" >> docker-compose/.env
          echo "# === BACKUP STRATEGY CONFIGURATION FOR CI ===" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_S3_BACKUP_STRATEGY=${{ matrix.backup_strategy }}" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_ENABLED=${{ matrix.s3_enabled }}" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_BUCKET=depictio-backup-bucket" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_ENDPOINT_URL=http://minio-backup:9000" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_REGION=us-east-1" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_ACCESS_KEY=backup_minio" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_SECRET_KEY=backup_minio123" >> docker-compose/.env

          echo "üìã Complete backup configuration for ${{ matrix.strategy_name }}:"
          grep "DEPICTIO_BACKUP" docker-compose/.env || echo "‚ùå No DEPICTIO_BACKUP vars found!"

          echo "üìÇ Creating required directories..."
          mkdir -p depictioDB minio_data minio_backup_data
          chmod 777 depictioDB minio_data minio_backup_data
          # Ensure MongoDB can create additional directories
          chmod -R 777 depictioDB 2>/dev/null || echo "Directory permissions already set"
          ls -la depictioDB minio_data minio_backup_data
          echo "‚úÖ Directories created and permissions set"

      - name: Log in and start services for ${{ matrix.strategy_name }}
        run: |
          echo "üöÄ Starting services for ${{ matrix.strategy_name }} backup strategy..."

          echo "üîê Logging into container registry..."
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin

          echo "üê≥ Setting up Docker image..."
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          echo "Using image: $FULL_IMAGE"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          echo "DEPICTIO_VERSION set to: $DEPICTIO_VERSION"

          echo "üìã Final environment file content before starting services:"
          echo "=== ALL DEPICTIO_BACKUP VARIABLES ==="
          grep "DEPICTIO_BACKUP" docker-compose/.env || echo "‚ùå No DEPICTIO_BACKUP vars found!"
          echo "=== SAMPLE OF OTHER ENVIRONMENT VARIABLES ==="
          head -10 docker-compose/.env
          echo "=================================="

          echo "üê≥ Starting Docker Compose services..."
          echo "Compose files: docker-compose.dev.yaml + docker-compose.minio.yaml + docker-compose.backup-minio.yaml"
          echo "Environment file: docker-compose/.env"

          export DEPICTIO_FASTAPI_WORKERS=1  # Single worker to avoid boot race conditions
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml -f docker-compose/docker-compose.backup-minio.yaml up -d --force-recreate

          echo "‚è≥ Waiting 30 seconds for services to start..."
          sleep 30

          echo "üìä Verifying services are running..."
          docker compose ps

          echo "üîç Checking individual container status..."
          echo "--- Depictio Backend ---"
          docker compose logs --tail=10 depictio-backend || echo "‚ùå Backend logs not available"
          echo "--- Main MinIO ---"
          docker compose logs --tail=5 minio || echo "‚ùå MinIO logs not available"
          echo "--- Backup MinIO ---"
          docker compose logs --tail=5 minio-backup || echo "‚ùå Backup MinIO logs not available"
          echo "--- MongoDB ---"
          docker compose logs --tail=10 mongo || echo "‚ùå MongoDB logs not available"

          # Wait for backup MinIO to be ready and create bucket
          echo "‚è≥ Waiting for backup MinIO to be ready..."
          sleep 10

          echo "üîß Testing backup MinIO connectivity and creating bucket..."
          docker compose exec -T depictio-backend python3 -c "
          import boto3
          import time
          from botocore.exceptions import ClientError

          print('üîç Attempting to connect to backup MinIO...')
          print('Endpoint: http://minio-backup:9000')
          print('Access Key: backup_minio')
          print('Secret Key: backup_minio123')

          # Wait for backup MinIO to be ready
          for i in range(30):
              try:
                  client = boto3.client('s3',
                      endpoint_url='http://minio-backup:9000',
                      aws_access_key_id='backup_minio',
                      aws_secret_access_key='backup_minio123',
                      region_name='us-east-1')
                  response = client.list_buckets()
                  print(f'‚úÖ Backup MinIO ready after {i+1} attempts')
                  print(f'üìã Current buckets: {[b[\"Name\"] for b in response.get(\"Buckets\", [])]}')
                  break
              except Exception as e:
                  print(f'‚ö†Ô∏è Backup MinIO not ready (attempt {i+1}/30): {e}')
                  if i < 5:  # Show detailed error for first few attempts
                      import traceback
                      traceback.print_exc()
                  time.sleep(2)
          else:
              print('‚ùå Backup MinIO failed to start after 30 attempts')
              print('üîç Final connection attempt with full error details:')
              try:
                  client = boto3.client('s3',
                      endpoint_url='http://minio-backup:9000',
                      aws_access_key_id='backup_minio',
                      aws_secret_access_key='backup_minio123',
                      region_name='us-east-1')
                  client.list_buckets()
              except Exception as final_e:
                  import traceback
                  traceback.print_exc()
              exit(1)

          # Create backup bucket
          print('ü™£ Creating backup bucket...')
          try:
              client.create_bucket(Bucket='depictio-backup-bucket')
              print('‚úÖ Backup bucket created successfully')
          except ClientError as e:
              if e.response['Error']['Code'] == 'BucketAlreadyOwnedByYou':
                  print('‚úÖ Backup bucket already exists')
              else:
                  print(f'‚ùå Failed to create backup bucket: {e}')
                  exit(1)

          # Final verification
          final_buckets = client.list_buckets()
          print(f'üìã Final bucket list: {[b[\"Name\"] for b in final_buckets.get(\"Buckets\", [])]}')
          "

          echo "‚úÖ Services started for ${{ matrix.strategy_name }} strategy"

      - name: Setup CLI for ${{ matrix.strategy_name }}
        run: |
          echo "üîß Setting up CLI for ${{ matrix.strategy_name }} testing..."

          echo "üìÅ Navigating to CLI directory..."
          cd depictio/cli

          echo "üêç Creating Python virtual environment..."
          uv venv --python 3.11 venv
          source venv/bin/activate
          echo "Python version: $(python --version)"
          echo "Pip version: $(pip --version)"

          echo "üì¶ Installing CLI dependencies..."
          uv pip install --upgrade pip
          uv pip install -e .
          echo "‚úÖ CLI dependencies installed"

          echo "üîë Copying admin configuration from backend container..."
          docker cp depictio-backend:/app/depictio/.depictio/admin_config.yaml .
          echo "üìã Admin config file copied, checking contents..."
          ls -la admin_config.yaml
          head -5 admin_config.yaml | grep -v "token" || echo "Config file structure check"

          echo "‚úÖ CLI setup completed for ${{ matrix.strategy_name }}"

      - name: Wait for system initialization - ${{ matrix.strategy_name }}
        run: |
          echo "‚è≥ Waiting for system initialization for ${{ matrix.strategy_name }}..."

          echo "üîë Extracting authentication token for health checks..."
          # Verify system is ready
          for i in {1..10}; do
            echo "üîç Health check attempt $i/10..."

            if token=$(docker compose exec depictio-backend bash -c "cat /app/depictio/.depictio/admin_config.yaml" 2>/dev/null | grep 'access_token' | awk '{print $2}'); then
              token=$(echo $token | tr -d "'\"")
              echo "‚úÖ Token extracted successfully (length: ${#token})"

              echo "üåê Testing API health endpoint..."
              health_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/utils/status)
              echo "üìä Health check response: HTTP $health_check"

              if [ "$health_check" = "200" ]; then
                echo "‚úÖ System ready for ${{ matrix.strategy_name }}"

                echo "üîç Testing additional API endpoints..."
                # Test projects endpoint
                projects_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/projects/get/all)
                echo "üìä Projects endpoint: HTTP $projects_check"

                # Test backup endpoint
                backup_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/backup/list)
                echo "üìä Backup endpoint: HTTP $backup_check"

                break
              else
                echo "‚ö†Ô∏è Health check failed with HTTP $health_check"
              fi
            else
              echo "‚ùå Failed to extract token from admin config"
            fi

            echo "‚ö†Ô∏è System not ready for ${{ matrix.strategy_name }}, attempt $i/10"
            echo "üîç Backend container logs (last 5 lines):"
            docker compose logs --tail=5 depictio-backend || echo "Failed to get logs"
            sleep 15
          done

          echo "‚è≥ Additional stabilization period..."
          sleep 30

          echo "üìä Final container status before backup testing:"
          docker compose ps

      - name: Create backup with ${{ matrix.strategy_name }} strategy
        run: |
          echo "üíæ Creating backup with ${{ matrix.strategy_name }} strategy..."
          cd depictio/cli
          source venv/bin/activate

          # Show current backup configuration from backend
          echo "üìã Checking backend configuration and database state..."

          echo "üîç Checking environment variables in backend container..."
          docker compose exec -T depictio-backend bash -c "env | grep DEPICTIO_BACKUP || echo 'No DEPICTIO_BACKUP env vars found'"

          echo "üìã Backend backup configuration:"
          docker compose exec -T depictio-backend python3 -c "
          import os;
          print('=== ENVIRONMENT VARIABLES ===');
          for key, value in os.environ.items():
              if 'DEPICTIO_BACKUP' in key:
                  print(f'{key}={value}');
          print('=== LOADED SETTINGS ===');
          from depictio.api.v1.configs.config import settings;
          print(f'Backup Strategy: {settings.backup.s3_backup_strategy}');
          print(f'Backup S3 Enabled: {settings.backup.backup_s3_enabled}');
          print(f'Backup S3 Bucket: {settings.backup.backup_s3_bucket}');
          print(f'Backup S3 Endpoint: {settings.backup.backup_s3_endpoint_url}');
          print(f'S3 Local Backup Path: {settings.backup.s3_local_backup_path}');
          print(f'Compress Local Backups: {settings.backup.compress_local_backups}');

          print('\n=== SOURCE S3 CONFIGURATION ===');
          print(f'Source MinIO Bucket: {settings.minio.bucket}');
          print(f'Source MinIO Endpoint: {settings.minio.endpoint_url}');

          # Test connectivity to both MinIO instances
          import boto3;
          print('\n=== CONNECTIVITY TESTS ===');

          # Test source MinIO
          try:
              source_client = boto3.client('s3',
                  endpoint_url=settings.minio.endpoint_url,
                  aws_access_key_id=settings.minio.aws_access_key_id,
                  aws_secret_access_key=settings.minio.aws_secret_access_key,
                  region_name='us-east-1');
              source_buckets = source_client.list_buckets();
              print(f'‚úÖ Source MinIO accessible, buckets: {[b[\"Name\"] for b in source_buckets.get(\"Buckets\", [])]}');

              # Check if source bucket has any deltatable data
              if settings.minio.bucket in [b[\"Name\"] for b in source_buckets.get(\"Buckets\", [])]:
                  objects = source_client.list_objects_v2(Bucket=settings.minio.bucket);
                  object_count = len(objects.get('Contents', []));
                  print(f'üìä Source bucket objects count: {object_count}');
                  if object_count > 0:
                      print('üìã Sample objects:');
                      for obj in objects.get('Contents', [])[:5]:
                          print(f'  - {obj[\"Key\"]} ({obj[\"Size\"]} bytes)');
              else:
                  print(f'‚ùå Source bucket {settings.minio.bucket} not found');
          except Exception as e:
              print(f'‚ùå Source MinIO not accessible: {e}');
              import traceback;
              traceback.print_exc();

          # Test backup MinIO
          try:
              backup_client = boto3.client('s3',
                  endpoint_url='http://minio-backup:9000',
                  aws_access_key_id='backup_minio',
                  aws_secret_access_key='backup_minio123',
                  region_name='us-east-1');
              backup_buckets = backup_client.list_buckets();
              print(f'‚úÖ Backup MinIO accessible, buckets: {[b[\"Name\"] for b in backup_buckets.get(\"Buckets\", [])]}');
          except Exception as e:
              print(f'‚ùå Backup MinIO not accessible: {e}');
              import traceback;
              traceback.print_exc();
          "

          echo ""
          echo "üìä Database state analysis..."

          echo "üîç Testing MongoDB connectivity..."
          docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "print('MongoDB connection test: ' + new Date())" --quiet || echo "‚ùå MongoDB query failed"

          # Show deltatable count before backup with error handling
          echo "üìä Querying deltatables collection..."
          DELTATABLE_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
          try {
            var count = db.deltatables.countDocuments({});
            print('Deltatable count: ' + count);
            print(count);
          } catch(e) {
            print('Error counting deltatables: ' + e);
            print('0');
          }" --quiet 2>&1 | tail -1)
          echo "üìä Total deltatables in database: $DELTATABLE_COUNT"

          # Show project count
          PROJECT_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
          try {
            var count = db.projects.countDocuments({});
            print('Project count: ' + count);
            print(count);
          } catch(e) {
            print('Error counting projects: ' + e);
            print('0');
          }" --quiet 2>&1 | tail -1)
          echo "üìä Total projects in database: $PROJECT_COUNT"

          # Debug database collections
          echo "üîç Available collections:"
          docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "db.listCollectionNames()" --quiet || echo "‚ùå Failed to list collections"

          if [ "$DELTATABLE_COUNT" -gt 0 ]; then
            echo "üìã Deltatable details (first 3):"
            docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
            db.deltatables.find({}).limit(3).forEach(function(doc) {
              var location = doc.delta_table_location || doc.location || 'no location';
              print('ID: ' + doc._id + ', Location: ' + location + ', Collection: ' + (doc.data_collection_id || 'no collection'));
            })" --quiet
          else
            echo "‚ö†Ô∏è  No deltatables found in database - backup will have no S3 data to process"
            echo "üîç Checking if system initialization completed..."
            docker compose logs --tail=20 depictio-backend | grep -i "iris\|init\|startup" || echo "No initialization logs found"
          fi

          # Create backup with strategy-specific prefix
          echo ""
          echo "üöÄ Starting backup creation with detailed logging..."
          echo "Command: depictio-cli -v -vl DEBUG backup create --CLI-config-path admin_config.yaml --include-s3-data --s3-backup-prefix ci_${{ matrix.backup_strategy }}_backup"
          echo "Strategy: ${{ matrix.backup_strategy }}"
          echo "Expected S3 files: ${{ matrix.expected_s3_files }}"
          echo "Expected local files: ${{ matrix.expected_local_files }}"
          echo ""

          # Set up timing
          START_TIME=$(date +%s)

          # Run backup command with full debugging
          if depictio-cli -v -vl DEBUG backup create \
            --CLI-config-path admin_config.yaml \
            --include-s3-data \
            --s3-backup-prefix "ci_${{ matrix.backup_strategy }}_backup"; then
            END_TIME=$(date +%s)
            DURATION=$((END_TIME - START_TIME))
            echo "‚úÖ Backup creation completed successfully for ${{ matrix.strategy_name }} in ${DURATION}s"
          else
            EXIT_CODE=$?
            END_TIME=$(date +%s)
            DURATION=$((END_TIME - START_TIME))
            echo "‚ùå Backup creation failed for ${{ matrix.strategy_name }} after ${DURATION}s with exit code $EXIT_CODE"

            echo "üîç Backend logs after failed backup:"
            docker compose logs --tail=30 depictio-backend

            echo "üîç CLI debug information:"
            ls -la admin_config.yaml
            echo "Environment variables:"
            env | grep DEPICTIO | head -10

            exit $EXIT_CODE
          fi

          echo ""
          echo "üìä Post-backup analysis..."

          # Check what was created after backup
          echo "üìÅ Checking backup directory structure after backup..."
          docker compose exec -T depictio-backend find /app/depictio/backups -type f -name "*" 2>/dev/null | head -10 || echo "No backup files found"

          if [ "${{ matrix.expected_local_files }}" = "true" ]; then
            echo "üìÇ Checking for local S3 backup files..."
            docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -type f -name "*" 2>/dev/null | head -5 || echo "No S3 local backup files found"
          fi

      - name: Verify S3 local backup files - ${{ matrix.strategy_name }}
        if: matrix.expected_local_files == true
        run: |
          echo "üìÅ Verifying local backup files for ${{ matrix.strategy_name }} strategy..."

          # Check if local backup files exist in the backend container
          echo "üîç Checking for local backup files in backend container..."
          echo "üìÇ Listing backup directory structure:"
          docker compose exec -T depictio-backend find /app/depictio/backups -type d -name "*" 2>/dev/null || echo "Backup directory not found, checking if it exists..."
          docker compose exec -T depictio-backend ls -la /app/depictio/backups 2>/dev/null || echo "Main backup directory doesn't exist"
          docker compose exec -T depictio-backend ls -la /app/depictio/backups/s3_data_backups 2>/dev/null || echo "S3 backup directory doesn't exist"

          # Look for backup files by checking prefix directory
          DATE=$(date +%Y%m%d)
          echo "üîç Searching for backup files with date prefix $DATE..."

          # Check for any backup files in the s3_data_backups directory with current date
          BACKUP_COUNT=$(docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "ci_${{ matrix.backup_strategy }}_backup" -type d 2>/dev/null | wc -l)
          echo "Found $BACKUP_COUNT backup prefix directories"

          if [ "$BACKUP_COUNT" -gt 0 ]; then
            echo "‚úÖ Local backup directory found for ${{ matrix.strategy_name }}"
            docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "ci_${{ matrix.backup_strategy }}_backup" -type d -exec ls -la {} \;

            # Check for actual data files inside backup directories
            FILE_COUNT=$(docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "*.parquet" -o -name "*.json" -o -name "*${DATE}*" 2>/dev/null | wc -l)
            echo "Found $FILE_COUNT actual backup files"

            if [ "$FILE_COUNT" -gt 0 ]; then
              echo "‚úÖ Local backup files verified for ${{ matrix.strategy_name }}"
              docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "*.parquet" -o -name "*.json" -o -name "*${DATE}*" 2>/dev/null | head -10
            else
              echo "‚ö†Ô∏è  Backup directory exists but no files found"
            fi
          else
            echo "‚ùå No local backup directories found for ${{ matrix.strategy_name }}"
            exit 1
          fi

      - name: Verify S3 backup files - ${{ matrix.strategy_name }}
        if: matrix.expected_s3_files == true
        run: |
          echo "‚òÅÔ∏è Verifying S3 backup files for ${{ matrix.strategy_name }} strategy..."

          # Check if backup files exist on local backup MinIO
          echo "üìã Checking S3 backup files in local backup MinIO for ${{ matrix.strategy_name }}..."
          docker compose exec -T depictio-backend python3 -c "
          import boto3;
          try:
              print('üîç Connecting to backup MinIO...');
              client = boto3.client('s3',
                  endpoint_url='http://minio-backup:9000',
                  aws_access_key_id='backup_minio',
                  aws_secret_access_key='backup_minio123',
                  region_name='us-east-1');

              # Test connection first
              print('üìã Testing backup MinIO connection...');
              buckets = client.list_buckets();
              print(f'Available buckets: {[b[\"Name\"] for b in buckets.get(\"Buckets\", [])]}');

              # List all objects in the bucket for debugging
              print('üìã Listing all objects in backup bucket...');
              all_response = client.list_objects_v2(Bucket='depictio-backup-bucket');
              all_files = all_response.get('Contents', []);
              if all_files:
                  print(f'üìä Total objects in backup bucket: {len(all_files)}');
                  for f in all_files:
                      print(f'  - {f[\"Key\"]} ({f[\"Size\"]} bytes)');
              else:
                  print('üìä No objects found in backup bucket');

              # Now check for specific prefix
              print(f'üîç Searching for files with prefix: ci_${{ matrix.backup_strategy }}_backup/');
              response = client.list_objects_v2(Bucket='depictio-backup-bucket', Prefix='ci_${{ matrix.backup_strategy }}_backup/');
              files = response.get('Contents', []);
              parquet_files = [f for f in files if f['Key'].endswith('.parquet')];
              print(f'‚úÖ ${{ matrix.strategy_name }}: Found {len(files)} total files, {len(parquet_files)} parquet files');

              # List backup files with prefix for debugging
              if files:
                  print('üìã Prefix-specific backup files found:');
                  for f in files:
                      print(f'  - {f[\"Key\"]} ({f[\"Size\"]} bytes)');

              if len(files) == 0:
                  print('‚ùå No S3 backup files found for ${{ matrix.strategy_name }}');
                  exit(1);
              else:
                  print('‚úÖ S3 backup verification successful for ${{ matrix.strategy_name }}');
          except Exception as e:
              print(f'‚ùå S3 verification failed for ${{ matrix.strategy_name }}: {e}');
              import traceback;
              traceback.print_exc();
              exit(1);
          "

      - name: Verify backup strategy behavior - ${{ matrix.strategy_name }}
        run: |
          echo "üîç Verifying ${{ matrix.strategy_name }} backup strategy behavior..."
          cd depictio/cli
          source venv/bin/activate

          # List backups and get the latest one
          BACKUP_LIST=$(depictio-cli backup list --CLI-config-path admin_config.yaml)
          echo "Available backups for ${{ matrix.strategy_name }}: $BACKUP_LIST"

          # Validate backup integrity
          BACKUP_ID=$(echo "$BACKUP_LIST" | grep -o '"backup_id": "[^"]*"' | head -1 | cut -d'"' -f4)
          echo "Using backup ID for ${{ matrix.strategy_name }}: $BACKUP_ID"

          if [ -n "$BACKUP_ID" ]; then
            depictio-cli -v -vl DEBUG backup validate "$BACKUP_ID" --CLI-config-path admin_config.yaml
            echo "‚úÖ Backup validation successful for ${{ matrix.strategy_name }}"
          else
            echo "‚ùå No backup ID found for ${{ matrix.strategy_name }}"
            exit 1
          fi

      - name: Test backup restoration - ${{ matrix.strategy_name }}
        run: |
          echo "‚ôªÔ∏è Testing backup restoration for ${{ matrix.strategy_name }}..."
          cd depictio/cli
          source venv/bin/activate

          # Drop some test data for restoration test
          docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
            var dashboardCount = db.dashboards.countDocuments({});
            print('Dashboards before deletion for ${{ matrix.strategy_name }}: ' + dashboardCount);
            if (dashboardCount > 0) {
              db.dashboards.deleteMany({});
              print('Dashboards after deletion for ${{ matrix.strategy_name }}: ' + db.dashboards.countDocuments({}));
            }
          "

          # Get backup ID and restore
          BACKUP_LIST=$(depictio-cli backup list --CLI-config-path admin_config.yaml)
          BACKUP_ID=$(echo "$BACKUP_LIST" | grep -o '"backup_id": "[^"]*"' | head -1 | cut -d'"' -f4)

          if [ -n "$BACKUP_ID" ]; then
            echo "üîÑ Performing restore test for ${{ matrix.strategy_name }}..."
            depictio-cli -v -vl DEBUG backup restore "$BACKUP_ID" \
              --CLI-config-path admin_config.yaml \
              --force

            # Verify restoration
            DASHBOARD_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "db.dashboards.countDocuments({})" --quiet)
            echo "Dashboards after restore for ${{ matrix.strategy_name }}: $DASHBOARD_COUNT"

            echo "‚úÖ Backup restoration test completed for ${{ matrix.strategy_name }}"
          else
            echo "‚ùå No backup ID found for restoration test"
            exit 1
          fi

      - name: Cleanup and summary - ${{ matrix.strategy_name }}
        run: |
          echo "üßπ Cleanup and summary for ${{ matrix.strategy_name }}..."

          # Show final status
          echo "üìä Final status for ${{ matrix.strategy_name }} backup strategy:"
          echo "- Strategy: ${{ matrix.backup_strategy }}"
          echo "- S3 Enabled: ${{ matrix.s3_enabled }}"
          echo "- Expected Local Files: ${{ matrix.expected_local_files }}"
          echo "- Expected S3 Files: ${{ matrix.expected_s3_files }}"

          # Stop services for this iteration
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml -f docker-compose/docker-compose.backup-minio.yaml down
          echo "‚úÖ ${{ matrix.strategy_name }} backup strategy test completed successfully"

      - name: Upload logs on failure
        if: failure()
        run: |
          docker compose logs > backup-${{ matrix.backup_strategy }}-logs.txt
          cd depictio/cli && ls -la >> ../backup-${{ matrix.backup_strategy }}-logs.txt
        continue-on-error: true

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: backup-${{ matrix.backup_strategy }}-logs
          path: backup-${{ matrix.backup_strategy }}-logs.txt
          retention-days: 7

  e2e-tests:
    needs: [docker-build]
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Setup environment
        run: |
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          # Enable dev mode
          sed -i 's/# DEPICTIO_DEV_MODE=false/DEPICTIO_DEV_MODE=true/' docker-compose/.env
          # Disable all special auth modes for standard auth tests (requires login)
          sed -i 's/DEPICTIO_AUTH_SINGLE_USER_MODE=true/DEPICTIO_AUTH_SINGLE_USER_MODE=false/' docker-compose/.env
          sed -i 's/DEPICTIO_AUTH_PUBLIC_MODE=true/DEPICTIO_AUTH_PUBLIC_MODE=false/' docker-compose/.env
          sed -i 's/DEPICTIO_AUTH_DEMO_MODE=true/DEPICTIO_AUTH_DEMO_MODE=false/' docker-compose/.env
          mkdir -p depictioDB minio_data prof_files cache
          chmod 777 depictioDB minio_data prof_files cache

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          export DEPICTIO_FASTAPI_WORKERS=1  # Single worker to avoid boot race conditions
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d
          sleep 15

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "20"

      - name: Install Chrome
        run: |
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Install Cypress dependencies
        run: |
          cd depictio/tests/e2e-tests
          if [ ! -f "package.json" ]; then
            npm init -y
            npm install cypress --save-dev
          else
            npm ci
          fi

      - name: Run Cypress tests
        run: |
          cd depictio/tests/e2e-tests
          export CYPRESS_UNAUTHENTICATED_MODE=false
          # Set Chrome flags for better CI rendering and stability
          export CYPRESS_BROWSER_ARGS="--disable-gpu --no-sandbox --disable-dev-shm-usage --disable-extensions --disable-background-timer-throttling --disable-renderer-backgrounding --disable-backgrounding-occluded-windows"
          # Run Chrome in headless mode for CI with improved stability
          npx cypress run \
            --browser chrome \
            --headless \
            --config screenshotsFolder=cypress/screenshots,videosFolder=cypress/videos,trashAssetsBeforeRuns=false,video=true,screenshotOnRunFailure=true,viewportWidth=1920,viewportHeight=1080,chromeWebSecurity=false \
            --spec "cypress/e2e/!(unauthenticated)/**/*.cy.js"

      - name: Upload screenshots
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cypress-screenshots
          path: depictio/tests/e2e-tests/cypress/screenshots
          retention-days: 30

      - name: Upload videos on failure
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: cypress-videos
          path: depictio/tests/e2e-tests/cypress/videos
          retention-days: 7

  e2e-tests-unauthenticated:
    needs: [docker-build]
    if: always() && needs.docker-build.result == 'success'
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Setup environment
        run: |
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          # Enable PUBLIC_MODE for unauthenticated tests (disable SINGLE_USER_MODE)
          sed -i 's/DEPICTIO_AUTH_SINGLE_USER_MODE=true/DEPICTIO_AUTH_SINGLE_USER_MODE=false/' docker-compose/.env
          sed -i 's/DEPICTIO_AUTH_PUBLIC_MODE=false/DEPICTIO_AUTH_PUBLIC_MODE=true/' docker-compose/.env
          sed -i 's/# DEPICTIO_DEV_MODE=false/DEPICTIO_DEV_MODE=true/' docker-compose/.env
          mkdir -p depictioDB minio_data prof_files cache
          chmod 777 depictioDB minio_data prof_files cache

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          export DEPICTIO_FASTAPI_WORKERS=1  # Single worker to avoid boot race conditions
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml --env-file docker-compose/.env up -d

      - name: Wait for services to be ready
        run: |
          echo "‚è≥ Waiting for services to be ready..."

          # Wait for MongoDB
          echo "Waiting for MongoDB..."
          for i in {1..30}; do
            if docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "db.runCommand({ ping: 1 })" --quiet &>/dev/null; then
              echo "‚úÖ MongoDB ready"
              break
            fi
            echo "MongoDB not ready yet, attempt $i/30..."
            sleep 2
          done

          # Wait for Backend API
          echo "Waiting for Backend API..."
          for i in {1..60}; do
            if curl -f http://localhost:8058/health &>/dev/null; then
              echo "‚úÖ Backend API ready"
              break
            fi
            echo "Backend API not ready yet, attempt $i/60..."
            sleep 2
          done

          # Wait for Frontend
          echo "Waiting for Frontend..."
          for i in {1..60}; do
            if curl -s -o /dev/null -w "%{http_code}" http://localhost:5080/ | grep -q "200"; then
              echo "‚úÖ Frontend ready"
              break
            fi
            echo "Frontend not ready yet, attempt $i/60..."
            sleep 2
          done

          echo "üîç Final service status:"
          docker compose ps

      - name: Show .env files
        run: |
          echo "üìã Environment variables in docker-compose/.env:"
          cat docker-compose/.env || echo "‚ùå .env file not found"

      - name: Log container status
        run: |
          echo "üìä Backend container status:"
          docker compose ps depictio-backend || echo "‚ùå Backend container not running"
          docker compose logs --tail=30 depictio-backend || echo "‚ùå Failed to get backend logs"

          echo ""
          echo "üìä Frontend container status:"
          docker compose ps depictio-frontend || echo "‚ùå Frontend container not running"
          docker compose logs --tail=30 depictio-frontend || echo "‚ùå Failed to get frontend logs"

      - name: Verify public mode is enabled
        run: |
          echo "üîç Verifying public mode configuration..."

          # Verify PUBLIC_MODE is enabled in .env
          if grep -q "DEPICTIO_AUTH_PUBLIC_MODE=true" docker-compose/.env; then
            echo "‚úÖ PUBLIC_MODE enabled in docker-compose/.env"
          else
            echo "‚ùå PUBLIC_MODE not enabled"
            exit 1
          fi

          echo "‚úÖ Public mode configuration verified"

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "20"

      - name: Install Cypress dependencies
        run: |
          cd depictio/tests/e2e-tests
          if [ ! -f "package.json" ]; then
            npm init -y
            npm install cypress --save-dev
          else
            npm ci
          fi

      - name: Install Chrome for unauthenticated tests
        run: |
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Run Cypress unauthenticated tests
        run: |
          cd depictio/tests/e2e-tests
          # Set environment variable for cypress to know it's unauthenticated mode
          export CYPRESS_UNAUTHENTICATED_MODE=true
          # Set Chrome flags for better CI rendering and stability
          export CYPRESS_BROWSER_ARGS="--disable-gpu --no-sandbox --disable-dev-shm-usage --disable-extensions --disable-background-timer-throttling --disable-renderer-backgrounding --disable-backgrounding-occluded-windows"
          npx cypress run \
            --browser chrome \
            --headless \
            --config screenshotsFolder=cypress/screenshots-unauthenticated,videosFolder=cypress/videos-unauthenticated,trashAssetsBeforeRuns=false,video=true,screenshotOnRunFailure=true,viewportWidth=1920,viewportHeight=1080,chromeWebSecurity=false \
            --spec "cypress/e2e/unauthenticated/**/*.cy.js"

      - name: Upload screenshots
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cypress-screenshots-unauthenticated
          path: depictio/tests/e2e-tests/cypress/screenshots-unauthenticated
          retention-days: 30

      - name: Upload videos on failure
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: cypress-videos-unauthenticated
          path: depictio/tests/e2e-tests/cypress/videos-unauthenticated
          retention-days: 7
