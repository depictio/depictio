name: "Depictio – Full CI: Quality, Build, Integration, E2E Tests"

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  quality:
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"
          cache-dependency-path: "pyproject.toml"

      - name: Install Dependencies with LTS Fallback
        run: |
          uv venv --python 3.12.9 venv
          source venv/bin/activate
          uv pip install --upgrade pip

          if uv pip install -e ".[dev]" && python -c "import polars" 2>/dev/null; then
            echo "✅ Default installation with standard polars successful"
          else
            echo "⚠️ Standard polars failed, uninstalling and trying LTS version..."
            uv pip uninstall polars || true
            uv pip install "polars-lts-cpu==1.22.0"
            echo "✅ LTS installation successful"
          fi

          python -c "import polars; print(f'Polars {polars.__version__} installed')"

      - name: Install dependencies for quality check & testing
        run: |
          source venv/bin/activate
          uv pip install -e ".[dev]"

      - name: Show installed packages
        run: |
          source venv/bin/activate
          pip list

      - name: Run Ruff for formatting
        run: |
          source venv/bin/activate
          ruff format depictio

      - name: Debug environment before Ruff check
        run: |
          source venv/bin/activate
          echo "=== RUFF DEBUGGING INFO ==="
          echo "Ruff version: $(ruff --version)"
          echo "Working directory: $(pwd)"
          echo "Python path: $(which python)"
          echo "Python version: $(python --version)"

          echo "=== RUFF CONFIGURATION ==="
          ruff check --show-settings depictio | head -20

          echo "=== FILE COUNTS ==="
          echo "Total Python files in depictio: $(find depictio -name '*.py' | wc -l)"
          echo "Sample files being checked:"
          find depictio -name '*.py' | head -10

          echo "=== IMPORT VIOLATIONS CHECK ==="
          echo "Running import-only check to see specific violations:"
          ruff check depictio --select I --output-format=json | jq '.[0:5]' || echo "No import violations found or jq not available"

          echo "=== PRE-COMMIT RUFF VERSION ==="
          cat .pre-commit-config.yaml | grep -A 2 "charliermarsh/ruff-pre-commit" || echo "Pre-commit config not found"

      - name: Run Ruff for linting
        run: |
          source venv/bin/activate
          ruff check depictio

      - name: Run ty type checker (must pass)
        run: |
          source venv/bin/activate
          ty version
          ty check depictio/models/ depictio/api/ depictio/dash/ depictio/cli/ depictio/tests/

      # - name: Run pre-commit hooks
      #   run: |
      #     source venv/bin/activate
      #     pre-commit run --all-files

      - name: Run tests
        run: |
          source venv/bin/activate
          python -m pytest -xvs -n auto

  docker-build:
    needs: quality
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: write
      id-token: write
    outputs:
      image-tag: ${{ steps.image-info.outputs.tag }}
      image-digest: ${{ steps.build.outputs.digest }}
      rebuild-needed: ${{ steps.check-rebuild.outputs.rebuild }}
      full-image: ${{ steps.image-info.outputs.full-image }}
    steps:
      - uses: actions/checkout@v4

      - name: Configure Docker Permissions
        run: |
          sudo usermod -aG docker $USER || true
          sudo chmod 666 /var/run/docker.sock

      - name: Export UID and GID
        run: |
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV

      - name: Setup directories
        run: |
          cp .env.example .env
          mkdir -p depictioDB minio_data
          chmod 777 depictioDB minio_data

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        if: env.ACT != 'true' # Skip login when using act
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Generate image info
        id: image-info
        run: |
          REPO_LOWER=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            TAG="pr-${{ github.event.number }}-${{ github.sha }}"
          else
            TAG="main-${{ github.sha }}"
          fi
          echo "tag=${TAG}" >> $GITHUB_OUTPUT
          echo "repo=${REPO_LOWER}" >> $GITHUB_OUTPUT
          echo "full-image=ghcr.io/${REPO_LOWER}:${TAG}" >> $GITHUB_OUTPUT

      - name: Check if rebuild needed
        id: check-rebuild
        run: |
          FULL_IMAGE="${{ steps.image-info.outputs.full-image }}"
          if docker manifest inspect "${FULL_IMAGE}" > /dev/null 2>&1; then
            echo "rebuild=false" >> $GITHUB_OUTPUT
            echo "✅ Image ${FULL_IMAGE} already exists, skipping build"
          else
            echo "rebuild=true" >> $GITHUB_OUTPUT
            echo "🔨 Image doesn't exist, will build ${FULL_IMAGE}"
          fi

      # Detect if running with act and set cache type accordingly
      - name: Set cache strategy
        id: cache-strategy
        run: |
          if [ "${ACT:-false}" = "true" ]; then
            echo "Running with act - using local cache"
            echo "cache_from=type=local,src=/tmp/buildx-cache" >> $GITHUB_OUTPUT
            echo "cache_to=type=local,dest=/tmp/buildx-cache-new,mode=max" >> $GITHUB_OUTPUT
            echo "cache_enabled=local" >> $GITHUB_OUTPUT
          else
            echo "Running on GitHub Actions - using GHA cache"
            echo "cache_from=type=gha,scope=${{ github.ref_name }}" >> $GITHUB_OUTPUT
            echo "cache_to=type=gha,mode=max,scope=${{ github.ref_name }}" >> $GITHUB_OUTPUT
            echo "cache_enabled=gha" >> $GITHUB_OUTPUT
          fi

      # Create cache directory for act
      - name: Prepare local cache directory (act only)
        if: env.ACT == 'true' || runner.os == 'act'
        run: |
          mkdir -p /tmp/buildx-cache
          echo "Created local cache directory for act"

      - name: Build and push Docker image
        id: build
        if: steps.check-rebuild.outputs.rebuild == 'true'
        uses: docker/build-push-action@v6
        with:
          context: .
          file: docker-images/Dockerfile_depictio.dockerfile
          platforms: linux/amd64
          push: ${{ env.ACT != 'true' }} # Push to registry unless using act
          load: ${{ env.ACT == 'true' }} # Load locally only when using act
          tags: ${{ steps.image-info.outputs.full-image }}
          cache-from: |
            ${{ steps.cache-strategy.outputs.cache_from }}
            ${{ env.ACT != 'true' && 'type=gha,scope=refs/heads/main' || '' }}
          cache-to: ${{ steps.cache-strategy.outputs.cache_to }}

      # Move cache for next run (act only)
      - name: Move cache (act only)
        if: (env.ACT == 'true' || runner.os == 'act') && steps.check-rebuild.outputs.rebuild == 'true'
        run: |
          rm -rf /tmp/buildx-cache
          mv /tmp/buildx-cache-new /tmp/buildx-cache || true

      - name: Pull image (GitHub Actions only)
        if: env.ACT != 'true' && steps.check-rebuild.outputs.rebuild == 'true'
        run: docker pull "${{ steps.image-info.outputs.full-image }}"

      - name: Tag image for local use (act only)
        if: env.ACT == 'true' || runner.os == 'act'
        run: |
          # When using act, tag the built image with the expected name
          docker tag "${{ steps.image-info.outputs.full-image }}" depictio:local || true
          echo "Tagged image for local use"

  docker-system-init:
    needs: docker-build
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    outputs:
      services-ready: ${{ steps.health.outputs.ready }}
    steps:
      - uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Configure Docker and directories
        run: |
          sudo usermod -aG docker $USER || true
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          mkdir -p depictioDB minio_data
          chmod 777 depictioDB minio_data

      - name: Start services
        run: |
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d

      - name: Logs
        run: sleep 3 && docker compose logs

      - name: Logs depictio-backend
        run: sleep 3 && docker compose logs depictio-backend

      - name: Wait and verify services
        id: health
        run: |
          echo "⏳ Waiting for services..."
          sleep 15
          docker compose ps

          # Extract token and health check
          for i in {1..5}; do
            if token=$(docker compose exec depictio-backend bash -c "cat /app/depictio/.depictio/admin_config.yaml" 2>/dev/null | grep 'access_token' | awk '{print $2}'); then
              token=$(echo $token | tr -d "'\"")
              health_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/utils/status)
              if [ "$health_check" = "200" ]; then
                echo "✅ Services ready"
                echo "ready=true" >> $GITHUB_OUTPUT
                exit 0
              fi
            fi
            echo "⚠️ Services not ready, attempt $i/5"
            sleep 10
          done
          echo "❌ Services failed to start"
          docker compose logs
          exit 1

      - name: Verify users and initial data
        run: |
          # Verify admin user
          ADMIN_USER=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.users.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.email == "admin@example.com" and .is_admin == true) | .email')
          [ -z "$ADMIN_USER" ] && echo "❌ Admin user not found" && exit 1

          # Verify test user
          TEST_USER=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.users.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.email == "test_user@example.com" and .is_admin == false) | .email')
          [ -z "$TEST_USER" ] && echo "❌ Test user not found" && exit 1

          echo "✅ Users verified: $ADMIN_USER, $TEST_USER"

      - name: Verify Iris integration from system initialization
        run: |
          # Verify project
          IRIS_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | .name')
          [ -z "$IRIS_PROJECT" ] && echo "❌ Iris project not found" && exit 1

          # Verify deltatable
          IRIS_DC_ID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | .workflows[0].data_collections[0]._id')
          IRIS_DT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$IRIS_DC_ID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$IRIS_DT" ] && echo "❌ Iris deltatable not found" && exit 1

          # Verify dashboard
          IRIS_PID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | ._id')
          IRIS_DASH=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.dashboards.find({\"project_id\": ObjectId(\"$IRIS_PID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$IRIS_DASH" ] && echo "❌ Iris dashboard not found" && exit 1

          echo "✅ Iris integration verified: Project=$IRIS_PROJECT, DT=$IRIS_DT, Dashboard=$IRIS_DASH"

      - name: Test Screenshot Generation - screenshot-dash-fixed
        run: |
          echo "📸 Testing screenshot generation functionality..."

          # Wait for services to be ready
          echo "⏳ Waiting for services to be ready..."
          for i in {1..30}; do
            if curl -s http://localhost:8058/depictio/api/v1/utils/status >/dev/null 2>&1; then
              echo "✅ Backend API is ready"
              break
            fi
            echo "⚠️ Backend not ready, attempt $i/30"
            sleep 10
          done

          # Test screenshot endpoint with actual Iris dashboard ID
          echo "🧪 Testing screenshot generation endpoint..."

          # Get the actual Iris dashboard ID from the database
          IRIS_PID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis") | ._id')
          DASHBOARD_ID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.dashboards.find({\"project_id\": ObjectId(\"$IRIS_PID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')

          if [ -z "$DASHBOARD_ID" ]; then
            echo "❌ No dashboard found for testing - skipping screenshot test"
            echo "✅ Screenshot endpoint test skipped (no dashboard available)"
            exit 0
          fi

          echo "📋 Using dashboard ID: $DASHBOARD_ID"

          # Debug: Check container status and logs before screenshot
          echo "🔍 Pre-screenshot debugging:"
          echo "📊 Container status:"
          docker compose ps

          echo "📋 Recent backend logs (last 20 lines):"
          docker compose logs --tail=20 depictio-backend || echo "Failed to get backend logs"

          echo "🌐 Testing basic API connectivity:"
          curl -s -o /dev/null -w "Status: %{http_code}, Time: %{time_total}s\n" http://localhost:8058/depictio/api/v1/utils/status || echo "API connectivity test failed"

          # Make the API call and capture response with timeout
          SCREENSHOT_RESPONSE=$(timeout 60s curl -s -w "\n%{http_code}" http://localhost:8058/depictio/api/v1/utils/screenshot-dash-fixed/$DASHBOARD_ID || echo -e "\nTIMEOUT")
          # SCREENSHOT_RESPONSE=$(curl -s -w "\n%{http_code}" http://localhost:8058/depictio/api/v1/dashboards/screenshot/$DASHBOARD_ID)

          # Extract HTTP status code (last line)
          HTTP_CODE=$(echo "$SCREENSHOT_RESPONSE" | tail -n1)

          # Extract JSON response (all lines except last)
          JSON_RESPONSE=$(echo "$SCREENSHOT_RESPONSE" | head -n -1)

          echo "📊 HTTP Status: $HTTP_CODE"

          # Debug: Check logs after screenshot attempt
          echo "🔍 Post-screenshot debugging:"
          echo "📋 Recent backend logs (last 30 lines after screenshot):"
          docker compose logs --tail=30 depictio-backend || echo "Failed to get backend logs"

          echo "📊 All container status after screenshot:"
          docker compose ps

          # Handle timeout case
          if [ "$HTTP_CODE" = "TIMEOUT" ]; then
            echo "⚠️ Screenshot generation timed out after 60 seconds"
            echo "📋 Backend logs during timeout (last 50 lines):"
            docker compose logs --tail=50 depictio-backend || echo "Failed to get timeout logs"
            echo "✅ Screenshot endpoint is accessible but slow - this may be expected in CI environment"
            exit 0
          elif [ "$HTTP_CODE" = "200" ]; then
            echo "✅ Screenshot endpoint responded successfully"

            # Parse and check response without logging sensitive data
            SUCCESS=$(echo "$JSON_RESPONSE" | jq -r '.success // false' 2>/dev/null)
            MESSAGE=$(echo "$JSON_RESPONSE" | jq -r '.message // "unknown"' 2>/dev/null)
            SCREENSHOT_PATH=$(echo "$JSON_RESPONSE" | jq -r '.screenshot_path // "unknown"' 2>/dev/null)
            URL=$(echo "$JSON_RESPONSE" | jq -r '.url // "unknown"' 2>/dev/null)

            echo "📋 Response details:"
            echo "  Success: $SUCCESS"
            echo "  Message: $MESSAGE"
            echo "  Screenshot path: $SCREENSHOT_PATH"
            echo "  URL: $URL"


            if [ "$SUCCESS" = "true" ]; then
              echo "✅ Screenshot generation successful"

              # Additional verification - check if screenshot path is valid
              if [[ "$SCREENSHOT_PATH" == *".png" ]]; then
                echo "✅ Screenshot path format is valid"
              else
                echo "⚠️  Screenshot path format may be invalid"
              fi

              # Optional: Verify screenshot file exists in container
              echo "🧪 Checking if screenshot file exists in backend container..."
              if docker compose exec -T depictio-backend test -f "$SCREENSHOT_PATH" 2>/dev/null; then
                echo "✅ Screenshot file exists in backend container"
              else
                echo "⚠️  Screenshot file not found in backend container (may be normal depending on setup)"
              fi

            else
              echo "❌ Screenshot generation failed"
              exit 1
            fi

          elif [ "$HTTP_CODE" = "404" ]; then
            echo "⚠️  Dashboard not found (expected for dummy ID) - testing endpoint availability only"
            echo "✅ Screenshot endpoint is accessible"
          else
            echo "❌ Screenshot endpoint failed with status: $HTTP_CODE"
            echo "Response: $JSON_RESPONSE"
            echo "📋 Backend logs on failure (last 50 lines):"
            docker compose logs --tail=50 depictio-backend || echo "Failed to get failure logs"
            echo "🔍 Full container logs on failure:"
            docker compose logs depictio-backend || echo "Failed to get full logs"
            exit 1
          fi

          # Final debug: Show summary logs
          echo "🔍 Final debugging summary:"
          echo "📊 Final container status:"
          docker compose ps

  cli-iris-single-file-test:
    needs: [docker-build]
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Setup environment
        run: |
          # Reuse setup from docker-system-init
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          mkdir -p depictioDB minio_data
          chmod 777 depictioDB minio_data

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d
          sleep 15

      - name: Setup CLI
        run: |
          cd depictio/cli
          pip install uv
          uv venv venv
          source venv/bin/activate
          uv pip install -e .
          docker cp depictio-backend:/app/depictio/.depictio/admin_config.yaml .

      - name: Run Iris CLI operations
        run: |
          cd depictio/cli
          source venv/bin/activate

          # Validate project config
          depictio-cli --verbose config validate-project-config \
            --project-config-path ../api/v1/configs/iris_dataset/initial_project_cli.yaml \
            --CLI-config-path admin_config.yaml

          # Sync project to server
          depictio-cli --verbose config sync-project-config-to-server \
            --update \
            --project-config-path ../api/v1/configs/iris_dataset/initial_project_cli.yaml \
            --CLI-config-path admin_config.yaml

          # Scan and process data
          depictio-cli --verbose data scan \
            --sync-files --rescan-folders \
            --project-config-path ../api/v1/configs/iris_dataset/initial_project_cli.yaml \
            --CLI-config-path admin_config.yaml

          depictio-cli --verbose data process \
            --overwrite \
            --project-config-path ../api/v1/configs/iris_dataset/initial_project_cli.yaml \
            --CLI-config-path admin_config.yaml

      - name: Verify Iris integration from CLI
        run: |
          # Verify project
          IRIS_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis CLI") | .name')
          [ -z "$IRIS_PROJECT" ] && echo "❌ Iris project not found" && exit 1

          # Verify deltatable
          IRIS_DC_ID=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Iris Dataset Project Data Analysis CLI") | .workflows[0].data_collections[0]._id')
          IRIS_DT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$IRIS_DC_ID\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$IRIS_DT" ] && echo "❌ Iris deltatable not found" && exit 1


          echo "✅ Iris integration verified: Project=$IRIS_PROJECT, DT=$IRIS_DT"

      - name: Upload logs on failure
        if: failure()
        run: |
          docker compose logs > iris-logs.txt
        continue-on-error: true

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: iris-integration-logs
          path: iris-logs.txt
          retention-days: 7

  cli-penguin-multi-file-test:
    needs: [docker-build]
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Setup environment
        run: |
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          mkdir -p depictioDB minio_data
          chmod 777 depictioDB minio_data

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d
          sleep 15

      - name: Setup CLI
        run: |
          cd depictio/cli
          pip install uv
          uv venv venv
          source venv/bin/activate
          uv pip install -e .
          docker cp depictio-backend:/app/depictio/.depictio/admin_config.yaml .

      - name: Run Penguin CLI operations
        run: |
          cd depictio/cli
          source venv/bin/activate

          # Validate project config
          depictio-cli --verbose config validate-project-config \
            --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml \
            --CLI-config-path admin_config.yaml

          # Sync project to server
          depictio-cli --verbose config sync-project-config-to-server \
            --update \
            --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml \
            --CLI-config-path admin_config.yaml

          # Scan and process data
          depictio-cli --verbose data scan \
            --sync-files --rescan-folders \
            --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml \
            --CLI-config-path admin_config.yaml

          depictio-cli --verbose data process \
            --overwrite \
            --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml \
            --CLI-config-path admin_config.yaml

          # Test full pipeline run
          sed -i 's/name: "Palmer Penguins Species Comparison"/name: "Palmer Penguins Species Comparison - RUN"/g' ../api/v1/configs/penguins_dataset/penguins_project.yaml
          depictio-cli run \
            --CLI-config-path admin_config.yaml \
            --project-config-path ../api/v1/configs/penguins_dataset/penguins_project.yaml

      - name: Verify Penguin integration
        run: |
          # Verify original project
          PENGUIN_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Palmer Penguins Species Comparison") | .name')
          [ -z "$PENGUIN_PROJECT" ] && echo "❌ Penguin project not found" && exit 1

          # Verify run project
          PENGUIN_RUN_PROJECT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Palmer Penguins Species Comparison - RUN") | .name')
          [ -z "$PENGUIN_RUN_PROJECT" ] && echo "❌ Penguin run project not found" && exit 1

          # Verify deltatables for run project
          PENGUIN_DC1=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.projects.find().toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.name == "Palmer Penguins Species Comparison - RUN") | .workflows[0].data_collections[0]._id')
          PENGUIN_DT1=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.deltatables.find({\"data_collection_id\": ObjectId(\"$PENGUIN_DC1\")}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[]._id // empty')
          [ -z "$PENGUIN_DT1" ] && echo "❌ Penguin deltatable 1 not found" && exit 1

          echo "✅ Penguin integration verified: Project=$PENGUIN_PROJECT, Run=$PENGUIN_RUN_PROJECT, DT1=$PENGUIN_DT1"

      - name: Upload logs on failure
        if: failure()
        run: |
          docker compose logs > penguin-logs.txt
        continue-on-error: true

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: penguin-integration-logs
          path: penguin-logs.txt
          retention-days: 7

  backup-s3-strategies-comprehensive-tests:
    needs: [docker-build]
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    strategy:
      fail-fast: false
      matrix:
        backup_strategy: [local, s3_to_s3, both]
        include:
          - backup_strategy: local
            strategy_name: "S3 to Local"
            s3_enabled: false
            expected_local_files: true
            expected_s3_files: false
          - backup_strategy: s3_to_s3
            strategy_name: "S3 to S3"
            s3_enabled: true
            expected_local_files: false
            expected_s3_files: true
          - backup_strategy: both
            strategy_name: "S3 to Both"
            s3_enabled: true
            expected_local_files: true
            expected_s3_files: true
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"
          cache-dependency-path: "pyproject.toml"

      - name: Setup environment for ${{ matrix.strategy_name }}
        run: |
          echo "🔧 Setting up environment for ${{ matrix.strategy_name }} backup strategy..."
          echo "🐳 Docker permissions and user setup..."
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          echo "UID: $(id -u), GID: $(id -g)"

          echo "📁 Creating environment files..."
          # Create root .env for Docker Compose variables
          cp .env.example .env
          echo "✅ Root .env file created"

          # Copy to docker-compose/.env for application variables
          cp .env.example docker-compose/.env
          echo "✅ docker-compose/.env file created"

          echo "⚙️ Configuring backup strategy in docker-compose/.env file..."
          # Remove any existing backup configuration first
          sed -i '/^DEPICTIO_BACKUP_/d' docker-compose/.env || echo "No existing backup config to remove"

          echo "" >> docker-compose/.env
          echo "# === BACKUP STRATEGY CONFIGURATION FOR CI ===" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_S3_BACKUP_STRATEGY=${{ matrix.backup_strategy }}" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_ENABLED=${{ matrix.s3_enabled }}" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_BUCKET=depictio-backup-bucket" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_ENDPOINT_URL=http://minio-backup:9000" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_REGION=us-east-1" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_ACCESS_KEY=backup_minio" >> docker-compose/.env
          echo "DEPICTIO_BACKUP_BACKUP_S3_SECRET_KEY=backup_minio123" >> docker-compose/.env

          echo "📋 Complete backup configuration for ${{ matrix.strategy_name }}:"
          grep "DEPICTIO_BACKUP" docker-compose/.env || echo "❌ No DEPICTIO_BACKUP vars found!"

          echo "📂 Creating required directories..."
          mkdir -p depictioDB minio_data minio_backup_data
          chmod 777 depictioDB minio_data minio_backup_data
          # Ensure MongoDB can create additional directories
          chmod -R 777 depictioDB 2>/dev/null || echo "Directory permissions already set"
          ls -la depictioDB minio_data minio_backup_data
          echo "✅ Directories created and permissions set"

      - name: Log in and start services for ${{ matrix.strategy_name }}
        run: |
          echo "🚀 Starting services for ${{ matrix.strategy_name }} backup strategy..."

          echo "🔐 Logging into container registry..."
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin

          echo "🐳 Setting up Docker image..."
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          echo "Using image: $FULL_IMAGE"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          echo "DEPICTIO_VERSION set to: $DEPICTIO_VERSION"

          echo "📋 Final environment file content before starting services:"
          echo "=== ALL DEPICTIO_BACKUP VARIABLES ==="
          grep "DEPICTIO_BACKUP" docker-compose/.env || echo "❌ No DEPICTIO_BACKUP vars found!"
          echo "=== SAMPLE OF OTHER ENVIRONMENT VARIABLES ==="
          head -10 docker-compose/.env
          echo "=================================="

          echo "🐳 Starting Docker Compose services..."
          echo "Compose files: docker-compose.dev.yaml + docker-compose.minio.yaml + docker-compose.backup-minio.yaml"
          echo "Environment file: docker-compose/.env"

          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml -f docker-compose/docker-compose.backup-minio.yaml up -d --force-recreate

          echo "⏳ Waiting 30 seconds for services to start..."
          sleep 30

          echo "📊 Verifying services are running..."
          docker compose ps

          echo "🔍 Checking individual container status..."
          echo "--- Depictio Backend ---"
          docker compose logs --tail=10 depictio-backend || echo "❌ Backend logs not available"
          echo "--- Main MinIO ---"
          docker compose logs --tail=5 minio || echo "❌ MinIO logs not available"
          echo "--- Backup MinIO ---"
          docker compose logs --tail=5 minio-backup || echo "❌ Backup MinIO logs not available"
          echo "--- MongoDB ---"
          docker compose logs --tail=10 mongo || echo "❌ MongoDB logs not available"

          # Wait for backup MinIO to be ready and create bucket
          echo "⏳ Waiting for backup MinIO to be ready..."
          sleep 10

          echo "🔧 Testing backup MinIO connectivity and creating bucket..."
          docker compose exec -T depictio-backend python3 -c "
          import boto3
          import time
          from botocore.exceptions import ClientError

          print('🔍 Attempting to connect to backup MinIO...')
          print('Endpoint: http://minio-backup:9000')
          print('Access Key: backup_minio')
          print('Secret Key: backup_minio123')

          # Wait for backup MinIO to be ready
          for i in range(30):
              try:
                  client = boto3.client('s3',
                      endpoint_url='http://minio-backup:9000',
                      aws_access_key_id='backup_minio',
                      aws_secret_access_key='backup_minio123',
                      region_name='us-east-1')
                  response = client.list_buckets()
                  print(f'✅ Backup MinIO ready after {i+1} attempts')
                  print(f'📋 Current buckets: {[b[\"Name\"] for b in response.get(\"Buckets\", [])]}')
                  break
              except Exception as e:
                  print(f'⚠️ Backup MinIO not ready (attempt {i+1}/30): {e}')
                  if i < 5:  # Show detailed error for first few attempts
                      import traceback
                      traceback.print_exc()
                  time.sleep(2)
          else:
              print('❌ Backup MinIO failed to start after 30 attempts')
              print('🔍 Final connection attempt with full error details:')
              try:
                  client = boto3.client('s3',
                      endpoint_url='http://minio-backup:9000',
                      aws_access_key_id='backup_minio',
                      aws_secret_access_key='backup_minio123',
                      region_name='us-east-1')
                  client.list_buckets()
              except Exception as final_e:
                  import traceback
                  traceback.print_exc()
              exit(1)

          # Create backup bucket
          print('🪣 Creating backup bucket...')
          try:
              client.create_bucket(Bucket='depictio-backup-bucket')
              print('✅ Backup bucket created successfully')
          except ClientError as e:
              if e.response['Error']['Code'] == 'BucketAlreadyOwnedByYou':
                  print('✅ Backup bucket already exists')
              else:
                  print(f'❌ Failed to create backup bucket: {e}')
                  exit(1)

          # Final verification
          final_buckets = client.list_buckets()
          print(f'📋 Final bucket list: {[b[\"Name\"] for b in final_buckets.get(\"Buckets\", [])]}')
          "

          echo "✅ Services started for ${{ matrix.strategy_name }} strategy"

      - name: Setup CLI for ${{ matrix.strategy_name }}
        run: |
          echo "🔧 Setting up CLI for ${{ matrix.strategy_name }} testing..."

          echo "📁 Navigating to CLI directory..."
          cd depictio/cli

          echo "🐍 Creating Python virtual environment..."
          uv venv --python 3.11 venv
          source venv/bin/activate
          echo "Python version: $(python --version)"
          echo "Pip version: $(pip --version)"

          echo "📦 Installing CLI dependencies..."
          uv pip install --upgrade pip
          uv pip install -e .
          echo "✅ CLI dependencies installed"

          echo "🔑 Copying admin configuration from backend container..."
          docker cp depictio-backend:/app/depictio/.depictio/admin_config.yaml .
          echo "📋 Admin config file copied, checking contents..."
          ls -la admin_config.yaml
          head -5 admin_config.yaml | grep -v "token" || echo "Config file structure check"

          echo "✅ CLI setup completed for ${{ matrix.strategy_name }}"

      - name: Wait for system initialization - ${{ matrix.strategy_name }}
        run: |
          echo "⏳ Waiting for system initialization for ${{ matrix.strategy_name }}..."

          echo "🔑 Extracting authentication token for health checks..."
          # Verify system is ready
          for i in {1..10}; do
            echo "🔍 Health check attempt $i/10..."

            if token=$(docker compose exec depictio-backend bash -c "cat /app/depictio/.depictio/admin_config.yaml" 2>/dev/null | grep 'access_token' | awk '{print $2}'); then
              token=$(echo $token | tr -d "'\"")
              echo "✅ Token extracted successfully (length: ${#token})"

              echo "🌐 Testing API health endpoint..."
              health_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/utils/status)
              echo "📊 Health check response: HTTP $health_check"

              if [ "$health_check" = "200" ]; then
                echo "✅ System ready for ${{ matrix.strategy_name }}"

                echo "🔍 Testing additional API endpoints..."
                # Test projects endpoint
                projects_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/projects/get/all)
                echo "📊 Projects endpoint: HTTP $projects_check"

                # Test backup endpoint
                backup_check=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $token" http://localhost:8058/depictio/api/v1/backup/list)
                echo "📊 Backup endpoint: HTTP $backup_check"

                break
              else
                echo "⚠️ Health check failed with HTTP $health_check"
              fi
            else
              echo "❌ Failed to extract token from admin config"
            fi

            echo "⚠️ System not ready for ${{ matrix.strategy_name }}, attempt $i/10"
            echo "🔍 Backend container logs (last 5 lines):"
            docker compose logs --tail=5 depictio-backend || echo "Failed to get logs"
            sleep 15
          done

          echo "⏳ Additional stabilization period..."
          sleep 30

          echo "📊 Final container status before backup testing:"
          docker compose ps

      - name: Create backup with ${{ matrix.strategy_name }} strategy
        run: |
          echo "💾 Creating backup with ${{ matrix.strategy_name }} strategy..."
          cd depictio/cli
          source venv/bin/activate

          # Show current backup configuration from backend
          echo "📋 Checking backend configuration and database state..."

          echo "🔍 Checking environment variables in backend container..."
          docker compose exec -T depictio-backend bash -c "env | grep DEPICTIO_BACKUP || echo 'No DEPICTIO_BACKUP env vars found'"

          echo "📋 Backend backup configuration:"
          docker compose exec -T depictio-backend python3 -c "
          import os;
          print('=== ENVIRONMENT VARIABLES ===');
          for key, value in os.environ.items():
              if 'DEPICTIO_BACKUP' in key:
                  print(f'{key}={value}');
          print('=== LOADED SETTINGS ===');
          from depictio.api.v1.configs.config import settings;
          print(f'Backup Strategy: {settings.backup.s3_backup_strategy}');
          print(f'Backup S3 Enabled: {settings.backup.backup_s3_enabled}');
          print(f'Backup S3 Bucket: {settings.backup.backup_s3_bucket}');
          print(f'Backup S3 Endpoint: {settings.backup.backup_s3_endpoint_url}');
          print(f'S3 Local Backup Path: {settings.backup.s3_local_backup_path}');
          print(f'Compress Local Backups: {settings.backup.compress_local_backups}');

          print('\n=== SOURCE S3 CONFIGURATION ===');
          print(f'Source MinIO Bucket: {settings.minio.bucket}');
          print(f'Source MinIO Endpoint: {settings.minio.endpoint_url}');

          # Test connectivity to both MinIO instances
          import boto3;
          print('\n=== CONNECTIVITY TESTS ===');

          # Test source MinIO
          try:
              source_client = boto3.client('s3',
                  endpoint_url=settings.minio.endpoint_url,
                  aws_access_key_id=settings.minio.aws_access_key_id,
                  aws_secret_access_key=settings.minio.aws_secret_access_key,
                  region_name='us-east-1');
              source_buckets = source_client.list_buckets();
              print(f'✅ Source MinIO accessible, buckets: {[b[\"Name\"] for b in source_buckets.get(\"Buckets\", [])]}');

              # Check if source bucket has any deltatable data
              if settings.minio.bucket in [b[\"Name\"] for b in source_buckets.get(\"Buckets\", [])]:
                  objects = source_client.list_objects_v2(Bucket=settings.minio.bucket);
                  object_count = len(objects.get('Contents', []));
                  print(f'📊 Source bucket objects count: {object_count}');
                  if object_count > 0:
                      print('📋 Sample objects:');
                      for obj in objects.get('Contents', [])[:5]:
                          print(f'  - {obj[\"Key\"]} ({obj[\"Size\"]} bytes)');
              else:
                  print(f'❌ Source bucket {settings.minio.bucket} not found');
          except Exception as e:
              print(f'❌ Source MinIO not accessible: {e}');
              import traceback;
              traceback.print_exc();

          # Test backup MinIO
          try:
              backup_client = boto3.client('s3',
                  endpoint_url='http://minio-backup:9000',
                  aws_access_key_id='backup_minio',
                  aws_secret_access_key='backup_minio123',
                  region_name='us-east-1');
              backup_buckets = backup_client.list_buckets();
              print(f'✅ Backup MinIO accessible, buckets: {[b[\"Name\"] for b in backup_buckets.get(\"Buckets\", [])]}');
          except Exception as e:
              print(f'❌ Backup MinIO not accessible: {e}');
              import traceback;
              traceback.print_exc();
          "

          echo ""
          echo "📊 Database state analysis..."

          echo "🔍 Testing MongoDB connectivity..."
          docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "print('MongoDB connection test: ' + new Date())" --quiet || echo "❌ MongoDB query failed"

          # Show deltatable count before backup with error handling
          echo "📊 Querying deltatables collection..."
          DELTATABLE_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
          try {
            var count = db.deltatables.countDocuments({});
            print('Deltatable count: ' + count);
            print(count);
          } catch(e) {
            print('Error counting deltatables: ' + e);
            print('0');
          }" --quiet 2>&1 | tail -1)
          echo "📊 Total deltatables in database: $DELTATABLE_COUNT"

          # Show project count
          PROJECT_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
          try {
            var count = db.projects.countDocuments({});
            print('Project count: ' + count);
            print(count);
          } catch(e) {
            print('Error counting projects: ' + e);
            print('0');
          }" --quiet 2>&1 | tail -1)
          echo "📊 Total projects in database: $PROJECT_COUNT"

          # Debug database collections
          echo "🔍 Available collections:"
          docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "db.listCollectionNames()" --quiet || echo "❌ Failed to list collections"

          if [ "$DELTATABLE_COUNT" -gt 0 ]; then
            echo "📋 Deltatable details (first 3):"
            docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
            db.deltatables.find({}).limit(3).forEach(function(doc) {
              var location = doc.delta_table_location || doc.location || 'no location';
              print('ID: ' + doc._id + ', Location: ' + location + ', Collection: ' + (doc.data_collection_id || 'no collection'));
            })" --quiet
          else
            echo "⚠️  No deltatables found in database - backup will have no S3 data to process"
            echo "🔍 Checking if system initialization completed..."
            docker compose logs --tail=20 depictio-backend | grep -i "iris\|init\|startup" || echo "No initialization logs found"
          fi

          # Create backup with strategy-specific prefix
          echo ""
          echo "🚀 Starting backup creation with detailed logging..."
          echo "Command: depictio-cli -v -vl DEBUG backup create --CLI-config-path admin_config.yaml --include-s3-data --s3-backup-prefix ci_${{ matrix.backup_strategy }}_backup"
          echo "Strategy: ${{ matrix.backup_strategy }}"
          echo "Expected S3 files: ${{ matrix.expected_s3_files }}"
          echo "Expected local files: ${{ matrix.expected_local_files }}"
          echo ""

          # Set up timing
          START_TIME=$(date +%s)

          # Run backup command with full debugging
          if depictio-cli -v -vl DEBUG backup create \
            --CLI-config-path admin_config.yaml \
            --include-s3-data \
            --s3-backup-prefix "ci_${{ matrix.backup_strategy }}_backup"; then
            END_TIME=$(date +%s)
            DURATION=$((END_TIME - START_TIME))
            echo "✅ Backup creation completed successfully for ${{ matrix.strategy_name }} in ${DURATION}s"
          else
            EXIT_CODE=$?
            END_TIME=$(date +%s)
            DURATION=$((END_TIME - START_TIME))
            echo "❌ Backup creation failed for ${{ matrix.strategy_name }} after ${DURATION}s with exit code $EXIT_CODE"

            echo "🔍 Backend logs after failed backup:"
            docker compose logs --tail=30 depictio-backend

            echo "🔍 CLI debug information:"
            ls -la admin_config.yaml
            echo "Environment variables:"
            env | grep DEPICTIO | head -10

            exit $EXIT_CODE
          fi

          echo ""
          echo "📊 Post-backup analysis..."

          # Check what was created after backup
          echo "📁 Checking backup directory structure after backup..."
          docker compose exec -T depictio-backend find /app/depictio/backups -type f -name "*" 2>/dev/null | head -10 || echo "No backup files found"

          if [ "${{ matrix.expected_local_files }}" = "true" ]; then
            echo "📂 Checking for local S3 backup files..."
            docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -type f -name "*" 2>/dev/null | head -5 || echo "No S3 local backup files found"
          fi

      - name: Verify S3 local backup files - ${{ matrix.strategy_name }}
        if: matrix.expected_local_files == true
        run: |
          echo "📁 Verifying local backup files for ${{ matrix.strategy_name }} strategy..."

          # Check if local backup files exist in the backend container
          echo "🔍 Checking for local backup files in backend container..."
          echo "📂 Listing backup directory structure:"
          docker compose exec -T depictio-backend find /app/depictio/backups -type d -name "*" 2>/dev/null || echo "Backup directory not found, checking if it exists..."
          docker compose exec -T depictio-backend ls -la /app/depictio/backups 2>/dev/null || echo "Main backup directory doesn't exist"
          docker compose exec -T depictio-backend ls -la /app/depictio/backups/s3_data_backups 2>/dev/null || echo "S3 backup directory doesn't exist"

          # Look for backup files by checking prefix directory
          DATE=$(date +%Y%m%d)
          echo "🔍 Searching for backup files with date prefix $DATE..."

          # Check for any backup files in the s3_data_backups directory with current date
          BACKUP_COUNT=$(docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "ci_${{ matrix.backup_strategy }}_backup" -type d 2>/dev/null | wc -l)
          echo "Found $BACKUP_COUNT backup prefix directories"

          if [ "$BACKUP_COUNT" -gt 0 ]; then
            echo "✅ Local backup directory found for ${{ matrix.strategy_name }}"
            docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "ci_${{ matrix.backup_strategy }}_backup" -type d -exec ls -la {} \;

            # Check for actual data files inside backup directories
            FILE_COUNT=$(docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "*.parquet" -o -name "*.json" -o -name "*${DATE}*" 2>/dev/null | wc -l)
            echo "Found $FILE_COUNT actual backup files"

            if [ "$FILE_COUNT" -gt 0 ]; then
              echo "✅ Local backup files verified for ${{ matrix.strategy_name }}"
              docker compose exec -T depictio-backend find /app/depictio/backups/s3_data_backups -name "*.parquet" -o -name "*.json" -o -name "*${DATE}*" 2>/dev/null | head -10
            else
              echo "⚠️  Backup directory exists but no files found"
            fi
          else
            echo "❌ No local backup directories found for ${{ matrix.strategy_name }}"
            exit 1
          fi

      - name: Verify S3 backup files - ${{ matrix.strategy_name }}
        if: matrix.expected_s3_files == true
        run: |
          echo "☁️ Verifying S3 backup files for ${{ matrix.strategy_name }} strategy..."

          # Check if backup files exist on local backup MinIO
          echo "📋 Checking S3 backup files in local backup MinIO for ${{ matrix.strategy_name }}..."
          docker compose exec -T depictio-backend python3 -c "
          import boto3;
          try:
              print('🔍 Connecting to backup MinIO...');
              client = boto3.client('s3',
                  endpoint_url='http://minio-backup:9000',
                  aws_access_key_id='backup_minio',
                  aws_secret_access_key='backup_minio123',
                  region_name='us-east-1');

              # Test connection first
              print('📋 Testing backup MinIO connection...');
              buckets = client.list_buckets();
              print(f'Available buckets: {[b[\"Name\"] for b in buckets.get(\"Buckets\", [])]}');

              # List all objects in the bucket for debugging
              print('📋 Listing all objects in backup bucket...');
              all_response = client.list_objects_v2(Bucket='depictio-backup-bucket');
              all_files = all_response.get('Contents', []);
              if all_files:
                  print(f'📊 Total objects in backup bucket: {len(all_files)}');
                  for f in all_files:
                      print(f'  - {f[\"Key\"]} ({f[\"Size\"]} bytes)');
              else:
                  print('📊 No objects found in backup bucket');

              # Now check for specific prefix
              print(f'🔍 Searching for files with prefix: ci_${{ matrix.backup_strategy }}_backup/');
              response = client.list_objects_v2(Bucket='depictio-backup-bucket', Prefix='ci_${{ matrix.backup_strategy }}_backup/');
              files = response.get('Contents', []);
              parquet_files = [f for f in files if f['Key'].endswith('.parquet')];
              print(f'✅ ${{ matrix.strategy_name }}: Found {len(files)} total files, {len(parquet_files)} parquet files');

              # List backup files with prefix for debugging
              if files:
                  print('📋 Prefix-specific backup files found:');
                  for f in files:
                      print(f'  - {f[\"Key\"]} ({f[\"Size\"]} bytes)');

              if len(files) == 0:
                  print('❌ No S3 backup files found for ${{ matrix.strategy_name }}');
                  exit(1);
              else:
                  print('✅ S3 backup verification successful for ${{ matrix.strategy_name }}');
          except Exception as e:
              print(f'❌ S3 verification failed for ${{ matrix.strategy_name }}: {e}');
              import traceback;
              traceback.print_exc();
              exit(1);
          "

      - name: Verify backup strategy behavior - ${{ matrix.strategy_name }}
        run: |
          echo "🔍 Verifying ${{ matrix.strategy_name }} backup strategy behavior..."
          cd depictio/cli
          source venv/bin/activate

          # List backups and get the latest one
          BACKUP_LIST=$(depictio-cli backup list --CLI-config-path admin_config.yaml)
          echo "Available backups for ${{ matrix.strategy_name }}: $BACKUP_LIST"

          # Validate backup integrity
          BACKUP_ID=$(echo "$BACKUP_LIST" | grep -o '"backup_id": "[^"]*"' | head -1 | cut -d'"' -f4)
          echo "Using backup ID for ${{ matrix.strategy_name }}: $BACKUP_ID"

          if [ -n "$BACKUP_ID" ]; then
            depictio-cli -v -vl DEBUG backup validate "$BACKUP_ID" --CLI-config-path admin_config.yaml
            echo "✅ Backup validation successful for ${{ matrix.strategy_name }}"
          else
            echo "❌ No backup ID found for ${{ matrix.strategy_name }}"
            exit 1
          fi

      - name: Test backup restoration - ${{ matrix.strategy_name }}
        run: |
          echo "♻️ Testing backup restoration for ${{ matrix.strategy_name }}..."
          cd depictio/cli
          source venv/bin/activate

          # Drop some test data for restoration test
          docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "
            var dashboardCount = db.dashboards.countDocuments({});
            print('Dashboards before deletion for ${{ matrix.strategy_name }}: ' + dashboardCount);
            if (dashboardCount > 0) {
              db.dashboards.deleteMany({});
              print('Dashboards after deletion for ${{ matrix.strategy_name }}: ' + db.dashboards.countDocuments({}));
            }
          "

          # Get backup ID and restore
          BACKUP_LIST=$(depictio-cli backup list --CLI-config-path admin_config.yaml)
          BACKUP_ID=$(echo "$BACKUP_LIST" | grep -o '"backup_id": "[^"]*"' | head -1 | cut -d'"' -f4)

          if [ -n "$BACKUP_ID" ]; then
            echo "🔄 Performing restore test for ${{ matrix.strategy_name }}..."
            depictio-cli -v -vl DEBUG backup restore "$BACKUP_ID" \
              --CLI-config-path admin_config.yaml \
              --force

            # Verify restoration
            DASHBOARD_COUNT=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "db.dashboards.countDocuments({})" --quiet)
            echo "Dashboards after restore for ${{ matrix.strategy_name }}: $DASHBOARD_COUNT"

            echo "✅ Backup restoration test completed for ${{ matrix.strategy_name }}"
          else
            echo "❌ No backup ID found for restoration test"
            exit 1
          fi

      - name: Cleanup and summary - ${{ matrix.strategy_name }}
        run: |
          echo "🧹 Cleanup and summary for ${{ matrix.strategy_name }}..."

          # Show final status
          echo "📊 Final status for ${{ matrix.strategy_name }} backup strategy:"
          echo "- Strategy: ${{ matrix.backup_strategy }}"
          echo "- S3 Enabled: ${{ matrix.s3_enabled }}"
          echo "- Expected Local Files: ${{ matrix.expected_local_files }}"
          echo "- Expected S3 Files: ${{ matrix.expected_s3_files }}"

          # Stop services for this iteration
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml -f docker-compose/docker-compose.backup-minio.yaml down
          echo "✅ ${{ matrix.strategy_name }} backup strategy test completed successfully"

      - name: Upload logs on failure
        if: failure()
        run: |
          docker compose logs > backup-${{ matrix.backup_strategy }}-logs.txt
          cd depictio/cli && ls -la >> ../backup-${{ matrix.backup_strategy }}-logs.txt
        continue-on-error: true

      - name: Upload artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: backup-${{ matrix.backup_strategy }}-logs
          path: backup-${{ matrix.backup_strategy }}-logs.txt
          retention-days: 7

  e2e-tests:
    needs: [docker-build]
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Setup environment
        run: |
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          # Enable dev mode
          sed -i 's/# DEV_MODE=false/DEV_MODE=true/' docker-compose/.env
          mkdir -p depictioDB minio_data
          chmod 777 depictioDB minio_data

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml up -d
          sleep 15

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "16"

      - name: Install Chrome
        run: |
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Install Cypress dependencies
        run: |
          cd depictio/tests/e2e-tests
          if [ ! -f "package.json" ]; then
            npm init -y
            npm install cypress --save-dev
          else
            npm ci
          fi

      - name: Run Cypress tests
        run: |
          cd depictio/tests/e2e-tests
          export CYPRESS_UNAUTHENTICATED_MODE=false
          # Set Chrome flags for better CI rendering and stability
          export CYPRESS_BROWSER_ARGS="--disable-gpu --no-sandbox --disable-dev-shm-usage --disable-extensions --disable-background-timer-throttling --disable-renderer-backgrounding --disable-backgrounding-occluded-windows"
          # Run Chrome in headless mode for CI with improved stability
          npx cypress run \
            --browser chrome \
            --headless \
            --config screenshotsFolder=cypress/screenshots,videosFolder=cypress/videos,trashAssetsBeforeRuns=false,video=true,screenshotOnRunFailure=true,viewportWidth=1920,viewportHeight=1080,chromeWebSecurity=false \
            --spec "cypress/e2e/!(unauthenticated)/**/*.cy.js"

      - name: Upload screenshots
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cypress-screenshots
          path: depictio/tests/e2e-tests/cypress/screenshots
          retention-days: 30

      - name: Upload videos on failure
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: cypress-videos
          path: depictio/tests/e2e-tests/cypress/videos
          retention-days: 7

  e2e-tests-unauthenticated:
    needs: [docker-build]
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Setup environment
        run: |
          sudo chmod 666 /var/run/docker.sock
          echo "UID=$(id -u)" >> $GITHUB_ENV
          echo "GID=$(id -g)" >> $GITHUB_ENV
          cp .env.example .env
          # Enable unauthenticated mode
          sed -i 's/# DEPICTIO_AUTH_UNAUTHENTICATED_MODE=false/DEPICTIO_AUTH_UNAUTHENTICATED_MODE=true/' docker-compose/.env
          sed -i 's/# DEV_MODE=false/DEV_MODE=true/' docker-compose/.env
          mkdir -p depictioDB minio_data
          chmod 777 depictioDB minio_data

      - name: Log in and start services
        run: |
          echo ${{ secrets.GHCR_PAT }} | docker login ghcr.io -u ${{ github.repository_owner }} --password-stdin
          FULL_IMAGE="${{ needs.docker-build.outputs.full-image }}"
          docker pull "${FULL_IMAGE}"
          export DEPICTIO_VERSION="${FULL_IMAGE}"
          docker compose -f docker-compose.dev.yaml -f docker-compose/docker-compose.minio.yaml --env-file docker-compose/.env up -d
          sleep 15

      - name: Show .env files
        run: |
          echo "📋 Environment variables in docker-compose/.env:"
          cat docker-compose/.env || echo "❌ .env file not found"
          echo "📋 Environment variables in .env.example:"
          cat .env.example || echo "❌ .env.example file not found"
          echo "📋 Environment variables in .env:"
          cat .env || echo "❌ .env file not found"

      - name: Log backend container status
        run: |
          echo "📊 Backend container status:"
          docker compose ps depictio-backend || echo "❌ Backend container not running"
          docker compose logs depictio-backend || echo "❌ Failed to get backend logs"

      - name: Verify unauthenticated mode is enabled
        run: |
          echo "🔍 Verifying unauthenticated mode configuration..."

          # Check if anonymous user was created
          for i in {1..10}; do
            ANON_USER=$(docker compose exec -T mongo mongosh localhost:27018/depictioDB --eval "JSON.stringify(db.users.find({email: 'anonymous@depict.io'}).toArray())" --quiet 2>&1 | grep '^[\[{]' | jq -r '.[] | select(.email == "anonymous@depict.io") | .email')
            if [ -n "$ANON_USER" ]; then
              echo "✅ Anonymous user found: $ANON_USER"
              break
            fi
            echo "⚠️ Anonymous user not found, attempt $i/10"
            sleep 5
          done
          [ -z "$ANON_USER" ] && echo "❌ Anonymous user not found" && exit 1

          # Verify frontend bypasses auth
          echo "🌐 Testing unauthenticated access to frontend..."
          curl -s -o /dev/null -w "%{http_code}" http://localhost:5080/ | grep -q "200" && echo "✅ Frontend accessible without authentication" || (echo "❌ Frontend not accessible" && exit 1)

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "16"

      - name: Install Cypress dependencies
        run: |
          cd depictio/tests/e2e-tests
          if [ ! -f "package.json" ]; then
            npm init -y
            npm install cypress --save-dev
          else
            npm ci
          fi

      - name: Install Chrome for unauthenticated tests
        run: |
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Run Cypress unauthenticated tests
        run: |
          cd depictio/tests/e2e-tests
          # Set environment variable for cypress to know it's unauthenticated mode
          export CYPRESS_UNAUTHENTICATED_MODE=true
          # Set Chrome flags for better CI rendering and stability
          export CYPRESS_BROWSER_ARGS="--disable-gpu --no-sandbox --disable-dev-shm-usage --disable-extensions --disable-background-timer-throttling --disable-renderer-backgrounding --disable-backgrounding-occluded-windows"
          npx cypress run \
            --browser chrome \
            --headless \
            --config screenshotsFolder=cypress/screenshots-unauthenticated,videosFolder=cypress/videos-unauthenticated,trashAssetsBeforeRuns=false,video=true,screenshotOnRunFailure=true,viewportWidth=1920,viewportHeight=1080,chromeWebSecurity=false \
            --spec "cypress/e2e/unauthenticated/**/*.cy.js"

      - name: Upload screenshots
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cypress-screenshots-unauthenticated
          path: depictio/tests/e2e-tests/cypress/screenshots-unauthenticated
          retention-days: 30

      - name: Upload videos on failure
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: cypress-videos-unauthenticated
          path: depictio/tests/e2e-tests/cypress/videos-unauthenticated
          retention-days: 7
