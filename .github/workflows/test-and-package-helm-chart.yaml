name: Test, Build and Push Helm Chart

on:
  push:
    branches: [ main ]
    paths:
      - "helm-charts/depictio/**"
      - "docker-images/Dockerfile_depictio_uv.dockerfile"
      - ".github/workflows/test-and-package-helm-chart.yaml"
  pull_request:
    branches: [ main ]
    paths:
      - "helm-charts/depictio/**"
      - "docker-images/Dockerfile_depictio_uv.dockerfile"
      - ".github/workflows/test-and-package-helm-chart.yaml"
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  CHART_NAME: depictio-helm

jobs:
  test-build-push:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: "v3.14.0"

      - name: Extract chart metadata
        id: chart-info
        run: |
          CHART_VERSION=$(helm show chart ./helm-charts/depictio | grep '^version:' | awk '{print $2}')
          APP_VERSION=$(helm show chart ./helm-charts/depictio | grep '^appVersion:' | awk '{print $2}' | tr -d '"')
          echo "chart_version=${CHART_VERSION}" >> $GITHUB_OUTPUT
          echo "app_version=${APP_VERSION}" >> $GITHUB_OUTPUT
          echo "Chart version: ${CHART_VERSION}"
          echo "App version: ${APP_VERSION}"

      - name: Set up Minikube
        uses: medyagh/setup-minikube@master
        with:
          minikube-version: "1.35.0"
          kubernetes-version: "v1.32.0"
          driver: docker
          start-args: "--memory=4096 --cpus=2"

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}

      - name: Generate image info
        id: image-info
        run: |
          REPO_LOWER=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            TAG="pr-${{ github.event.number }}-${{ github.sha }}"
          else
            TAG="main-${{ github.sha }}"
          fi
          echo "tag=${TAG}" >> $GITHUB_OUTPUT
          echo "repo=${REPO_LOWER}" >> $GITHUB_OUTPUT
          echo "full-image=ghcr.io/${REPO_LOWER}:${TAG}" >> $GITHUB_OUTPUT

      - name: Check if rebuild needed
        id: check-rebuild
        run: |
          FULL_IMAGE="${{ steps.image-info.outputs.full-image }}"
          if docker manifest inspect "${FULL_IMAGE}" > /dev/null 2>&1; then
            echo "rebuild=false" >> $GITHUB_OUTPUT
            echo "‚úÖ Image ${FULL_IMAGE} already exists, skipping build"
          else
            echo "rebuild=true" >> $GITHUB_OUTPUT
            echo "üî® Image doesn't exist, will build ${FULL_IMAGE}"
          fi

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push Docker image
        id: build
        if: steps.check-rebuild.outputs.rebuild == 'true'
        uses: docker/build-push-action@v6
        with:
          context: .
          file: docker-images/Dockerfile_depictio_uv.dockerfile
          platforms: linux/amd64
          push: true
          load: false
          tags: ${{ steps.image-info.outputs.full-image }}
          cache-from: |
            type=gha,scope=${{ github.ref_name }}
            type=gha,scope=refs/heads/main
          cache-to: type=gha,mode=max,scope=${{ github.ref_name }}

      - name: Pull image to Minikube
        run: |
          eval $(minikube docker-env)
          docker pull "${{ steps.image-info.outputs.full-image }}"
          docker tag "${{ steps.image-info.outputs.full-image }}" "depictio:${{ steps.chart-info.outputs.app_version }}"
          docker images | grep depictio

      - name: Get Kubernetes cluster info
        run: |
          kubectl cluster-info
          kubectl get nodes
          kubectl version

      - name: Lint Helm chart
        run: |
          helm lint ./helm-charts/depictio

      - name: Test chart packaging
        run: |
          # Package the chart
          helm package ./helm-charts/depictio --version ${{ steps.chart-info.outputs.chart_version }}

          # Verify package was created
          ls -la depictio-*.tgz

          # Test chart from package
          helm template test-release ./depictio-${{ steps.chart-info.outputs.chart_version }}.tgz > /tmp/rendered-manifests.yaml
          echo "Successfully rendered chart from package"

      - name: Validate Kubernetes manifests
        run: |
          echo "üîç Validating rendered Kubernetes manifests..."

          # Check for required resources
          if ! grep -q "kind: Deployment" /tmp/rendered-manifests.yaml; then
            echo "‚ùå No Deployment found in manifests"
            exit 1
          fi

          if ! grep -q "kind: Service" /tmp/rendered-manifests.yaml; then
            echo "‚ùå No Service found in manifests"
            exit 1
          fi

          echo "‚úÖ Basic manifest validation passed"

      - name: Generate random release name
        id: release-info
        run: |
          # Generate DNS-compliant release name: letter + 9 random hex chars
          RANDOM_SUFFIX=$(openssl rand -hex 4 | cut -c1-9)
          RELEASE_NAME="r${RANDOM_SUFFIX}"
          echo "release_name=${RELEASE_NAME}" >> $GITHUB_OUTPUT
          echo "üé≤ Generated DNS-compliant release name: ${RELEASE_NAME}"

          # Validate the name meets DNS requirements
          if [[ $RELEASE_NAME =~ ^[a-z][a-z0-9-]*[a-z0-9]$ ]]; then
            echo "‚úÖ Release name is DNS-compliant"
          else
            echo "‚ùå Release name validation failed: $RELEASE_NAME"
            exit 1
          fi

      - name: Install Helm chart (from local directory)
        run: |
          echo "üì¶ Installing Helm chart..."
          echo "Release name: ${{ steps.release-info.outputs.release_name }}"
          echo "App version: ${{ steps.chart-info.outputs.app_version }}"

          helm upgrade --install ${{ steps.release-info.outputs.release_name }} ./helm-charts/depictio \
            -f ./helm-charts/depictio/values.yaml \
            -f ./helm-charts/depictio/values-gh-actions.yaml \
            --set backend.image.repository=depictio \
            --set backend.image.tag=${{ steps.chart-info.outputs.app_version }} \
            --set backend.image.pullPolicy=Never \
            --set frontend.image.repository=depictio \
            --set frontend.image.tag=${{ steps.chart-info.outputs.app_version }} \
            --set frontend.image.pullPolicy=Never \
            --debug

          echo "‚úÖ Helm installation completed"
          echo "üìä Checking initial state..."
          kubectl get all -l "release=${{ steps.release-info.outputs.release_name }}"

      - name: Wait for Kubernetes Resources to Propagate
        run: |
          echo "‚è≥ Waiting for Kubernetes resources to propagate..."
          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"

          # Initial wait for resource creation
          echo "üïê Initial 30-second wait for resource creation..."
          sleep 30

          # Poll for expected workloads to be created (deployments + statefulsets)
          echo "üîç Waiting for workloads to be created..."
          timeout=180  # 3 minutes total timeout
          elapsed=0
          expected_deployments=4  # minio, backend, frontend, celery-worker
          expected_statefulsets=2  # mongo, redis

          while [ $elapsed -lt $timeout ]; do
            # Count deployments by their names
            deployment_count=$(kubectl get deployments --no-headers 2>/dev/null | grep -c "^${RELEASE_NAME}-" || echo "0")
            # Count statefulsets by their names
            statefulset_count=$(kubectl get statefulsets --no-headers 2>/dev/null | grep -c "^${RELEASE_NAME}-" || echo "0")
            total_workloads=$((deployment_count + statefulset_count))
            expected_total=$((expected_deployments + expected_statefulsets))

            echo "üìä Found $deployment_count deployments, $statefulset_count statefulsets (total: $total_workloads, expecting: $expected_total)"

            if [ "$deployment_count" -ge "$expected_deployments" ] && [ "$statefulset_count" -ge "$expected_statefulsets" ]; then
              echo "‚úÖ All expected workloads have been created"
              break
            fi

            echo "‚è≥ Waiting for more workloads... (${elapsed}s/${timeout}s)"
            sleep 10
            elapsed=$((elapsed + 10))
          done

          if [ $elapsed -ge $timeout ]; then
            echo "‚ùå Timeout waiting for workloads to be created"
            echo "üìä Final deployment status:"
            kubectl get deployments --no-headers | grep "^${RELEASE_NAME}-" || echo "No deployments found with prefix ${RELEASE_NAME}-"
            echo "üìä Final statefulset status:"
            kubectl get statefulsets --no-headers | grep "^${RELEASE_NAME}-" || echo "No statefulsets found with prefix ${RELEASE_NAME}-"
            echo "üìä All deployments:"
            kubectl get deployments
            echo "üìä All statefulsets:"
            kubectl get statefulsets
            echo "üìä All resources with release label:"
            kubectl get all -l "release=${RELEASE_NAME}"
            exit 1
          fi

          # List all created workloads for verification
          echo "üìã Created deployments:"
          kubectl get deployments --no-headers | grep "^${RELEASE_NAME}-" || echo "No deployments found"
          echo "üìã Created statefulsets:"
          kubectl get statefulsets --no-headers | grep "^${RELEASE_NAME}-" || echo "No statefulsets found"

          echo ""
          echo "üîç Detailed pod status monitoring for troubleshooting frontend..."

          # Monitor pods every 30 seconds for 3 minutes to see what's happening
          monitor_timeout=180  # 3 minutes
          monitor_elapsed=0

          while [ $monitor_elapsed -lt $monitor_timeout ]; do
            echo ""
            echo "======================================="
            echo "üìä Pod Status Check (${monitor_elapsed}s/${monitor_timeout}s)"
            echo "======================================="

            echo "üîç All pods with details:"
            kubectl get pods -l "release=${RELEASE_NAME}" -o wide --show-labels

            echo ""
            echo "üîç Frontend pod detailed status:"
            FRONTEND_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=depictio-frontend" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$FRONTEND_POD" ]; then
              echo "üìã Frontend pod: $FRONTEND_POD"
              kubectl describe pod $FRONTEND_POD | grep -A 10 -E "(Conditions:|Init Containers:|Containers:)"

              echo ""
              echo "üìã Frontend init container logs (last 20 lines):"
              kubectl logs $FRONTEND_POD --all-containers=true --tail=20 2>/dev/null || echo "‚ùå No logs available yet"

              # Check if frontend is ready
              FRONTEND_READY=$(kubectl get pod $FRONTEND_POD -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
              if [ "$FRONTEND_READY" = "True" ]; then
                echo "‚úÖ Frontend pod is now ready!"
                break
              else
                echo "‚è≥ Frontend pod not ready yet (Ready: $FRONTEND_READY)"
              fi
            else
              echo "‚ùå Frontend pod not found"
            fi

            echo ""
            echo "üîç Backend pod status for comparison:"
            BACKEND_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=depictio-backend" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$BACKEND_POD" ]; then
              BACKEND_READY=$(kubectl get pod $BACKEND_POD -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
              echo "üìã Backend pod: $BACKEND_POD (Ready: $BACKEND_READY)"

              if [ "$BACKEND_READY" = "True" ]; then
                echo "‚úÖ Backend is ready and should be accepting connections"

                # Test backend connectivity from within cluster
                echo "üß™ Testing backend connectivity from cluster:"
                kubectl run test-backend-connectivity --image=busybox:1.35 --rm -i --restart=Never -- sh -c "nc -z ${RELEASE_NAME}-depictio-backend 80 && echo 'Backend service accessible' || echo 'Backend service not accessible'" || echo "Test failed"
              else
                echo "‚è≥ Backend not ready yet"
              fi
            else
              echo "‚ùå Backend pod not found"
            fi

            echo ""
            echo "üîç Celery worker pod status:"
            CELERY_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=celery-worker" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$CELERY_POD" ]; then
              CELERY_READY=$(kubectl get pod $CELERY_POD -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
              echo "üìã Celery worker pod: $CELERY_POD (Ready: $CELERY_READY)"
              kubectl describe pod $CELERY_POD | grep -A 10 -E "(Conditions:|Init Containers:|Containers:)"

              echo ""
              echo "üìã Celery worker init container logs (last 20 lines each):"
              for container in fix-permissions-celery wait-for-mongo wait-for-redis wait-for-backend wait-for-api-key; do
                echo "--- $container ---"
                kubectl logs $CELERY_POD -c $container --tail=20 2>/dev/null || echo "  (not available)"
              done

              echo ""
              echo "üìã Celery worker main container logs (last 20 lines):"
              kubectl logs $CELERY_POD -c celery-worker --tail=20 2>/dev/null || echo "  (not started yet)"

              if [ "$CELERY_READY" = "True" ]; then
                echo "‚úÖ Celery worker pod is now ready!"
              else
                echo "‚è≥ Celery worker pod not ready yet (Ready: $CELERY_READY)"
              fi
            else
              echo "‚è≥ Celery worker pod not found yet"
            fi

            # Wait 30 seconds before next check
            sleep 30
            monitor_elapsed=$((monitor_elapsed + 30))
          done

          echo ""
          echo "üìä Final pod status:"
          kubectl get pods -l "release=${RELEASE_NAME}" -o wide

          echo ""
          echo "‚úÖ Resource propagation monitoring complete"

      - name: Backend Logs
        if: always()
        run: |
          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"
          echo "üìã Backend Pod Logs"
          echo "===================="

          BACKEND_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=depictio-backend" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$BACKEND_POD" ]; then
            echo "Pod: $BACKEND_POD"
            echo ""
            echo "--- Pod Status ---"
            kubectl get pod $BACKEND_POD -o wide
            echo ""
            echo "--- Pod Describe (Events) ---"
            kubectl describe pod $BACKEND_POD | grep -A 50 "Events:" || echo "No events"
            echo ""
            echo "--- Init Container Logs ---"
            for container in update-iris-configs copy-screenshot-file wait-for-mongo wait-for-minio wait-for-redis verify-config-storage; do
              echo "=== $container ==="
              kubectl logs $BACKEND_POD -c $container 2>/dev/null || echo "  (not available)"
            done
            echo ""
            echo "--- Main Container Logs ---"
            kubectl logs $BACKEND_POD -c depictio-backend 2>/dev/null || echo "  (not available)"
          else
            echo "‚ùå Backend pod not found"
          fi

      - name: Frontend Logs
        if: always()
        run: |
          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"
          echo "üìã Frontend Pod Logs"
          echo "===================="

          FRONTEND_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=depictio-frontend" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$FRONTEND_POD" ]; then
            echo "Pod: $FRONTEND_POD"
            echo ""
            echo "--- Pod Status ---"
            kubectl get pod $FRONTEND_POD -o wide
            echo ""
            echo "--- Pod Describe (Events) ---"
            kubectl describe pod $FRONTEND_POD | grep -A 50 "Events:" || echo "No events"
            echo ""
            echo "--- Init Container Logs ---"
            for container in fix-permissions-frontend verify-config-storage wait-for-backend wait-for-backend-startup wait-for-api-key wait-for-redis; do
              echo "=== $container ==="
              kubectl logs $FRONTEND_POD -c $container 2>/dev/null || echo "  (not available)"
            done
            echo ""
            echo "--- Main Container Logs ---"
            kubectl logs $FRONTEND_POD -c depictio-frontend 2>/dev/null || echo "  (not available)"
          else
            echo "‚ùå Frontend pod not found"
          fi

      - name: Celery Worker Logs
        if: always()
        run: |
          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"
          echo "üìã Celery Worker Pod Logs"
          echo "========================="

          CELERY_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=celery-worker" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$CELERY_POD" ]; then
            echo "Pod: $CELERY_POD"
            echo ""
            echo "--- Pod Status ---"
            kubectl get pod $CELERY_POD -o wide
            echo ""
            echo "--- Pod Describe (Events) ---"
            kubectl describe pod $CELERY_POD | grep -A 50 "Events:" || echo "No events"
            echo ""
            echo "--- Init Container Logs ---"
            for container in fix-permissions-celery wait-for-mongo wait-for-redis wait-for-backend wait-for-api-key; do
              echo "=== $container ==="
              kubectl logs $CELERY_POD -c $container 2>/dev/null || echo "  (not available)"
            done
            echo ""
            echo "--- Main Container Logs ---"
            kubectl logs $CELERY_POD -c celery-worker 2>/dev/null || echo "  (not available)"
          else
            echo "‚ùå Celery worker pod not found"
          fi

      - name: Test Inter-Service Connectivity
        run: |
          echo "üîó Testing inter-service connectivity..."
          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"
          echo "üéØ Using release name: $RELEASE_NAME"

          # First check what pods exist
          echo "üîç Checking existing pods..."
          kubectl get pods -l "release=${RELEASE_NAME}" --show-labels || echo "No pods found yet"

          # Check deployments status first (using name prefix instead of labels)
          echo "üìä Checking deployment status..."
          kubectl get deployments --no-headers | grep "^${RELEASE_NAME}-" || echo "No deployments found"

          # Since pods are already verified as ready in propagation phase, skip deployment wait
          echo "‚úÖ Skipping deployment wait - pods already verified as ready in propagation phase"

          # Now wait for specific pods to be ready
          echo "‚è≥ Waiting for backend pods to be ready..."
          kubectl wait --for=condition=ready pod -l "release=${RELEASE_NAME},app=depictio-backend" --timeout=300s || {
            echo "‚ùå Backend pods failed to be ready"
            echo "üìä Backend pod details:"
            kubectl describe pods -l "release=${RELEASE_NAME},app=depictio-backend"
            exit 1
          }

          echo "‚è≥ Waiting for frontend pods to be ready..."
          kubectl wait --for=condition=ready pod -l "release=${RELEASE_NAME},app=depictio-frontend" --timeout=300s || {
            echo "‚ùå Frontend pods failed to be ready"
            echo "üìä Frontend pod details:"
            kubectl describe pods -l "release=${RELEASE_NAME},app=depictio-frontend"
            exit 1
          }

          echo "‚è≥ Waiting for celery-worker pods to be ready..."
          kubectl wait --for=condition=ready pod -l "release=${RELEASE_NAME},app=celery-worker" --timeout=300s || {
            echo "‚ùå Celery worker pods failed to be ready"
            echo "üìä Celery worker pod details:"
            kubectl describe pods -l "release=${RELEASE_NAME},app=celery-worker"
            echo ""
            echo "üìã Celery init container logs:"
            CELERY_POD_FAIL=$(kubectl get pods -l "release=${RELEASE_NAME},app=celery-worker" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$CELERY_POD_FAIL" ]; then
              for container in fix-permissions-celery wait-for-mongo wait-for-redis wait-for-backend wait-for-api-key; do
                echo "--- $container ---"
                kubectl logs $CELERY_POD_FAIL -c $container 2>/dev/null || echo "  (not available)"
              done
              echo ""
              echo "üìã Celery main container logs:"
              kubectl logs $CELERY_POD_FAIL -c celery-worker 2>/dev/null || echo "  (not available)"
            fi
            exit 1
          }

          # Additional wait for containers to fully start
          sleep 30

          # Use the correct selectors with release name
          echo "üîç Finding backend pod..."
          BACKEND_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=depictio-backend" -o jsonpath='{.items[0].metadata.name}' || echo "")
          if [ -z "$BACKEND_POD" ]; then
            echo "‚ùå No backend pod found with labels: release=${RELEASE_NAME},app=depictio-backend"
            echo "üìä Available pods:"
            kubectl get pods -l "release=${RELEASE_NAME}" --show-labels
            exit 1
          fi

          echo "üîç Finding frontend pod..."
          FRONTEND_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=depictio-frontend" -o jsonpath='{.items[0].metadata.name}' || echo "")
          if [ -z "$FRONTEND_POD" ]; then
            echo "‚ùå No frontend pod found with labels: release=${RELEASE_NAME},app=depictio-frontend"
            echo "üìä Available pods:"
            kubectl get pods -l "release=${RELEASE_NAME}" --show-labels
            exit 1
          fi

          echo "‚úÖ Backend pod: $BACKEND_POD"
          echo "‚úÖ Frontend pod: $FRONTEND_POD"

          # Check pod status and logs before connectivity tests
          echo ""
          echo "üìä Pod Status Summary:"
          kubectl get pods -l "release=${RELEASE_NAME}"

          echo ""
          echo "üîç Backend Pod Detailed Status:"
          kubectl describe pod $BACKEND_POD | grep -A 10 "Conditions:"

          echo ""
          echo "üîç Frontend Pod Detailed Status:"
          kubectl describe pod $FRONTEND_POD | grep -A 10 "Conditions:"

          echo ""
          echo "=============================="
          echo "üìã BACKEND POD LOGS (FULL)"
          echo "=============================="
          kubectl logs $BACKEND_POD --all-containers=true || echo "‚ùå Could not get backend logs"

          echo ""
          echo "=============================="
          echo "üìã FRONTEND POD LOGS (FULL)"
          echo "=============================="
          kubectl logs $FRONTEND_POD --all-containers=true || echo "‚ùå Could not get frontend logs"

          echo ""
          echo "=============================="
          echo "üìã BACKEND INIT CONTAINER LOGS"
          echo "=============================="
          kubectl logs $BACKEND_POD --previous --all-containers=true 2>/dev/null || echo "‚ÑπÔ∏è  No previous backend container logs available"

          echo ""
          echo "=============================="
          echo "üìã FRONTEND INIT CONTAINER LOGS"
          echo "=============================="
          kubectl logs $FRONTEND_POD --previous --all-containers=true 2>/dev/null || echo "‚ÑπÔ∏è  No previous frontend container logs available"

          # Find and log celery worker pod
          echo ""
          echo "üîç Finding celery-worker pod for logging..."
          CELERY_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=celery-worker" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$CELERY_POD" ]; then
            echo "‚úÖ Celery worker pod: $CELERY_POD"

            echo ""
            echo "üîç Celery Worker Pod Detailed Status:"
            kubectl describe pod $CELERY_POD | grep -A 10 "Conditions:"

            echo ""
            echo "=============================="
            echo "üìã CELERY WORKER POD LOGS (FULL)"
            echo "=============================="
            kubectl logs $CELERY_POD --all-containers=true || echo "‚ùå Could not get celery worker logs"

            echo ""
            echo "=============================="
            echo "üìã CELERY WORKER INIT CONTAINER LOGS"
            echo "=============================="
            kubectl logs $CELERY_POD --previous --all-containers=true 2>/dev/null || echo "‚ÑπÔ∏è  No previous celery worker container logs available"
          else
            echo "‚ö†Ô∏è  No celery worker pod found"
          fi

          echo ""
          echo "üîç Pod Container Status Details:"
          kubectl get pods $BACKEND_POD $FRONTEND_POD $CELERY_POD -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{range .status.containerStatuses[*]}  Container: {.name} - Ready: {.ready} - State: {.state}{"\n"}{end}{"\n"}{end}' 2>/dev/null || kubectl get pods $BACKEND_POD $FRONTEND_POD -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{range .status.containerStatuses[*]}  Container: {.name} - Ready: {.ready} - State: {.state}{"\n"}{end}{"\n"}{end}'

          echo ""
          echo "=============================="
          echo "üîß CONFIGURATION DEBUGGING"
          echo "=============================="

          echo "üìã ConfigMaps:"
          kubectl get configmaps -l "release=${RELEASE_NAME}"

          echo ""
          echo "üìã Secrets:"
          kubectl get secrets -l "release=${RELEASE_NAME}"

          echo ""
          echo "üìã Backend ConfigMap Contents:"
          kubectl get configmap ${RELEASE_NAME}-backend-config -o yaml 2>/dev/null || echo "‚ùå Backend configmap not found"

          echo ""
          echo "üìã Frontend ConfigMap Contents:"
          kubectl get configmap ${RELEASE_NAME}-frontend-config -o yaml 2>/dev/null || echo "‚ùå Frontend configmap not found"

          echo ""
          echo "üìã Celery ConfigMap Contents:"
          kubectl get configmap ${RELEASE_NAME}-celery-config -o yaml 2>/dev/null || echo "‚ùå Celery configmap not found"

          echo ""
          echo "üìã Backend Pod Environment Variables:"
          kubectl exec $BACKEND_POD -- env | sort | grep -E "(DEPICTIO|MONGO|MINIO)" || echo "‚ùå Could not get backend env vars"

          echo ""
          echo "üìã Frontend Pod Environment Variables:"
          kubectl exec $FRONTEND_POD -- env | sort | grep -E "(DEPICTIO|MONGO|MINIO)" || echo "‚ùå Could not get frontend env vars"

          echo ""
          echo "üìã Celery Worker Pod Environment Variables:"
          if [ -n "$CELERY_POD" ]; then
            kubectl exec $CELERY_POD -- env | sort | grep -E "(DEPICTIO|MONGO|MINIO|CELERY|REDIS)" || echo "‚ùå Could not get celery env vars"
          else
            echo "‚ö†Ô∏è  No celery worker pod available"
          fi

          echo ""
          echo "=============================="
          echo "üîß RESOURCE AND NETWORK INFO"
          echo "=============================="

          echo "üìä Node Resources:"
          kubectl top nodes 2>/dev/null || echo "‚ÑπÔ∏è  Metrics server not available"

          echo ""
          echo "üìä Pod Resources:"
          kubectl top pods -l "release=${RELEASE_NAME}" 2>/dev/null || echo "‚ÑπÔ∏è  Metrics server not available"

          echo ""
          echo "üìã Persistent Volume Claims:"
          kubectl get pvc -l "release=${RELEASE_NAME}"

          echo ""
          echo "üîß Service Endpoints Check:"
          kubectl get endpoints ${RELEASE_NAME}-depictio-backend
          kubectl get endpoints ${RELEASE_NAME}-depictio-frontend

          echo ""
          echo "üåê Services Details:"
          kubectl describe svc ${RELEASE_NAME}-depictio-backend
          echo ""
          kubectl describe svc ${RELEASE_NAME}-depictio-frontend

          echo ""
          echo "=============================="
          echo "üöÄ STARTING CONNECTIVITY TESTS"
          echo "=============================="

          # Construct service names (these match your output)
          MONGODB_SERVICE="${RELEASE_NAME}-mongo"  # Note: "mongo" not "mongodb"
          REDIS_SERVICE="${RELEASE_NAME}-redis"
          MINIO_SERVICE="${RELEASE_NAME}-minio"
          BACKEND_SERVICE="${RELEASE_NAME}-depictio-backend"
          FRONTEND_SERVICE="${RELEASE_NAME}-depictio-frontend"

          echo "üìã Service names:"
          echo "  MongoDB: $MONGODB_SERVICE"
          echo "  Redis: $REDIS_SERVICE"
          echo "  MinIO: $MINIO_SERVICE"
          echo "  Backend: $BACKEND_SERVICE"
          echo "  Frontend: $FRONTEND_SERVICE"

          # Verify services exist
          echo "üîç Verifying services exist..."
          kubectl get svc $MONGODB_SERVICE $REDIS_SERVICE $MINIO_SERVICE $BACKEND_SERVICE $FRONTEND_SERVICE

          # Test Backend -> MongoDB connectivity (PORT: 27018) - REMOVED || true
          echo "üß™ Testing Backend -> MongoDB connectivity..."
          if kubectl exec $BACKEND_POD -- sh -c "nc -z $MONGODB_SERVICE 27018"; then
            echo "‚úÖ Backend can reach MongoDB on port 27018"
          else
            echo "‚ùå Backend cannot reach MongoDB on port 27018"
            exit 1
          fi

          # Test Backend -> Redis connectivity (PORT: 6379)
          echo "üß™ Testing Backend -> Redis connectivity..."
          if kubectl exec $BACKEND_POD -- sh -c "nc -z $REDIS_SERVICE 6379"; then
            echo "‚úÖ Backend can reach Redis on port 6379"
          else
            echo "‚ùå Backend cannot reach Redis on port 6379"
            exit 1
          fi

          # Test Backend -> MinIO connectivity (PORT: 9000) - REMOVED || true
          echo "üß™ Testing Backend -> MinIO connectivity..."
          if kubectl exec $BACKEND_POD -- sh -c "nc -z $MINIO_SERVICE 9000"; then
            echo "‚úÖ Backend can reach MinIO on port 9000"
          else
            echo "‚ùå Backend cannot reach MinIO on port 9000"
            exit 1
          fi

          # Test Backend -> Frontend connectivity (PORT: 80) - REMOVED || true
          echo "üß™ Testing Backend -> Frontend connectivity..."
          if kubectl exec $BACKEND_POD -- sh -c "nc -z $FRONTEND_SERVICE 80"; then
            echo "‚úÖ Backend can reach Frontend on port 80"
          else
            echo "‚ùå Backend cannot reach Frontend on port 80"
            exit 1
          fi

          # Test Frontend -> Backend connectivity (PORT: 80) - REMOVED || true
          echo "üß™ Testing Frontend -> Backend connectivity..."
          if kubectl exec $FRONTEND_POD -- sh -c "nc -z $BACKEND_SERVICE 80"; then
            echo "‚úÖ Frontend can reach Backend on port 80"
          else
            echo "‚ùå Frontend cannot reach Backend on port 80"
            exit 1
          fi

          # Test Frontend -> MinIO connectivity (PORT: 9000) - REMOVED || true
          echo "üß™ Testing Frontend -> MinIO connectivity..."
          if kubectl exec $FRONTEND_POD -- sh -c "nc -z $MINIO_SERVICE 9000"; then
            echo "‚úÖ Frontend can reach MinIO on port 9000"
          else
            echo "‚ùå Frontend cannot reach MinIO on port 9000"
            exit 1
          fi

          # Test Frontend -> Redis connectivity (PORT: 6379)
          echo "üß™ Testing Frontend -> Redis connectivity..."
          if kubectl exec $FRONTEND_POD -- sh -c "nc -z $REDIS_SERVICE 6379"; then
            echo "‚úÖ Frontend can reach Redis on port 6379"
          else
            echo "‚ùå Frontend cannot reach Redis on port 6379"
            exit 1
          fi

          # Find Celery worker pod
          echo "üîç Finding celery-worker pod..."
          CELERY_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=celery-worker" -o jsonpath='{.items[0].metadata.name}' || echo "")
          if [ -z "$CELERY_POD" ]; then
            echo "‚ùå No celery-worker pod found with labels: release=${RELEASE_NAME},app=celery-worker"
            echo "üìä Available pods:"
            kubectl get pods -l "release=${RELEASE_NAME}" --show-labels
            exit 1
          fi
          echo "‚úÖ Celery worker pod: $CELERY_POD"

          # Test Celery -> Redis connectivity (PORT: 6379) - Celery broker
          echo "üß™ Testing Celery -> Redis connectivity..."
          if kubectl exec $CELERY_POD -- sh -c "nc -z $REDIS_SERVICE 6379"; then
            echo "‚úÖ Celery worker can reach Redis on port 6379"
          else
            echo "‚ùå Celery worker cannot reach Redis on port 6379"
            exit 1
          fi

          # Test Celery -> MongoDB connectivity (PORT: 27018)
          echo "üß™ Testing Celery -> MongoDB connectivity..."
          if kubectl exec $CELERY_POD -- sh -c "nc -z $MONGODB_SERVICE 27018"; then
            echo "‚úÖ Celery worker can reach MongoDB on port 27018"
          else
            echo "‚ùå Celery worker cannot reach MongoDB on port 27018"
            exit 1
          fi

          # Test Celery -> Backend connectivity (PORT: 80)
          echo "üß™ Testing Celery -> Backend connectivity..."
          if kubectl exec $CELERY_POD -- sh -c "nc -z $BACKEND_SERVICE 80"; then
            echo "‚úÖ Celery worker can reach Backend on port 80"
          else
            echo "‚ùå Celery worker cannot reach Backend on port 80"
            exit 1
          fi

          echo "üéâ All inter-service connectivity tests passed!"

      - name: Test Database and Storage Functionality
        run: |
          echo "üóÑÔ∏è Testing database and storage functionality..."

          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"
          BACKEND_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=depictio-backend" -o jsonpath='{.items[0].metadata.name}')

          echo "Using backend pod: $BACKEND_POD"

          # Get MinIO credentials from secret
          SECRET_NAME="${RELEASE_NAME}-depictio-secrets"
          MINIO_PASSWORD=$(kubectl get secret $SECRET_NAME -o jsonpath='{.data.MINIO_ROOT_PASSWORD}' | base64 -d)

          # Test MongoDB - List collections
          echo "üß™ Testing MongoDB and listing collections..."
          kubectl exec $BACKEND_POD -- python3 -c '
          import pymongo
          try:
              client = pymongo.MongoClient("mongodb://'${RELEASE_NAME}'-mongo:27018/", serverSelectionTimeoutMS=5000)
              client.admin.command("ping")

              # List all databases
              db_names = client.list_database_names()
              print(f"‚úÖ MongoDB connected - Databases: {db_names}")

              # Check if depictioDB exists
              if "depictioDB" in db_names:
                  print("‚úÖ depictioDB found!")

              # Check for specific collections
              db = client["depictioDB"]
              collections = db.list_collection_names()
              print(f"üìä Collections in depictioDB: {collections}")

              # Check if "users" collection exists
              if "users" in collections:
                  print("‚úÖ 'users' collection found!")
              else:
                  print("‚ö†Ô∏è  'users' collection not found")

              # Test static ID preservation for iris demo project
              if "projects" in collections:
                  print("\nüîç Verifying static IDs for iris demo project...")
                  projects_collection = db["projects"]

                  # Expected static IDs from YAML
                  expected_project_id = "646b0f3c1e4a2d7f8e5b8c9a"
                  expected_workflow_id = "646b0f3c1e4a2d7f8e5b8c9b"
                  expected_dc_id = "646b0f3c1e4a2d7f8e5b8c9c"

                  # Find the iris demo project
                  iris_project = projects_collection.find_one({"name": "Iris Dataset Project Data Analysis"})

                  if iris_project:
                      actual_project_id = str(iris_project["_id"])
                      print(f"üìã Project ID - Expected: {expected_project_id}, Actual: {actual_project_id}")

                      if actual_project_id == expected_project_id:
                          print("‚úÖ Project ID matches static ID from YAML")
                      else:
                          print(f"‚ùå Project ID mismatch! Expected {expected_project_id}, got {actual_project_id}")
                          exit(1)

                      # Check workflow ID
                      if "workflows" in iris_project and len(iris_project["workflows"]) > 0:
                          workflow = iris_project["workflows"][0]
                          actual_workflow_id = str(workflow["_id"])
                          print(f"üìã Workflow ID - Expected: {expected_workflow_id}, Actual: {actual_workflow_id}")

                          if actual_workflow_id == expected_workflow_id:
                              print("‚úÖ Workflow ID matches static ID from YAML")
                          else:
                              print(f"‚ùå Workflow ID mismatch! Expected {expected_workflow_id}, got {actual_workflow_id}")
                              exit(1)

                          # Check data collection ID
                          if "data_collections" in workflow and len(workflow["data_collections"]) > 0:
                              dc = workflow["data_collections"][0]
                              actual_dc_id = str(dc["_id"])
                              print(f"üìã Data Collection ID - Expected: {expected_dc_id}, Actual: {actual_dc_id}")

                              if actual_dc_id == expected_dc_id:
                                  print("‚úÖ Data Collection ID matches static ID from YAML")
                                  print("üéâ All static IDs are preserved correctly!")
                              else:
                                  print(f"‚ùå Data Collection ID mismatch! Expected {expected_dc_id}, got {actual_dc_id}")
                                  exit(1)
                          else:
                              print("‚ö†Ô∏è  No data collections found in workflow")
                      else:
                          print("‚ö†Ô∏è  No workflows found in project")
                  else:
                      print("‚ö†Ô∏è  Iris demo project not found in database")

              # Verify deltatable document exists for multi-instance deployments
              print("\nüóÑÔ∏è Verifying deltatable document exists...")
              if "deltatables" in collections:
                  deltatables_collection = db["deltatables"]
                  expected_dc_id = "646b0f3c1e4a2d7f8e5b8c9c"

                  # Find deltatable for iris data collection
                  from bson import ObjectId
                  deltatable = deltatables_collection.find_one({"data_collection_id": ObjectId(expected_dc_id)})

                  if deltatable:
                      print("‚úÖ Deltatable document found for dc_id:", expected_dc_id)
                      print("üìç Delta table location:", deltatable.get("delta_table_location", "N/A"))
                      aggregation_count = len(deltatable.get("aggregation", []))
                      print("üìä Aggregation count:", aggregation_count)
                  else:
                      print("‚ùå Deltatable document NOT found for dc_id:", expected_dc_id)
                      print("‚ö†Ô∏è  This will cause issues in multi-instance K8s deployments!")
                      exit(1)
              else:
                  print("‚ö†Ô∏è  deltatables collection not found")
                  exit(1)

              # Verify dashboard document has correct dc_id references
              print("\nüìä Verifying dashboard dc_id references...")
              if "dashboards" in collections:
                  dashboards_collection = db["dashboards"]
                  expected_dc_id = "646b0f3c1e4a2d7f8e5b8c9c"

                  # Find iris dashboard
                  iris_dashboard = dashboards_collection.find_one({"title": "Iris Dashboard demo"})

                  if iris_dashboard:
                      print("‚úÖ Iris dashboard found")
                      stored_metadata = iris_dashboard.get("stored_metadata", [])
                      print("üìã Dashboard has", len(stored_metadata), "components")

                      all_correct = True
                      for idx, component in enumerate(stored_metadata):
                          component_index = component.get("index", "component-" + str(idx))
                          dc_id = component.get("dc_id")

                          if dc_id:
                              actual_dc_id = str(dc_id)
                              if actual_dc_id != expected_dc_id:
                                  print("‚ùå Component", component_index + ":", "dc_id mismatch! Expected", expected_dc_id + ", got", actual_dc_id)
                                  all_correct = False
                              else:
                                  print("‚úÖ Component", component_index + ":", "dc_id correct (" + expected_dc_id + ")")

                          # Check nested dc_config._id
                          dc_config = component.get("dc_config", {})
                          if dc_config and "_id" in dc_config:
                              actual_config_id = str(dc_config["_id"])
                              if actual_config_id != expected_dc_id:
                                  print("‚ùå Component", component_index + ":", "dc_config._id mismatch! Expected", expected_dc_id + ", got", actual_config_id)
                                  all_correct = False
                              else:
                                  print("‚úÖ Component", component_index + ":", "dc_config._id correct (" + expected_dc_id + ")")

                      if not all_correct:
                          print("\n‚ùå Some dashboard components have incorrect dc_id references!")
                          exit(1)
                      else:
                          print("\nüéâ All dashboard components have correct dc_id references!")
                  else:
                      print("‚ö†Ô∏è  Iris dashboard not found")
              else:
                  print("‚ö†Ô∏è  dashboards collection not found")

          except Exception as e:
              print(f"‚ùå MongoDB failed: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          '

          # Test MinIO - Check for depictio-bucket
          echo "üß™ Testing MinIO and checking for depictio-bucket..."
          kubectl exec $BACKEND_POD -- python3 -c '
          import boto3
          from botocore.exceptions import ClientError
          try:
              s3 = boto3.client(
                  "s3",
                  endpoint_url="http://'${RELEASE_NAME}'-minio:9000",
                  aws_access_key_id="'$RELEASE_NAME'",
                  aws_secret_access_key="'$MINIO_PASSWORD'",
                  region_name="us-east-1"
              )

              # List all buckets
              response = s3.list_buckets()
              buckets = [bucket["Name"] for bucket in response.get("Buckets", [])]
              print(f"‚úÖ MinIO connected - Total buckets: {len(buckets)}")

              if buckets:
                  print(f"üìä Available buckets: {buckets}")
              else:
                  print("üìä No buckets found")

              # Check specifically for depictio-bucket
              if "depictio-bucket" in buckets:
                  print("‚úÖ depictio-bucket found!")

                  # Try to list objects in the bucket
                  try:
                      objects = s3.list_objects_v2(Bucket="depictio-bucket")
                      object_count = objects.get("KeyCount", 0)
                      print(f"üìÅ depictio-bucket contains {object_count} objects")
                  except Exception as e:
                      print(f"‚ö†Ô∏è  Could not list objects in depictio-bucket: {e}")
              else:
                  print("‚ö†Ô∏è  depictio-bucket not found")

                  # Try to create it for testing
                  try:
                      s3.create_bucket(Bucket="test-connectivity")
                      print("‚úÖ MinIO write test successful (created test-connectivity bucket)")
                      s3.delete_bucket(Bucket="test-connectivity")
                      print("‚úÖ MinIO delete test successful (removed test-connectivity bucket)")
                  except Exception as e:
                      print(f"‚ùå MinIO write/delete test failed: {e}")

          except Exception as e:
              print(f"‚ùå MinIO failed: {e}")
          '

          # Test Redis - Check connectivity and basic operations
          echo "üß™ Testing Redis connectivity and basic operations..."
          kubectl exec $BACKEND_POD -- python3 -c '
          import redis
          try:
              # Connect to Redis
              r = redis.Redis(host="'${RELEASE_NAME}'-redis", port=6379, db=0, socket_connect_timeout=5)

              # Test ping
              r.ping()
              print("‚úÖ Redis connected successfully")

              # Test basic set/get operations
              test_key = "test_helm_ci_key"
              test_value = "test_value_123"
              r.set(test_key, test_value)
              retrieved = r.get(test_key)

              if retrieved and retrieved.decode("utf-8") == test_value:
                  print(f"‚úÖ Redis read/write test successful")
                  r.delete(test_key)
              else:
                  print(f"‚ùå Redis read/write test failed")

              # Test cache DB (DB 0)
              cache_info = r.info("stats")
              print(f"üìä Redis cache stats: {cache_info.get('total_connections_received', 0)} connections")

          except Exception as e:
              print(f"‚ùå Redis failed: {e}")
              import traceback
              traceback.print_exc()
          '

      - name: Test API Endpoints
        run: |
          echo "üöÄ Testing confirmed API endpoints..."

          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"
          BACKEND_SERVICE="${RELEASE_NAME}-depictio-backend"  # Updated service name

          # Port forward to backend
          kubectl port-forward svc/$BACKEND_SERVICE 8082:80 &
          PID_BACKEND=$!
          sleep 5

          # Test the endpoint we KNOW works
          echo "üß™ Testing /depictio/api/v1/utils/status..."
          API_RESPONSE=$(curl -s http://localhost:8082/depictio/api/v1/utils/status 2>/dev/null || echo '{"error":"connection_failed"}')
          API_STATUS=$(echo "$API_RESPONSE" | jq -r '.status // "unknown"' 2>/dev/null || echo "parse_error")
          API_VERSION=$(echo "$API_RESPONSE" | jq -r '.version // "unknown"' 2>/dev/null || echo "parse_error")

          echo "üìä API Response: $API_RESPONSE"

          if [ "$API_STATUS" = "online" ]; then
            echo "‚úÖ API is online with version: $API_VERSION"
          else
            echo "‚ùå API status check failed. Expected 'online', got: $API_STATUS"
          fi

          # Test FastAPI docs (should exist if it's FastAPI)
          echo "üß™ Testing /docs (FastAPI documentation)..."
          DOCS_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8082/docs 2>/dev/null || echo "000")

          if [ "$DOCS_STATUS" = "200" ]; then
            echo "‚úÖ API docs accessible at /docs"
          else
            echo "‚ÑπÔ∏è  API docs not available (status: $DOCS_STATUS)"
          fi

          # Test OpenAPI schema (should exist if it's FastAPI)
          echo "üß™ Testing /openapi.json (OpenAPI schema)..."
          OPENAPI_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8082/openapi.json 2>/dev/null || echo "000")

          if [ "$OPENAPI_STATUS" = "200" ]; then
            echo "‚úÖ OpenAPI schema accessible"
          else
            echo "‚ÑπÔ∏è  OpenAPI schema not available (status: $OPENAPI_STATUS)"
          fi

          kill $PID_BACKEND || true

      - name: Test Basic Service Connectivity
        run: |
          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"
          FRONTEND_SERVICE="${RELEASE_NAME}-depictio-frontend"
          BACKEND_SERVICE="${RELEASE_NAME}-depictio-backend"

          echo "üåê Testing frontend service..."
          kubectl port-forward svc/$FRONTEND_SERVICE 8080:80 &
          PID_FRONTEND=$!
          sleep 5

          FRONTEND_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8080 || echo "000")
          echo "üìä Frontend status: $FRONTEND_STATUS"

          if [ "$FRONTEND_STATUS" = "200" ]; then
            echo "‚úÖ Frontend service responding"
          else
            echo "‚ÑπÔ∏è  Frontend status: $FRONTEND_STATUS"
          fi

          kill $PID_FRONTEND

          echo "üåê Testing backend service..."
          kubectl port-forward svc/$BACKEND_SERVICE 8081:80 &
          PID_BACKEND=$!
          sleep 5

          # Use the confirmed working endpoint
          BACKEND_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8081/depictio/api/v1/utils/status || echo "000")
          echo "üìä Backend API status: $BACKEND_STATUS"

          if [ "$BACKEND_STATUS" = "200" ]; then
            echo "‚úÖ Backend API responding correctly"
          else
            echo "‚ùå Backend API not responding (status: $BACKEND_STATUS)"
          fi

          kill $PID_BACKEND || true

      - name: Test Screenshot Generation
        run: |
          echo "üì∏ Testing screenshot generation functionality..."

          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"
          BACKEND_SERVICE="${RELEASE_NAME}-depictio-backend"

          # Clean up any leftover port forwards first
          echo "üßπ Cleaning up existing port forwards..."
          pkill -f "kubectl port-forward" || true
          sleep 3

          # Port forward to backend
          echo "üîó Setting up port forward to $BACKEND_SERVICE..."
          kubectl port-forward svc/$BACKEND_SERVICE 8083:80 &
          PID_BACKEND=$!

          # Wait longer for port forward to stabilize
          echo "‚è≥ Waiting for port forward to stabilize..."
          sleep 10

          # Test connectivity first
          echo "üîß Testing port forward connectivity..."
          if curl -s --max-time 10 http://localhost:8083/depictio/api/v1/utils/status >/dev/null 2>&1; then
            echo "‚úÖ Port forward is working"
          else
            echo "‚ùå Port forward failed - checking service details..."
            kubectl describe svc/$BACKEND_SERVICE
            kubectl get endpoints $BACKEND_SERVICE
            exit 1
          fi

          # Get backend pod name
          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"
          BACKEND_POD=$(kubectl get pods -l "release=${RELEASE_NAME},app=depictio-backend" -o jsonpath='{.items[0].metadata.name}')
          echo "Backend pod: $BACKEND_POD"

          # Log backend BEFORE the request
          echo "üìã Backend logs BEFORE screenshot request:"
          kubectl logs $BACKEND_POD --tail=200

          # Test screenshot endpoint
          echo "üß™ Testing screenshot generation endpoint..."
          DASHBOARD_ID="6824cb3b89d2b72169309737"

          echo "üìû Making screenshot request (timeout: 90s)..."

          # Add timeout for screenshot generation (it's slow)
          # http://localhost:8083/depictio/api/v1/dashboards/screenshot/$DASHBOARD_ID)
          set +e  # Don't exit on curl error
          SCREENSHOT_RESPONSE=$(curl -s --max-time 90 -w "\n%{http_code}" \
            http://localhost:8083/depictio/api/v1/utils/screenshot-dash-fixed/$DASHBOARD_ID)
          CURL_EXIT_CODE=$?
          set -e

          # Log backend AFTER the request
          echo "üìã Backend logs AFTER screenshot request:"
          kubectl logs $BACKEND_POD --tail=200

          if [ $CURL_EXIT_CODE -eq 0 ]; then
            # Extract HTTP status code (last line)
            HTTP_CODE=$(echo "$SCREENSHOT_RESPONSE" | tail -n1)
            JSON_RESPONSE=$(echo "$SCREENSHOT_RESPONSE" | head -n -1)

            echo "üìä HTTP Status: $HTTP_CODE"

            if [ "$HTTP_CODE" = "200" ]; then
              echo "‚úÖ Screenshot endpoint responded successfully"

              # Parse response safely
              SUCCESS=$(echo "$JSON_RESPONSE" | jq -r '.success // false' 2>/dev/null || echo "false")
              MESSAGE=$(echo "$JSON_RESPONSE" | jq -r '.message // "unknown"' 2>/dev/null || echo "unknown")

              echo "üìã Success: $SUCCESS, Message: $MESSAGE"

              if [ "$SUCCESS" = "true" ]; then
                echo "‚úÖ Screenshot generation successful"
              else
                echo "‚ùå Screenshot generation failed"
                exit 1
              fi

            elif [ "$HTTP_CODE" = "404" ]; then
              echo "‚ö†Ô∏è  Dashboard not found (expected for dummy ID)"
              echo "‚úÖ Screenshot endpoint is accessible"
            else
              echo "‚ùå Screenshot endpoint failed with status: $HTTP_CODE"
              exit 1
            fi
          else
            echo "‚ùå Curl failed with exit code: $CURL_EXIT_CODE"
            case $CURL_EXIT_CODE in
              7) echo "Failed to connect to server" ;;
              28) echo "Request timed out after 90 seconds" ;;
              52) echo "Server returned empty response" ;;
            esac
            exit 1
          fi

          # Clean up
          kill $PID_BACKEND || true


      - name: Test install from package
        run: |
          RELEASE_NAME="${{ steps.release-info.outputs.release_name }}"

          # Clean up existing installation and all resources
          helm uninstall $RELEASE_NAME || true
          kubectl delete pvc --all || true
          kubectl delete configmap --all || true
          sleep 15

          PACKAGE_RANDOM_SUFFIX=$(openssl rand -hex 4 | cut -c1-9)
          PACKAGE_RELEASE_NAME="p${PACKAGE_RANDOM_SUFFIX}"
          echo "üé≤ Package test release name: $PACKAGE_RELEASE_NAME"

          # Install from packaged chart
          helm install $PACKAGE_RELEASE_NAME ./depictio-${{ steps.chart-info.outputs.chart_version }}.tgz \
            -f ./helm-charts/depictio/values-gh-actions.yaml \
            --set backend.image.repository=depictio \
            --set backend.image.tag=${{ steps.chart-info.outputs.app_version }} \
            --set backend.image.pullPolicy=Never \
            --set frontend.image.repository=depictio \
            --set frontend.image.tag=${{ steps.chart-info.outputs.app_version }} \
            --set frontend.image.pullPolicy=Never

          echo "‚úÖ Successfully installed from packaged chart"
          kubectl get pods

          # Store package release name for cleanup
          echo "package_release_name=$PACKAGE_RELEASE_NAME" >> $GITHUB_ENV

      - name: Push chart to GHCR
        if: (github.event_name == 'push' && github.ref == 'refs/heads/main') || github.event_name == 'workflow_dispatch'
        run: |
          helm push depictio-${{ steps.chart-info.outputs.chart_version }}.tgz oci://${{ env.REGISTRY }}/${{ github.repository_owner }}/${{ env.CHART_NAME }}
          echo "Chart pushed to: oci://${{ env.REGISTRY }}/${{ github.repository_owner }}/${{ env.CHART_NAME }}:${{ steps.chart-info.outputs.chart_version }}"

      - name: Cleanup
        if: always()
        run: |
          helm uninstall ${{ steps.release-info.outputs.release_name }} || true
          helm uninstall ${{ env.package_release_name }} || true
          minikube delete || true
