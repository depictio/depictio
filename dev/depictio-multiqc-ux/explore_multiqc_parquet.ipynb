{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECOMMENDED: Export sample list using general_stats_table filter\n",
    "if 'sample' in df.columns and 'anchor' in df.columns:\n",
    "    print(\"=== RECOMMENDED APPROACH: Filter by general_stats_table ===\")\n",
    "    \n",
    "    # Apply the filtering used in the dashboard\n",
    "    sample_series = (\n",
    "        df.filter(pl.col(\"anchor\") == \"general_stats_table\")\n",
    "        .select(\"sample\")\n",
    "        .drop_nulls()\n",
    "        .unique()\n",
    "        .sort(\"sample\")\n",
    "    )\n",
    "    \n",
    "    # Filter out None, \"null\" strings, and empty strings\n",
    "    clean_samples = [\n",
    "        s for s in sample_series[\"sample\"].to_list() \n",
    "        if s is not None and s != \"null\" and s != \"\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"‚úÖ Filtered samples from general_stats_table: {len(clean_samples)}\")\n",
    "    print(\"\\nAll samples:\")\n",
    "    for i, sample in enumerate(clean_samples, 1):\n",
    "        print(f\"{i:2d}. '{sample}'\")\n",
    "    \n",
    "    print(\"\\n=== COMPARISON WITH UNFILTERED ===\")\n",
    "    # Compare with all samples approach\n",
    "    all_samples = [s for s in df['sample'].unique().sort() if s is not None and s != \"null\" and s != \"\"]\n",
    "    print(f\"All samples (any anchor): {len(all_samples)}\")\n",
    "    print(f\"General stats only: {len(clean_samples)}\")\n",
    "    print(f\"Samples filtered out: {len(all_samples) - len(clean_samples)}\")\n",
    "    \n",
    "    print(\"\\n=== PYTHON FORMAT FOR DASHBOARD ===\")\n",
    "    print(\"# Use this in your dashboard code:\")\n",
    "    print(f\"AVAILABLE_SAMPLES = {clean_samples}\")\n",
    "    \n",
    "    # Save to JSON\n",
    "    import json\n",
    "    with open('multiqc_samples_general_stats.json', 'w') as f:\n",
    "        json.dump(clean_samples, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüìÅ Saved to 'multiqc_samples_general_stats.json'\")\n",
    "else:\n",
    "    print(\"‚ùå Required columns 'sample' or 'anchor' not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiQC Parquet Data Exploration\n",
    "\n",
    "This notebook explores the MultiQC parquet file to understand the data structure and extract useful information for the dashboard automation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# File path\n",
    "parquet_path = \"/Users/tweber/Gits/workspaces/MultiQC-MegaQC/MultiQC_TestData/multiqc_output_fastqc_v1_30_0/multiqc_data/BETA-multiqc.parquet\"\n",
    "\n",
    "# Load with Polars (fast)\n",
    "df = pl.read_parquet(parquet_path)\n",
    "\n",
    "print(f\"‚úÖ Loaded parquet file: {Path(parquet_path).name}\")\n",
    "print(f\"üìä Shape: {df.shape}\")\n",
    "print(f\"üóÇÔ∏è  Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"=== COLUMN NAMES ===\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\n=== DATA TYPES ===\")\n",
    "for col, dtype in zip(df.columns, df.dtypes):\n",
    "    print(f\"{col:<20} {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows\n",
    "print(\"=== FIRST 5 ROWS ===\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample column analysis\n",
    "if 'sample' in df.columns:\n",
    "    print(\"=== SAMPLE COLUMN ANALYSIS ===\")\n",
    "    \n",
    "    # Unique samples\n",
    "    unique_samples = df.select('sample').unique().sort('sample')\n",
    "    sample_list = unique_samples['sample'].to_list()\n",
    "    \n",
    "    print(f\"Total unique samples: {len(sample_list)}\")\n",
    "    print(f\"Samples with None values: {sample_list.count(None)}\")\n",
    "    \n",
    "    # Filter out None values\n",
    "    valid_samples = [s for s in sample_list if s is not None]\n",
    "    print(f\"Valid samples (no None): {len(valid_samples)}\")\n",
    "    \n",
    "    print(\"\\n=== FIRST 10 VALID SAMPLES ===\")\n",
    "    for i, sample in enumerate(valid_samples[:10], 1):\n",
    "        print(f\"{i:2d}. {sample}\")\n",
    "    \n",
    "    print(\"\\n=== SAMPLE LENGTH DISTRIBUTION ===\")\n",
    "    sample_lengths = [len(str(s)) for s in valid_samples]\n",
    "    print(f\"Min length: {min(sample_lengths)}\")\n",
    "    print(f\"Max length: {max(sample_lengths)}\")\n",
    "    print(f\"Average length: {sum(sample_lengths) / len(sample_lengths):.1f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No 'sample' column found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample patterns analysis\n",
    "if 'sample' in df.columns:\n",
    "    print(\"=== SAMPLE PATTERN ANALYSIS ===\")\n",
    "    \n",
    "    valid_samples = [s for s in df['sample'].unique() if s is not None]\n",
    "    \n",
    "    # Categorize samples by pattern\n",
    "    numeric_samples = [s for s in valid_samples if s.isdigit()]\n",
    "    alphanumeric_samples = [s for s in valid_samples if not s.isdigit() and '_' in s]\n",
    "    dna_like_samples = [s for s in valid_samples if all(c in 'ATCG' for c in s) and len(s) > 20]\n",
    "    other_samples = [s for s in valid_samples if s not in numeric_samples + alphanumeric_samples + dna_like_samples]\n",
    "    \n",
    "    print(f\"Numeric samples: {len(numeric_samples)}\")\n",
    "    print(f\"  Examples: {numeric_samples[:3]}\")\n",
    "    \n",
    "    print(f\"\\nAlphanumeric samples (with underscore): {len(alphanumeric_samples)}\")\n",
    "    print(f\"  Examples: {alphanumeric_samples[:3]}\")\n",
    "    \n",
    "    print(f\"\\nDNA-like samples (long ATCG sequences): {len(dna_like_samples)}\")\n",
    "    print(f\"  Examples: {[s[:30] + '...' for s in dna_like_samples[:3]]}\")\n",
    "    \n",
    "    print(f\"\\nOther samples: {len(other_samples)}\")\n",
    "    print(f\"  Examples: {[s[:30] + '...' if len(s) > 30 else s for s in other_samples[:3]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Content Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore key columns\n",
    "key_columns = ['anchor', 'type', 'plot_type', 'section_key', 'metric']\n",
    "\n",
    "for col in key_columns:\n",
    "    if col in df.columns:\n",
    "        unique_vals = df[col].unique().to_list()\n",
    "        print(f\"\\n=== {col.upper()} (unique values: {len(unique_vals)}) ===\")\n",
    "        for val in unique_vals[:10]:\n",
    "            print(f\"  - {val}\")\n",
    "        if len(unique_vals) > 10:\n",
    "            print(f\"  ... and {len(unique_vals) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value columns analysis\n",
    "value_columns = ['val_raw', 'val_mod', 'val_fmt']\n",
    "\n",
    "for col in value_columns:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n=== {col.upper()} ===\")\n",
    "        print(f\"Non-null count: {df[col].count()}\")\n",
    "        print(f\"Null count: {df.shape[0] - df[col].count()}\")\n",
    "        \n",
    "        # Sample values\n",
    "        non_null_values = df.filter(pl.col(col).is_not_null())[col].unique().to_list()[:5]\n",
    "        print(f\"Sample values: {non_null_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample-Specific Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for our test sample\n",
    "test_sample = '00050101'\n",
    "\n",
    "if 'sample' in df.columns:\n",
    "    sample_data = df.filter(pl.col('sample') == test_sample)\n",
    "    \n",
    "    print(f\"=== DATA FOR SAMPLE: {test_sample} ===\")\n",
    "    print(f\"Rows for this sample: {sample_data.shape[0]}\")\n",
    "    \n",
    "    if sample_data.shape[0] > 0:\n",
    "        print(\"\\n=== METRICS FOR THIS SAMPLE ===\")\n",
    "        metrics = sample_data['metric'].unique().to_list()\n",
    "        for metric in metrics[:10]:\n",
    "            print(f\"  - {metric}\")\n",
    "        \n",
    "        print(\"\\n=== SAMPLE DATA PREVIEW ===\")\n",
    "        sample_data.select(['anchor', 'metric', 'val_raw', 'val_fmt']).head(5)\n",
    "    else:\n",
    "        print(f\"‚ùå No data found for sample {test_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Sample List for Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clean sample list for use in dashboard\n",
    "if 'sample' in df.columns:\n",
    "    # Get clean sample list (no None values)\n",
    "    clean_samples = [s for s in df['sample'].unique().sort() if s is not None]\n",
    "    \n",
    "    print(f\"=== FINAL SAMPLE LIST FOR DASHBOARD ===\")\n",
    "    print(f\"Total samples: {len(clean_samples)}\")\n",
    "    print(\"\\nFirst 10 samples:\")\n",
    "    for i, sample in enumerate(clean_samples[:10], 1):\n",
    "        print(f\"{i:2d}. '{sample}'\")\n",
    "    \n",
    "    print(\"\\n=== PYTHON LIST FORMAT ===\")\n",
    "    print(\"# Copy this for your dashboard:\")\n",
    "    print(f\"SAMPLES = {clean_samples[:20]}  # First 20 samples\")\n",
    "    \n",
    "    # Save to file\n",
    "    import json\n",
    "    with open('multiqc_samples.json', 'w') as f:\n",
    "        json.dump(clean_samples, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Saved {len(clean_samples)} samples to 'multiqc_samples.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas for more detailed exploration if needed\n",
    "df_pandas = df.to_pandas()\n",
    "\n",
    "print(\"=== PANDAS DATAFRAME INFO ===\")\n",
    "print(df_pandas.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample correlation with metrics\n",
    "if 'sample' in df.columns and 'metric' in df.columns:\n",
    "    print(\"=== SAMPLE-METRIC RELATIONSHIPS ===\")\n",
    "    \n",
    "    # Cross-tabulation\n",
    "    sample_metric_counts = df.group_by(['sample', 'metric']).count().sort('count', descending=True)\n",
    "    \n",
    "    print(\"Top sample-metric combinations:\")\n",
    "    sample_metric_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=== SUMMARY STATISTICS ===\")\n",
    "print(f\"üìä Total rows: {df.shape[0]:,}\")\n",
    "print(f\"üóÇÔ∏è  Total columns: {df.shape[1]}\")\n",
    "print(f\"üè∑Ô∏è  Unique samples: {df['sample'].n_unique() if 'sample' in df.columns else 'N/A'}\")\n",
    "print(f\"üìà Unique metrics: {df['metric'].n_unique() if 'metric' in df.columns else 'N/A'}\")\n",
    "print(f\"üéØ Unique plot types: {df['plot_type'].n_unique() if 'plot_type' in df.columns else 'N/A'}\")\n",
    "\n",
    "# Memory usage\n",
    "memory_mb = df.estimated_size() / (1024 * 1024) if hasattr(df, 'estimated_size') else 'Unknown'\n",
    "print(f\"üíæ Estimated memory: {memory_mb:.2f} MB\" if isinstance(memory_mb, float) else f\"üíæ Memory: {memory_mb}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
