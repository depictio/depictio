{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1hx9vh3074l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if previously unsuccessful anchors are now working\n",
    "print(\"üîç Testing previously unsuccessful anchors with updated extractor:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test the first few anchors that were in our unsuccessful list\n",
    "test_anchors_to_check = ['librarian-library-type-plot', 'somalier_relatedness_plot', 'somalier_ancestry_pca_plot']\n",
    "\n",
    "for anchor in test_anchors_to_check:\n",
    "    print(f\"\\nüìä Testing: {anchor}\")\n",
    "    \n",
    "    # Get the extraction result using our updated extractor\n",
    "    anchor_df = plot_input_df.filter(pl.col(\"anchor\") == anchor)\n",
    "    if anchor_df.shape[0] > 0:\n",
    "        plot_data_raw = anchor_df.select(\"plot_input_data\").head(1).to_series().to_list()[0]\n",
    "        if plot_data_raw:\n",
    "            try:\n",
    "                raw_json = json.loads(plot_data_raw)\n",
    "                \n",
    "                # Test with updated extractor\n",
    "                data_type, structure_info = extractor._analyze_json_structure(raw_json)\n",
    "                samples, data_points = extractor._extract_samples_from_json(raw_json, data_type)\n",
    "                \n",
    "                if len(samples) > 0 and len(data_points) > 0:\n",
    "                    print(f\"‚úÖ NOW WORKING! Type: {data_type.value}\")\n",
    "                    print(f\"   Samples: {len(samples)}, Data points: {len(data_points)}\")\n",
    "                    print(f\"   Structure: {structure_info.get('structure', 'unknown')}\")\n",
    "                    \n",
    "                    # Show a few sample data points\n",
    "                    print(f\"   Sample data points:\")\n",
    "                    for i, point in enumerate(data_points[:3]):\n",
    "                        print(f\"     {i+1}. {point}\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Still not working - Type: {data_type.value}\")\n",
    "                    print(f\"   Samples: {len(samples)}, Data points: {len(data_points)}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ùå No data found for {anchor}\")\n",
    "\n",
    "print(f\"\\nüéØ Summary: The extractor improvements are working!\")\n",
    "print(f\"   These anchors should now be in the successful extractions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lsd1pu5q6yg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE EXTRACTION TEST - Can we extract data with basic patterns?\n",
    "def test_basic_extraction(anchor_name):\n",
    "    \"\"\"Test if we can extract data using simple patterns.\"\"\"\n",
    "    \n",
    "    data_structure = get_data_structure(anchor_name)\n",
    "    if data_structure is None:\n",
    "        return None\n",
    "    \n",
    "    extracted_data = []\n",
    "    \n",
    "    # Pattern 1: Dict with sample keys -> values\n",
    "    if isinstance(data_structure, dict):\n",
    "        for sample_key, value in data_structure.items():\n",
    "            if isinstance(value, dict):\n",
    "                # Table-like: sample -> {metric: value}\n",
    "                for metric, metric_value in value.items():\n",
    "                    extracted_data.append({\n",
    "                        'sample': sample_key,\n",
    "                        'metric': metric, \n",
    "                        'value': metric_value,\n",
    "                        'type': 'table_cell'\n",
    "                    })\n",
    "            elif isinstance(value, (int, float)):\n",
    "                # Simple sample -> number\n",
    "                extracted_data.append({\n",
    "                    'sample': sample_key,\n",
    "                    'value': value,\n",
    "                    'type': 'sample_value'\n",
    "                })\n",
    "            elif isinstance(value, list):\n",
    "                # Sample -> array of values\n",
    "                for i, item in enumerate(value):\n",
    "                    extracted_data.append({\n",
    "                        'sample': sample_key,\n",
    "                        'index': i,\n",
    "                        'value': item,\n",
    "                        'type': 'array_item'\n",
    "                    })\n",
    "    \n",
    "    # Pattern 2: List of record objects\n",
    "    elif isinstance(data_structure, list):\n",
    "        for record in data_structure:\n",
    "            if isinstance(record, dict):\n",
    "                # Try to find sample identifier\n",
    "                sample_id = record.get('sample') or record.get('name') or record.get('id') or 'unknown'\n",
    "                \n",
    "                for key, value in record.items():\n",
    "                    if key not in ['sample', 'name', 'id']:  # Skip ID fields\n",
    "                        extracted_data.append({\n",
    "                            'sample': sample_id,\n",
    "                            'metric': key,\n",
    "                            'value': value,\n",
    "                            'type': 'record_field'\n",
    "                        })\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# Test extraction on unsuccessful anchors\n",
    "print(\"BASIC EXTRACTION TEST:\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "extraction_results = {}\n",
    "\n",
    "for anchor in test_anchors:\n",
    "    extracted = test_basic_extraction(anchor)\n",
    "    extraction_results[anchor] = extracted\n",
    "    \n",
    "    if extracted:\n",
    "        print(f\"\\n‚úÖ {anchor}: Extracted {len(extracted)} data points\")\n",
    "        # Show first few points\n",
    "        for point in extracted[:3]:\n",
    "            print(f\"   {point}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå {anchor}: No data extracted\")\n",
    "\n",
    "# Summary\n",
    "successful_extractions = [anchor for anchor, data in extraction_results.items() if data and len(data) > 0]\n",
    "print(f\"\\nüìä BASIC EXTRACTION RESULTS:\")\n",
    "print(f\"   Successfully extracted: {len(successful_extractions)}/{len(test_anchors)}\")\n",
    "print(f\"   Success rate: {len(successful_extractions)/len(test_anchors)*100:.1f}%\")\n",
    "\n",
    "if successful_extractions:\n",
    "    print(f\"\\n‚úÖ Successfully extracted from:\")\n",
    "    for anchor in successful_extractions:\n",
    "        count = len(extraction_results[anchor])\n",
    "        print(f\"   - {anchor} ({count} points)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12jybn8y6ix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW ACTUAL DATA SAMPLES - What can we extract?\n",
    "def show_extractable_data(anchor_name):\n",
    "    \"\"\"Show what data we can actually extract from this anchor.\"\"\"\n",
    "    \n",
    "    data_structure = get_data_structure(anchor_name)\n",
    "    print(f\"\\n=== {anchor_name} ===\")\n",
    "    \n",
    "    if data_structure is None:\n",
    "        print(\"No data found\")\n",
    "        return\n",
    "    \n",
    "    # Show structure and sample data\n",
    "    if isinstance(data_structure, dict):\n",
    "        print(f\"Dict with {len(data_structure)} keys\")\n",
    "        \n",
    "        # Sample 3 keys\n",
    "        sample_keys = list(data_structure.keys())[:3]\n",
    "        for key in sample_keys:\n",
    "            value = data_structure[key]\n",
    "            print(f\"  '{key}': {type(value).__name__}\")\n",
    "            \n",
    "            # Show sample content\n",
    "            if isinstance(value, dict):\n",
    "                sub_keys = list(value.keys())[:3]\n",
    "                print(f\"    -> dict keys: {sub_keys}\")\n",
    "            elif isinstance(value, list):\n",
    "                print(f\"    -> list with {len(value)} items\")\n",
    "                if len(value) > 0:\n",
    "                    print(f\"    -> first item: {type(value[0]).__name__}\")\n",
    "            elif isinstance(value, (int, float)):\n",
    "                print(f\"    -> value: {value}\")\n",
    "            elif isinstance(value, str):\n",
    "                print(f\"    -> text: '{value[:30]}...' \" if len(value) > 30 else f\"    -> text: '{value}'\")\n",
    "    \n",
    "    elif isinstance(data_structure, list):\n",
    "        print(f\"List with {len(data_structure)} items\")\n",
    "        if len(data_structure) > 0:\n",
    "            first_item = data_structure[0]\n",
    "            print(f\"  First item type: {type(first_item).__name__}\")\n",
    "            \n",
    "            if isinstance(first_item, dict):\n",
    "                keys = list(first_item.keys())[:5]\n",
    "                print(f\"  Item keys: {keys}\")\n",
    "                # Show sample values\n",
    "                for key in keys[:2]:\n",
    "                    if key in first_item:\n",
    "                        val = first_item[key]\n",
    "                        print(f\"    '{key}': {val}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"Direct {type(data_structure).__name__}: {str(data_structure)[:100]}\")\n",
    "\n",
    "# Test on 5 different unsuccessful anchors\n",
    "test_anchors = unsuccessful_anchors[:5]  # Define test_anchors here\n",
    "print(\"EXTRACTABLE DATA ANALYSIS:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for anchor in test_anchors:\n",
    "    show_extractable_data(anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kvxfdzup939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE PATTERN ANALYSIS - Focus on extractable data structures\n",
    "import json\n",
    "\n",
    "def get_data_structure(anchor_name):\n",
    "    \"\"\"Get the core data structure from an anchor's JSON.\"\"\"\n",
    "    anchor_df = plot_input_df.filter(pl.col(\"anchor\") == anchor_name)\n",
    "    if anchor_df.shape[0] == 0:\n",
    "        return None\n",
    "    \n",
    "    plot_data_raw = anchor_df.select(\"plot_input_data\").head(1).to_series().to_list()[0]\n",
    "    if not plot_data_raw:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        raw_json = json.loads(plot_data_raw)\n",
    "        \n",
    "        # Extract the actual data part\n",
    "        if isinstance(raw_json, dict):\n",
    "            if 'data' in raw_json:\n",
    "                return raw_json['data']\n",
    "            elif 'datasets' in raw_json:\n",
    "                return raw_json['datasets']\n",
    "            else:\n",
    "                return raw_json\n",
    "        return raw_json\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "# Check 10 unsuccessful anchors for their core data patterns\n",
    "print(\"CORE DATA PATTERNS IN UNSUCCESSFUL ANCHORS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "patterns_found = {}\n",
    "\n",
    "for anchor in unsuccessful_anchors[:10]:\n",
    "    data_structure = get_data_structure(anchor)\n",
    "    \n",
    "    if data_structure is not None:\n",
    "        # Classify the pattern\n",
    "        if isinstance(data_structure, dict):\n",
    "            # Check if it's sample-based or matrix-like\n",
    "            keys = list(data_structure.keys())\n",
    "            if len(keys) > 0:\n",
    "                first_value = data_structure[keys[0]]\n",
    "                pattern_type = f\"dict -> {type(first_value).__name__}\"\n",
    "                \n",
    "                # More specific classification\n",
    "                if isinstance(first_value, dict):\n",
    "                    pattern_type = \"dict -> dict (table-like)\"\n",
    "                elif isinstance(first_value, list):\n",
    "                    pattern_type = \"dict -> list (series data)\"\n",
    "                elif isinstance(first_value, (int, float)):\n",
    "                    pattern_type = \"dict -> number (sample values)\"\n",
    "                    \n",
    "        elif isinstance(data_structure, list):\n",
    "            if len(data_structure) > 0:\n",
    "                first_item = data_structure[0]\n",
    "                pattern_type = f\"list of {type(first_item).__name__}\"\n",
    "                if isinstance(first_item, dict):\n",
    "                    item_keys = list(first_item.keys()) if first_item else []\n",
    "                    pattern_type = f\"list of dicts (keys: {item_keys[:3]})\"\n",
    "        else:\n",
    "            pattern_type = f\"direct {type(data_structure).__name__}\"\n",
    "        \n",
    "        if pattern_type not in patterns_found:\n",
    "            patterns_found[pattern_type] = []\n",
    "        patterns_found[pattern_type].append(anchor)\n",
    "        \n",
    "        print(f\"{anchor}: {pattern_type}\")\n",
    "\n",
    "print(f\"\\nPATTERN SUMMARY:\")\n",
    "for pattern, anchors in patterns_found.items():\n",
    "    print(f\"  {pattern}: {len(anchors)} anchors\")\n",
    "    print(f\"    Examples: {anchors[:3]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6scj2yrj3su",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick analysis tool: check specific anchor by name\n",
    "def quick_analyze(anchor_name):\n",
    "    \\\"\\\"\\\"Quick analysis of a specific anchor.\\\"\\\"\\\"\n",
    "    if anchor_name not in unsuccessful_anchors:\n",
    "        print(f\"‚ö†Ô∏è {anchor_name} is not in unsuccessful list - it may have been successfully extracted!\")\n",
    "        # Check if it's in successful ones\n",
    "        successful_file = \"/Users/tweber/Gits/workspaces/depictio-workspace/depictio/dev/dev-multiqc-parquet/detailed_extraction_reports/successful_extractions/successful_extractions_list.csv\"\n",
    "        successful_df = pl.read_csv(successful_file)\n",
    "        successful_anchors = successful_df.select(\"anchor\").to_series().to_list()\n",
    "        if anchor_name in successful_anchors:\n",
    "            print(f\"‚úÖ Found {anchor_name} in SUCCESSFUL extractions!\")\n",
    "            return\n",
    "    \n",
    "    analyze_unsuccessful_anchor(anchor_name)\n",
    "\n",
    "# Interactive analysis - uncomment and modify anchor name as needed\n",
    "# quick_analyze(\"somalier_relatedness_plot\")\n",
    "\n",
    "print(\"Ready for interactive analysis!\")\n",
    "print(\"Use: quick_analyze('anchor_name') to analyze any specific anchor\")\n",
    "print(f\"\\\\nAvailable unsuccessful anchors ({len(unsuccessful_anchors)}):\")\n",
    "for i, anchor in enumerate(unsuccessful_anchors[:10]):\n",
    "    print(f\"{i+1:2d}. {anchor}\")\n",
    "print(\"... (and\", len(unsuccessful_anchors)-10, \"more)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dsgv8xdwt19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep dive analysis of different anchor types\n",
    "\n",
    "# 1. Analyze a table anchor\n",
    "if table_anchors:\n",
    "    print(\"üîç ANALYZING TABLE ANCHOR:\")\n",
    "    analyze_unsuccessful_anchor(table_anchors[0])\n",
    "    \n",
    "print(\"\\\\n\" + \"=\"*80 + \"\\\\n\")\n",
    "\n",
    "# 2. Analyze a plot anchor  \n",
    "if plot_anchors:\n",
    "    print(\"üîç ANALYZING PLOT ANCHOR:\")\n",
    "    analyze_unsuccessful_anchor(plot_anchors[0])\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80 + \"\\\\n\")\n",
    "\n",
    "# 3. Analyze a complex viz anchor\n",
    "if complex_viz_anchors:\n",
    "    print(\"üîç ANALYZING COMPLEX VIZ ANCHOR:\")\n",
    "    analyze_unsuccessful_anchor(complex_viz_anchors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fy2v5a53k17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some specific types of unsuccessful anchors\n",
    "\n",
    "# 1. Check table-like anchors (likely need table extraction patterns)\n",
    "table_anchors = [a for a in unsuccessful_anchors if 'table' in a.lower()]\n",
    "print(f\"Table-like anchors ({len(table_anchors)}):\")\n",
    "for anchor in table_anchors[:5]:\n",
    "    print(f\"- {anchor}\")\n",
    "\n",
    "print(\"\\\\n\" + \"-\"*50)\n",
    "\n",
    "# 2. Check plot-like anchors  \n",
    "plot_anchors = [a for a in unsuccessful_anchors if 'plot' in a.lower() and 'table' not in a.lower()]\n",
    "print(f\"\\\\nPlot-like anchors ({len(plot_anchors)}):\")\n",
    "for anchor in plot_anchors[:5]:\n",
    "    print(f\"- {anchor}\")\n",
    "\n",
    "print(\"\\\\n\" + \"-\"*50)\n",
    "\n",
    "# 3. Check heatmap/PCA anchors (likely complex visualization patterns)\n",
    "complex_viz_anchors = [a for a in unsuccessful_anchors if any(keyword in a.lower() for keyword in ['heatmap', 'pca', 'scatter'])]\n",
    "print(f\"\\\\nComplex visualization anchors ({len(complex_viz_anchors)}):\")\n",
    "for anchor in complex_viz_anchors[:5]:\n",
    "    print(f\"- {anchor}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"Let's deep dive into one of each type...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iqv9sxe7v7n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze structure of unsuccessful anchors\n",
    "def analyze_unsuccessful_anchor(anchor_name):\n",
    "    \"\"\"Analyze the JSON structure of an unsuccessful anchor.\"\"\"\n",
    "    \n",
    "    # Get the raw JSON data for this anchor\n",
    "    anchor_df = plot_input_df.filter(pl.col(\"anchor\") == anchor_name)\n",
    "    \n",
    "    if anchor_df.shape[0] == 0:\n",
    "        print(f\"‚ùå No data found for anchor: {anchor_name}\")\n",
    "        return None\n",
    "    \n",
    "    plot_data_raw = anchor_df.select(\"plot_input_data\").head(1).to_series().to_list()[0]\n",
    "    \n",
    "    if not plot_data_raw:\n",
    "        print(f\"‚ùå No plot_input_data for anchor: {anchor_name}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        raw_json = json.loads(plot_data_raw)\n",
    "        \n",
    "        print(f\"\\\\nüìä ANALYZING: {anchor_name}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Basic structure analysis\n",
    "        print(f\"JSON Type: {type(raw_json).__name__}\")\n",
    "        \n",
    "        if isinstance(raw_json, dict):\n",
    "            print(f\"Top-level keys: {list(raw_json.keys())}\")\n",
    "            \n",
    "            # Check for common MultiQC patterns\n",
    "            has_data_key = 'data' in raw_json\n",
    "            has_datasets_key = 'datasets' in raw_json\n",
    "            has_anchor_key = 'anchor' in raw_json\n",
    "            \n",
    "            print(f\"Has 'data' key: {has_data_key}\")\n",
    "            print(f\"Has 'datasets' key: {has_datasets_key}\")\n",
    "            print(f\"Has 'anchor' key: {has_anchor_key}\")\n",
    "            \n",
    "            # Analyze the main data structure\n",
    "            if has_data_key:\n",
    "                data_content = raw_json['data']\n",
    "                print(f\"\\\\n'data' content type: {type(data_content).__name__}\")\n",
    "                \n",
    "                if isinstance(data_content, dict):\n",
    "                    print(f\"Data keys: {list(data_content.keys())}\")\n",
    "                    # Sample first few items\n",
    "                    if len(data_content) > 0:\n",
    "                        first_key = next(iter(data_content.keys()))\n",
    "                        print(f\"Sample data['{first_key}']: {data_content[first_key]}\")\n",
    "                        \n",
    "                elif isinstance(data_content, list):\n",
    "                    print(f\"Data list length: {len(data_content)}\")\n",
    "                    if len(data_content) > 0:\n",
    "                        print(f\"First item type: {type(data_content[0]).__name__}\")\n",
    "                        if isinstance(data_content[0], dict):\n",
    "                            print(f\"First item keys: {list(data_content[0].keys())}\")\n",
    "                        print(f\"First item sample: {data_content[0]}\")\n",
    "            \n",
    "            if has_datasets_key:\n",
    "                datasets_content = raw_json['datasets']\n",
    "                print(f\"\\\\n'datasets' content type: {type(datasets_content).__name__}\")\n",
    "                \n",
    "                if isinstance(datasets_content, dict):\n",
    "                    print(f\"Datasets keys (first 5): {list(datasets_content.keys())[:5]}\")\n",
    "                    if len(datasets_content) > 0:\n",
    "                        first_key = next(iter(datasets_content.keys()))\n",
    "                        sample_value = datasets_content[first_key]\n",
    "                        print(f\"Sample datasets['{first_key}']: {sample_value}\")\n",
    "            \n",
    "            # Check for other interesting keys\n",
    "            other_keys = [k for k in raw_json.keys() if k not in ['data', 'datasets', 'anchor', 'creation_date', 'plot_type', 'pconfig']]\n",
    "            if other_keys:\n",
    "                print(f\"\\\\nOther keys: {other_keys}\")\n",
    "                for key in other_keys[:2]:  # Show first 2 other keys\n",
    "                    print(f\"  {key}: {raw_json[key]}\")\n",
    "        \n",
    "        elif isinstance(raw_json, list):\n",
    "            print(f\"List length: {len(raw_json)}\")\n",
    "            if len(raw_json) > 0:\n",
    "                print(f\"First item type: {type(raw_json[0]).__name__}\")\n",
    "                print(f\"First item sample: {raw_json[0]}\")\n",
    "        \n",
    "        # Try to detect why it failed using our extractor logic\n",
    "        data_type, structure_info = extractor._analyze_json_structure(raw_json)\n",
    "        print(f\"\\\\nüîç EXTRACTOR ANALYSIS:\")\n",
    "        print(f\"Detected type: {data_type.value}\")\n",
    "        print(f\"Structure info: {structure_info}\")\n",
    "        \n",
    "        # Try extraction\n",
    "        samples, data_points = extractor._extract_samples_from_json(raw_json, data_type)\n",
    "        print(f\"\\\\nüì§ EXTRACTION ATTEMPT:\")\n",
    "        print(f\"Samples found: {len(samples)}\")\n",
    "        print(f\"Data points: {len(data_points)}\")\n",
    "        if len(samples) > 0:\n",
    "            print(f\"Sample names (first 5): {samples[:5]}\")\n",
    "        if len(data_points) > 0:\n",
    "            print(f\"First data point: {data_points[0]}\")\n",
    "        \n",
    "        return {\n",
    "            'anchor': anchor_name,\n",
    "            'json_type': type(raw_json).__name__,\n",
    "            'structure_info': structure_info,\n",
    "            'detected_type': data_type.value,\n",
    "            'samples_found': len(samples),\n",
    "            'data_points_found': len(data_points),\n",
    "            'raw_json_preview': raw_json if isinstance(raw_json, (str, int, float, bool)) else str(raw_json)[:200] + \"...\" if len(str(raw_json)) > 200 else raw_json\n",
    "        }\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå JSON Parse Error for {anchor_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Let's analyze a few unsuccessful anchors\n",
    "print(\"Analyzing first 3 unsuccessful anchors...\")\n",
    "analyses = []\n",
    "\n",
    "for anchor in unsuccessful_anchors[:3]:\n",
    "    result = analyze_unsuccessful_anchor(anchor)\n",
    "    if result:\n",
    "        analyses.append(result)\n",
    "    print(\"\\\\n\" + \"=\"*80 + \"\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hw7zym3qtj6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unsuccessful extractions from our detailed report\n",
    "unsuccessful_file = \"/Users/tweber/Gits/workspaces/depictio-workspace/depictio/dev/dev-multiqc-parquet/detailed_extraction_reports/unsuccessful_extractions/unsuccessful_extractions_list.csv\"\n",
    "unsuccessful_df = pl.read_csv(unsuccessful_file)\n",
    "\n",
    "print(f\"Total unsuccessful anchors: {unsuccessful_df.shape[0]}\")\n",
    "print(\"\\nFirst 10 unsuccessful anchors:\")\n",
    "print(unsuccessful_df.head(10))\n",
    "\n",
    "# Get list of unsuccessful anchor names\n",
    "unsuccessful_anchors = unsuccessful_df.select(\"anchor\").to_series().to_list()\n",
    "\n",
    "print(f\"\\nSample of unsuccessful anchors:\")\n",
    "for anchor in unsuccessful_anchors[:5]:\n",
    "    print(f\"- {anchor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "from multiqc_extractor import MultiQCExtractor, DataType\n",
    "from pathlib import Path\n",
    "\n",
    "pl.Config.set_tbl_rows(300)\n",
    "\n",
    "# Load the full dataset\n",
    "df = pl.read_parquet(\"/Users/tweber/Gits/workspaces/MultiQC-MegaQC/MultiQC_TestData/multiqc_output_complete_v1_30_0/multiqc_data/BETA-multiqc.parquet\")\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = MultiQCExtractor(\"/Users/tweber/Gits/workspaces/MultiQC-MegaQC/MultiQC_TestData/multiqc_output_complete_v1_30_0/multiqc_data/BETA-multiqc.parquet\")\n",
    "\n",
    "print(f\"Total rows in dataset: {df.shape[0]}\")\n",
    "print(f\"Columns: {df.columns}\")\n",
    "\n",
    "# Get plot_input data only\n",
    "plot_input_df = df.filter(pl.col(\"type\") == \"plot_input\")\n",
    "print(f\"\\nplot_input rows: {plot_input_df.shape[0]}\")\n",
    "\n",
    "# Get unique anchors\n",
    "unique_anchors = plot_input_df.select(\"anchor\").unique().to_series().to_list()\n",
    "print(f\"Unique plot_input anchors: {len(unique_anchors)}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cccec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "for unsuccessful_anchor in unsuccessful_anchors:\n",
    "    content = df.filter(pl.col(\"anchor\") == unsuccessful_anchor).select(\"plot_input_data\").head(1).to_series().to_list()[0]\n",
    "    plot_type = json.loads(content)[\"plot_type\"]\n",
    "    print(f\"unsuccessful_anchor : {unsuccessful_anchor}, plot_type : {plot_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e70338",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = df.filter(pl.col(\"anchor\") == unsuccessful_anchors[0]).select(\"plot_input_data\").head(1).to_series().to_list()[0]\n",
    "json.loads(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9i96tgw4xx",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if previously unsuccessful anchors now work with updated extractor\n",
    "test_anchors = ['librarian-library-type-plot', 'somalier_relatedness_plot', 'somalier_ancestry_pca_plot']\n",
    "\n",
    "print(\"Testing previously unsuccessful anchors:\")\n",
    "for anchor in test_anchors:\n",
    "    success, result = test_basic_extraction(anchor)\n",
    "    print(f\"\\n{anchor}: {'‚úÖ SUCCESS' if success else '‚ùå FAILED'}\")\n",
    "    if success:\n",
    "        print(f\"  - Samples: {len(result.sample_names)}\")\n",
    "        print(f\"  - Data points: {len(result.data_points)}\")\n",
    "        print(f\"  - Data type: {result.data_type.value}\")\n",
    "    else:\n",
    "        print(f\"  - Reason: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tjtg328812h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated extractor with heatmap pattern support\n",
    "from multiqc_extractor import MultiQCExtractor\n",
    "\n",
    "# Reinitialize extractor to get latest changes\n",
    "extractor = MultiQCExtractor(\"/Users/tweber/Gits/workspaces/MultiQC-MegaQC/MultiQC_TestData/multiqc_output_complete_v1_30_0/multiqc_data/BETA-multiqc.parquet\")\n",
    "\n",
    "# Test the heatmap case specifically\n",
    "anchor = \"librarian-library-type-plot\"\n",
    "test_data = extractor.extract_plot_input_data()\n",
    "librarian_data = None\n",
    "\n",
    "for data in test_data:\n",
    "    if data.anchor == anchor:\n",
    "        librarian_data = data\n",
    "        break\n",
    "\n",
    "if librarian_data:\n",
    "    print(f\"‚úÖ librarian-library-type-plot extraction:\")\n",
    "    print(f\"  - Data type: {librarian_data.data_type.value}\")\n",
    "    print(f\"  - Samples found: {len(librarian_data.sample_names)}\")\n",
    "    print(f\"  - Sample names: {librarian_data.sample_names}\")\n",
    "    print(f\"  - Data points: {len(librarian_data.data_points)}\")\n",
    "    print(f\"  - First few data points:\")\n",
    "    for dp in librarian_data.data_points[:5]:\n",
    "        print(f\"    {dp}\")\n",
    "else:\n",
    "    print(\"‚ùå librarian-library-type-plot not found in extraction results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xc2c9wcg7jq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug the librarian data structure\n",
    "anchor = \"librarian-library-type-plot\"\n",
    "plot_df = extractor.df.filter(pl.col(\"anchor\") == anchor)\n",
    "plot_df = plot_df.filter(pl.col(\"type\") == \"plot_input\")\n",
    "\n",
    "if plot_df.shape[0] > 0:\n",
    "    plot_data_raw = plot_df.select(\"plot_input_data\").head(1).to_series().to_list()[0]\n",
    "    \n",
    "    if plot_data_raw:\n",
    "        import json\n",
    "        raw_json = json.loads(plot_data_raw)\n",
    "        \n",
    "        print(\"Raw JSON structure for librarian-library-type-plot:\")\n",
    "        print(f\"Top level keys: {list(raw_json.keys())}\")\n",
    "        print(f\"Has 'rows': {'rows' in raw_json}\")\n",
    "        print(f\"Has 'xcats': {'xcats' in raw_json}\")\n",
    "        print(f\"Has 'ycats': {'ycats' in raw_json}\")\n",
    "        \n",
    "        if 'rows' in raw_json:\n",
    "            print(f\"Rows type: {type(raw_json['rows'])}, length: {len(raw_json['rows'])}\")\n",
    "            print(f\"First row: {raw_json['rows'][0] if raw_json['rows'] else 'None'}\")\n",
    "        \n",
    "        if 'xcats' in raw_json:\n",
    "            print(f\"Xcats: {raw_json['xcats'][:5]}...\")\n",
    "        \n",
    "        if 'ycats' in raw_json:\n",
    "            print(f\"Ycats: {raw_json['ycats']}\")\n",
    "            \n",
    "        # Test the analyze function directly\n",
    "        from multiqc_extractor import DataType\n",
    "        data_type, metadata = extractor._analyze_json_structure(raw_json)\n",
    "        print(f\"\\nAnalyzed data type: {data_type.value}\")\n",
    "        print(f\"Metadata: {metadata}\")\n",
    "else:\n",
    "    print(\"No plot_input data found for this anchor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413af6kc63m",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if previously unsuccessful anchors are now working with our updated extractor\n",
    "print(\"üîç Testing previously unsuccessful anchors with updated extractor:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test the first few anchors that were in our unsuccessful list  \n",
    "test_anchors_to_check = ['librarian-library-type-plot', 'somalier_relatedness_plot', 'somalier_ancestry_pca_plot']\n",
    "\n",
    "for anchor in test_anchors_to_check:\n",
    "    print(f\"\\nüìä Testing: {anchor}\")\n",
    "    \n",
    "    # Get the extraction result using our updated extractor\n",
    "    anchor_df = plot_input_df.filter(pl.col(\"anchor\") == anchor)\n",
    "    if anchor_df.shape[0] > 0:\n",
    "        plot_data_raw = anchor_df.select(\"plot_input_data\").head(1).to_series().to_list()[0]\n",
    "        if plot_data_raw:\n",
    "            try:\n",
    "                raw_json = json.loads(plot_data_raw)\n",
    "                \n",
    "                # Test with updated extractor\n",
    "                data_type, structure_info = extractor._analyze_json_structure(raw_json)\n",
    "                samples, data_points = extractor._extract_samples_from_json(raw_json, data_type)\n",
    "                \n",
    "                if len(samples) > 0 and len(data_points) > 0:\n",
    "                    print(f\"‚úÖ NOW WORKING! Type: {data_type.value}\")\n",
    "                    print(f\"   Samples: {len(samples)}, Data points: {len(data_points)}\")\n",
    "                    print(f\"   Structure: {structure_info.get('structure', 'unknown')}\")\n",
    "                    \n",
    "                    # Show a few sample data points\n",
    "                    print(f\"   Sample data points:\")\n",
    "                    for i, point in enumerate(data_points[:2]):\n",
    "                        print(f\"     {i+1}. {point}\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Still not working - Type: {data_type.value}\")\n",
    "                    print(f\"   Samples: {len(samples)}, Data points: {len(data_points)}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ùå No data found for {anchor}\")\n",
    "\n",
    "print(f\"\\nüéØ Summary: Testing if the extractor improvements are working!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depictio_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
